@PREAMBLE{ {\providecommand{\noopsort}[1]{}} }
@string{academic = {Academic Press}}
@string{acmmathsoft = {{ACM} Trans. Math. Softw.}}
@string{acmpress = {{ACM} Press}}
@string{actanumerica = {Acta Numer.}}
@string{adamhilger = {Adam Hilger}}
@string{addisonwesley = {Addison-Wesley}}
@string{allynbacon = {Allyn and Bacon}}
@string{amermathmonthly = {Amer. Math. Monthly}}
@string{amersocio = {Amer. J. Sociology}}
@string{amerstatassoc = {J. Amer. Statist. Assoc.}}
@string{ams = {American Mathematical Society}}
@string{amstrans = {Amer. Math. Soc. Transl.}}
@string{annalsstats = {Ann. Statist.}}
@string{appnummath = {Appl. Numer. Math.}}
@string{applmathcomp = {Appl. Math. Comput.}}
@string{athena = {Athena Scientific}}
@string{birkhauser = {Birkha{\"u}ser}}
@string{bit = {{BIT}}}
@string{britstatpsych = {Brit. J. Math. Statist. Psych.}}
@string{bullams = {Bull. Amer. Math. Soc.}}
@string{cacm = {Comm. {ACM}}}
@string{cambridgepress = {Cambridge University Press}}
@string{canmathbull = {Canad. Math. Bull.}}
@string{chelsea = {Chelsea}}
@string{claredonpress = {Claredon Press}}
@string{compapplmath = {J. Comput. Appl. Math.}}
@string{compapplopt = {Comput. Optim. Appl.}}
@string{compoptsoft = {Comput. Optim. Softw.}}
@string{compjour = {Comput. J.}}
@string{compphys = {J. Comput. Phys.}}
@string{compserv = {Comput. Surveys}}
@string{compstruct = {Comput. \& Structures}}
@string{compsyssci = {J. Comput. System Sci.}}
@string{computer = {{IEEE} Computer}}
@string{computing = {Computing}}
@string{contempmath = {Contemp. Math.}}
@string{crelle = {Crelle's J.}}
@string{doverpub = {Dover Publications}}
@string{eyolles = {Eyolles}}
@string{giornalemath = {Giorn. Mat.}}
@string{geophysics = {Geophys.}}
@string{holtrinehartwinston = {Holt, Rinehart and Winston}}
@string{ieeespec = {{IEEE} Spectrum}}
@string{ieeetransac = {{IEEE} Trans. Automat. Control}}
@string{ieeetransaeroelec = {{IEEE} Trans. Aerospace Electron. Systems}}
@string{ieeetranscomp = {{IEEE} Trans. Comput.}}
@string{ieeetransimproc = {{IEEE} Trans. Image Process.}}
@string{ieeetransinfo = {{IEEE} Trans. Inform. Theory}}
@string{ieeetranssigproc = {{IEEE} Trans. Sig. Proc.}}
@string{imanumerana = {{IMA} J. Numer. Anal.}}
@string{imanumerana- = {{IMA} Journal of Numerical Analysis}}
@string{infproclet = {Inform. Process. Lett.}}
@string{instmathapp = {J. Inst. Math. Appl.}}
@string{intcontrol = {Internat. J. Control}}
@string{interscience = {Interscience}}
@string{intnumereng = {Internat. J. Numer. Methods Engrg.}}
@string{intsuper = {Internat. J. Supercomputing Applic.}}
@string{jacm = {J. Assoc. Comput. Mach.}}
@string{jconvexanal = {J. Convex Anal.}}
@string{johnshopkinspress = {The Johns Hopkins University Press}}
@string{johnwileysons = {John Wiley and Sons}}
@string{jota = {J. Optim. Theory Appl.}}
@string{jresnatburstand = {J. Res. Nat. Bur. Standards}}
@string{jsiam = {J. Soc. Indust. Appl. Math.}}
@string{jsiamb = {J. Soc. Indust. Appl. Math. Ser. B Numer. Anal.}}
@string{kibernetika = {Kibernetika}}
@string{linalgapp = {Linear Algebra Appl.}}
@string{macmillan = {Macmillan}}
@string{managesci = {Mgmnt Sci.}}
@string{mathanaappl = {J. Math. Anal. Appl.}}
@string{mathannalen = {Math. Ann.}}
@string{mathcomp = {Math. Comp.}}
@string{mathofor = {Math. Op. Res.}}
@string{mathphys = {J. Math. Phys.}}
@string{mathprog = {Math. Program.}}
@string{mathprogb = {Math. Program., Ser. B}}
@string{mathprogc = {Math. Program. Comp.}}
@string{mathprogstudy = {Math. Program. Study}}
@string{mathscand = {Math. Scand.}}
@string{mathworks = {The Math Works Inc.}}
@string{mcgrawhill = {McGraw-Hill}}
@string{natburstd = {National Bureau of Standards}}
@string{northholland = {North-Holland}}
@string{numermath = {Numer. Math.}}
@string{optimmeth = {Optim. Methods Softw.}}
@string{oxfordpress = {Oxford University Press}}
@string{pacificmath = {Pacific J. Math.}}
@string{parcomputing = {Parallel Comput.}}
@string{pardistcomp = {J. Parallel and Distrib. Comput.}}
@string{pergamonpress = {Pergamon Press}}
@string{philmag = {Philos. Mag.}}
@string{plenumpress = {Plenum Press}}
@string{prenticehall = {Prentice-Hall}}
@string{procams = {Proc. Amer. Math. Soc.}}
@string{procieee = {Proc. {IEEE}}}
@string{procnas = {Proc.\@ Natl.\@ Acad.\@ Sci.\@ USA}}
@string{psychometrika = {Psychometrika}}
@string{quartapplmath = {Quart. Appl. Math.}}
@string{quartmath = {Quart. J. Math. Oxford Ser. (2)}}
@string{revueinststat = {Rev. Inst. Internat. Statist.}}
@string{scientific = {The Scientific Press}}
@string{siamalgmeth = {{SIAM} J. Algebraic Discrete Methods}}
@string{siamappmath = {{SIAM} J. Appl. Math.}}
@string{siamcomp = {{SIAM} J. Comput.}}
@string{siamcontrol = {{SIAM} J. Control Optim.}}
@string{siammath = {{SIAM} J. Math. Anal.}}
@string{siammatrix = {{SIAM} J. Matrix Anal. Appl.}}
@string{siammms = {Multiscale Model. Simul.}}
@string{siamnumanal = {{SIAM} J. Numer. Anal.}}
@string{siamopt = {{SIAM} J. Optim.}}
@string{siampub = {Society of Industrial and Applied Mathematics}}
@string{siamreview = {{SIAM} Rev.}}
@string{siamscicomp = {{SIAM} J. Sci. Comput.}}
@string{siamsiims = {{SIAM} J. Imag. Sci.}}
@string{signum = {{ACM} {SIGNUM} Newslett.}}
@string{softpracexp = {Software Prac. Experience}}
@string{springer = {Springer-Verlag}}
@string{stanford = {Stanford University Press}}
@string{statscience = {Statist. Sci.}}
@string{tablesaidscomp = {Math. Tables Aids Comput.}}
@string{techno = {Technometrics}}
@string{texaspress = {University of Texas Press}}
@string{transams = {Trans. Amer. Math. Soc.}}
@string{ussrcompmathphys = {{U. S. S. R.} Comput. Math. and Math. Phys.}}
@string{vannostrand = {Van Nostrand}}
@string{vlsicompsys = {J. {VLSI} Comput. Syst.}}
@string{whfreeman = {W. H. Freeman and Co.}}
@string{zangewmathmech = {Z. Angew. Math. Mech.}}
@string{zangewmathphys = {Z. Angew. Math. Phys.}}

@article{kleywegt2002sample,
  title =        {{The sample average approximation method for
                  stochastic discrete optimization}},
  author =       {Kleywegt, A.J. and Shapiro, A. and Homem-de-Mello,
                  T.},
  journal =      siamopt,
  volume =       12,
  number =       2,
  pages =        {479--502},
  year =         2002,
  publisher =    {Citeseer}
}

@incollection{Lovasz:1983,
  year =         1983,
  isbn =         {978-3-642-68876-8},
  booktitle =    {Mathematical Programming The State of the Art},
  editor =       {Bachem, Achim and Korte, Bernhard and Gr√∂tschel,
                  Martin},
  doi =          {10.1007/978-3-642-68874-4_10},
  title =        {Submodular functions and convexity},
  publisher =    {Springer Berlin Heidelberg},
  author =       {Lov\`asz, L.},
  pages =        {235-257},
  language =     {English}
}

@article{Chan:2012,
  year =         2012,
  issn =         {1615-3375},
  journal =      {Foundations of Computational Mathematics},
  volume =       12,
  number =       6,
  doi =          {10.1007/s10208-012-9135-7},
  title =        {The Convex Geometry of Linear Inverse Problems},
  url =          {http://dx.doi.org/10.1007/s10208-012-9135-7},
  publisher =    {Springer-Verlag},
  keywords =     {Convex optimization; Semidefinite programming;
                  Atomic norms; Real algebraic geometry; Gaussian
                  width; Symmetry; 52A41; 90C25; 90C22; 60D05; 41A45},
  author =       {Chandrasekaran, Venkat and Recht, Benjamin and
                  Parrilo, Pablo A. and Willsky, Alan S.},
  pages =        {805-849},
  language =     {English}
}


@article{10.1137/070697835,
  title =        {Guaranteed Minimum-Rank Solutions of Linear Matrix
                  Equations via Nuclear Norm Minimization},
  year =         2010,
  doi =          {DOI:10.1137/070697835},
  issn =         00361445,
  eissn =        10957200,
  journal =      siamreview,
  volume =       52,
  number =       3,
  pages =        {471-501},
  author =       {Benjamin Recht and Maryam Fazel and Pablo
                  A. Parrilo},
  keywords =     {rank; convex optimization; matrix norms; random
                  matrices; compressed sensing; semidefinite
                  programming; 90C25; 90C59; 15A52; },
  url =          {http://dx.doi.org/doi/10.1137/070697835},
}

@article{1993,
  title =        {Lagrange Multipliers and Optimality},
  author =       {Rockafellar, R. T.},
  journal =      {SIAM Review},
  volume =       35,
  number =       2,
  pages =        {pp. 183-238},
  url =          {http://www.jstor.org/stable/2133143},
  ISSN =         00361445,
  abstract =     {Lagrange multipliers used to be viewed as auxiliary
                  variables introduced in a problem of constrained
                  minimization in order to write first-order
                  optimality conditions formally as a system of
                  equations. Modern applications, with their emphasis
                  on numerical methods and more complicated side
                  conditions than equations, have demanded deeper
                  understanding of the concept and how it fits into a
                  larger theoretical picture. A major line of research
                  has been the nonsmooth geometry of one-sided tangent
                  and normal vectors to the set of points satisfying
                  the given constraints. Another has been the
                  game-theoretic role of multiplier vectors as
                  solutions to a dual problem. Interpretations as
                  generalized derivatives of the optimal value with
                  respect to problem parameters have also been
                  explored. Lagrange multipliers are now being seen as
                  arising from a general rule for the
                  subdifferentiation of a nonsmooth objective function
                  which allows black-and-white constraints to be
                  replaced by penalty expressions. This paper traces
                  such themes in the current theory of Lagrange
                  multipliers, providing along the way a free-standing
                  exposition of basic nonsmooth analysis as motivated
                  by and applied to this subject.},
  year =         1993
}

@Article{ABEV09,
  author =       "Jacob Abernethy and Francis Bach and Theodoros
                  Evgeniou and Jean-Philippe Vert",
  title =        "A new approach to collaborative filtering: operator
                  estimation with spectral regularization",
  journal =      "Journal of Machine Learning Research",
  year =         2009
}

@Article{AEP08,
  author =       "Andreas Argyriou and Theodoros Evgeniou and
                  Massimiliano Pontil",
  title =        "Convex multi-task feature learning",
  journal =      "Machine Learning",
  year =         2008,
  volume =       73,
  page =         {243--272}
}

@Inproceedings{AGY04,
  title =        "On the computational complexity of sensor network
                  localization",
  author =       "James Aspnes and David Goldenberg and Yang Richard
                  Yang",
  booktitle =    "Algorithmic Aspects of Wireless Sensor Networks:
                  First International Workshop, ALGOSENSORS 2004",
  address =      {Turku, Finland},
  series =       {Lecture Notes in Computer Science},
  volume =       3121,
  publisher =    "Springer-Verlag",
  year =         2004,
  month =        {July},
  pages =        {32--44}
}

@inbook{Abad:1967,
  Address =      {Amsterdam},
  Author =       {J. Abadie},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Editor =       {J. Abadie},
  Pages =        {19--36},
  Publisher =    NorthHolland,
  Title =        {Nonlinear Programming},
  Year =         1967
}

@Article{Alf00,
  author =       "A. Y. Alfakih",
  title =        "Graph rigidity via {Euclidean} distance matrices",
  journal =      "Linear Algebra and its Applications",
  year =         2000,
  volume =       310,
  page =         {149--165}
}

@article{AlizGold:2003,
  Author =       {F. Alizadeh and D. Goldfarb},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      MathProgB,
  Pages =        {3--51},
  Title =        {Second-order cone programming},
  Volume =       95,
  Year =         2003
}

@article{AltmGond:1999,
  Author =       {A. Altman and J. Gondzio},
  Date-Modified ={2007-09-07 10:48:13 -0700},
  Journal =      {Optim. Methods Softw.},
  Local-Url =
                  {file://localhost/Users/mpf/papers/AltmanGondzio99.pdf},
  Pages =        {275--302},
  Title =        {Regularized Symmetric Indefinite Systems in Interior
                  Point Methods for Linear and Quadratic Optimization},
  Volume =       11,
  Year =         1999
}

@article{Ande:1996,
  Author =       {Andersen, Knud D.},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Fjournal =     siamopt,
  Issn =         {1052-6234},
  Journal =      SIAMOpt,
  Number =       1,
  Pages =        {74--95},
  Title =        {An efficient {N}ewton barrier method for minimizing
                  a sum of {E}uclidean norms},
  Volume =       6,
  Year =         1996
}

@article{AndeChriConnOver:2000,
  Author =       {Andersen, Knud D. and Christiansen, Edmund and Conn,
                  Andrew R. and Overton, M. L.},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Issn =         {1064-8275},
  Journal =      siamscicomp,
  Number =       1,
  Pages =        {243--262},
  Title =        {An efficient primal-dual interior-point method for
                  minimizing a sum of {E}uclidean norms},
  Volume =       22,
  Year =         2000
}

@article{AndeElfv:1997,
  author =       {Lars-Erik Andersson and Tommy Elfving},
  title =        {A Constrained Procrustes Problem},
  publisher =    {SIAM},
  year =         1997,
  journal =      siammatrix,
  volume =       18,
  number =       1,
  pages =        {124-139},
  keywords =     {constrained matrices; convex cones; positive
                  semidefinite; Procrustes},
  url =          {http://link.aip.org/link/?SML/18/124/1},
  doi =          {10.1137/S0895479894277545}
}

@article{AndeRoosTerl:2003,
  Author =       {E. D. Anderson and C. Roos and T. Terlaky},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      MathProgB,
  Pages =        {249--277},
  Title =        {On implementing a primal-dual interior-point method
                  for conic quadratic optimization},
  Volume =       95,
  Year =         2003
}

@article{AndrBirgMartSchu:2006,
  Abstract =     {Two Augmented Lagrangian algorithms for solving KKT
                  systems are introduced. The algorithms differ in the
                  way in which penalty parameters are
                  updated. Possibly infeasible accumulation points are
                  characterized. It is proved that feasible limit
                  points that satisfy the Constant Positive Linear
                  Dependence constraint qualification are KKT
                  solutions. Boundedness of the penalty parameters is
                  proved under suitable assumptions. Numerical
                  experiments are presented.},
  Annote =       {Published online.},
  Author =       {R. Andreani and E. G. Birgin and J. M. Mart\'{i}nez
                  and M. L. Schuverdt},
  Journal =      {Math. Program. B},
  Local-Url =
                  {file://localhost/Users/mpf/papers/AndrBirgMartSchu06.pdf},
  Month =        {December},
  Title =        {Augmented Lagrangian methods under the constant
                  positive linear dependence constraint qualification},
  Year =         2008,
  pages =        {5--32},
  volume =       111,
  numbers =      {1--2}
}

@techreport{Anit:2000,
  Author =       {Mihai Anitescu},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Institution =  {Argonne National Laboratory},
  Number =       {ANL/MCS-P864-1200},
  Title =        {On solving mathematical programs with
                  complementarity constraints as nonlinear programs},
  Year =         2000
}

@Article{Anit:2006,
  author =       {M. Anitescu},
  title =        {Optimization-based simulation of nonsmooth rigid
                  multibody dynamics},
  journal =      mathprog,
  year =         2006,
  volume =       105,
  number =       1,
  pages =        {113--143}
}

@incollection{ArroSolo:1958,
  Address =      {Stanford, CA},
  Author =       {Kenneth J. Arrow and Robert M. Solow},
  Booktitle =    {Studies in Linear and Nonlinear Programming},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Editor =       {Kenneth J. Arrow and Leonid Hurwicz and Hirofumi
                  Uzawa},
  Pages =        {166--176},
  Publisher =    Stanford,
  Title =        {Gradient methods for constrained maxima, with
                  weakened assumptions},
  Year =         1958
}

@book{AuT03,
  Address =      {New York},
  Author =       {A. Auslender and M. Teboulle},
  Date-Modified ={2013-09-20},
  Publisher =    springer,
  Series =       {Springer Monographs in Mathematics},
  Title =        {Asymptotic Cones and Functions in Optimization and Variational Inequalities},
  Year =         2003
}

@Article{AuT05,
  author =       "A. Auslender and M. Teboulle",
  title =        "Interior projection-like methods for monotone
                  variational inequalities",
  journal =      "Mathematical Programming",
  year =         2005,
  volume =       104,
  page =         {39--68}
}

@Article{AuT06,
  author =       "A. Auslender and M. Teboulle",
  title =        "Interior Gradient and Proximal Methods for Convex
                  and Conic Optimization",
  journal =      siamopt,
  year =         2006,
  volume =       16,
  page =         {697--725}
}

@Article{Aus78,
  author =       "A. Auslender",
  editor =       "O. L. Mangazarian and R. R. Meyer and
                  S. M. Robinson",
  title =        "Minimisation sans contraintes de fonctions
                  localement lipschitziennes: Applications \`a la
                  programmation mi-convexe, mi-diff\'erentiable",
  journal =      "Nonlinear Programming",
  year =         1978,
  volume =       3,
  pages =        {429--460},
  publisher =    "Academic press",
  address =      "New York"
}

@article{vdDoelAscher:2011,
  author    = {Kees van den Doel and
               Uri M. Ascher},
  title     = {Adaptive and Stochastic Algorithms for Electrical Impedance
               Tomography and DC Resistivity Problems with Piecewise Constant
               Solutions and Many Measurements},
  journal   = siamcomp,
  volume    = {34},
  number    = {1},
  year      = {2012},
  ee        = {http://dx.doi.org/10.1137/110826692},
  bibsource = {DBLP, http://dblp.uni-trier.de}
}


@article{AvronToledo:2011,
  author =       {Avron, Haim and Toledo, Sivan},
  title =        {Randomized algorithms for estimating the trace of an
                  implicit symmetric positive semi-definite matrix},
  journal =      {J. ACM},
  issue_date =   {April 2011},
  volume =       58,
  issue =        2,
  month =        {April},
  year =         2011,
  issn =         {0004-5411},
  pages =        {8:1--8:34},
  articleno =    8,
  numpages =     34,
  url =          {http://doi.acm.org/10.1145/1944345.1944349},
  doi =          {http://doi.acm.org/10.1145/1944345.1944349},
  acmid =        1944349,
  publisher =    {ACM},
  address =      {New York, NY, USA},
  keywords =     {Trace estimation, implicit linear operators},
}

@article{LaiYin:2013,
  author =       {Lai, M. and Yin, W.},
  title =        {Augmented $\ell_1$ and Nuclear-Norm Models with a
                  Globally Linearly Convergent Algorithm},
  journal =      {SIAM Journal on Imaging Sciences},
  volume =       6,
  number =       2,
  pages =        {1059-1091},
  year =         2013,
  doi =          {10.1137/120863290},
  URL =          {http://epubs.siam.org/doi/abs/10.1137/120863290},
  eprint =       {http://epubs.siam.org/doi/pdf/10.1137/120863290}
}


@Inproceedings{BAY05,
  title =        "Semidefinite programming algorithms for sensor
                  network localization using angle of arrival
                  information",
  author =       "Pratik Biswas and Hamid Aghajan and Yinyu Ye",
  booktitle =    "39th Annual Asiloinar Conference on Signals,
                  Systems, and Computers",
  address =      "Pacific Grove, CA",
  year =         2005
}

@Article{BBC03,
  author =       "Heinz H. Bauschke and Jonathan M. Borwein and
                  Patrick L. Combettes",
  title =        "{Bregman} Monotone Optimization Algorithms",
  journal =      siamcontrol,
  year =         2003,
  volume =       42,
  number =       2,
  page =         {596--636}
}

@techreport{BBC09,
  title =        {NESTA: A Fast and Accurate First-order Method for
                  Sparse Recovery},
  author =       {S. Becker and J. Bobin and E. Cand\'es},
  institution =  {California Institute of Technology},
  type =         {Tech. Rep.},
  month =        {April},
  year =         2009
}

@Article{BDDW08,
  author =       {Richard Baraniuk and Mark Davenport and Ronald
                  DeVore and Michael Wakin },
  title =        {A Simple Proof of the Restricted Isometry Property
                  for Random Matrices},
  journal =      {Constructive Approximation},
  year =         2008,
  volume =       28,
  number =       3,
  pages =        {253--263},
  month =        {December}
}

@Article{BGD08,
  author =       "Onureena Banerjee and Laurent El Ghaoui and
                  Alexandre {\noopsort{Asprement}}{D'Aspremont}",
  title =        "Model Selection Through Sparse Maximum Likelihood
                  Estimation for Multivariate Gaussian or Binary Data",
  journal =      "J. Mach. Learn. Res.",
  year =         2008,
  volume =       9,
  page =         {485--516}
}

@Article{BHG07,
  author =       "Doron Blatt and Alfred O. Hero and Hillel Gauchman",
  title =        "A Convergent Incremental Gradient Method with a
                  Constant Step Size",
  journal =      siamopt,
  year =         2007,
  volume =       18,
  page =         {29--51}
}

@Article{BLTYW06,
  author =       "P. Biswas and Tzu-Chen Liang and Kim-Chuan Toh and
                  Ta-Chung Wang and Yinyu Ye",
  title =        "Semidefinite Programming Approaches for Sensor
                  Network Localization With Noisy Distance
                  Measurements",
  journal =      "Automation Science and Engineering, IEEE
                  Transactions",
  year =         2006,
  volume =       3,
  page =         {360--371}
}

@Article{BLWY06,
  author =       "Biswas, P. and Liang, T.-C. and Wang, T.-C. and Ye,
                  Y.",
  title =        "Semidefinite programming based algorithms for sensor
                  network localization",
  journal =      "ACM Transactions on Sensor Networks",
  year =         2006,
  volume =       2,
  page =         {188--220}
}

@Article{BT:2000,
  author =       {Dimitri P. Bertsekas and John N. Tsitsiklis},
  title =        {Gradient convergence in gradient methods with
                  errors},
  journal =      siamoptim,
  year =         2000,
  volume =       10,
  number =       3,
  pages =        {627-642}
}

@Article{BTY08,
  author =       "Biswas, P. and Toh, K.-C. and Ye, Y.",
  title =        "A Distributed {SDP} Approach for Large-Scale Noisy
                  Anchor-Free Graph Realization with Applications to
                  Molecular Conformation",
  journal =      siamcomp,
  year =         2008,
  volume =       30,
  number =       2,
  page =         {1251--1277}
}

@incollection{BachThibJord:2005,
  Address =      {San Mateo, CA},
  Author =       {F. R. Bach and R. Thibaux and M. I. Jordan},
  Booktitle =    {Advances in Neural Information Processing Systems
                  (NIPS) 17},
  Editor =       {L. Saul and Y. Weiss and L. Bottou},
  Publisher =    {Morgan Kaufmann},
  Title =        {Computing regularization paths for learning multiple
                  kernels},
  Year =         2005
}

@unpublished{BalaBuscGropKausKnep:2001,
  Author =       {Satish Balay and Kris Buschelman and William
                  D. Gropp and Dinesh Kaushik and Matt Knepley and
                  Lois Curfman McInnes and Barry F. Smith and Hong
                  Zhang},
  Note =         {http://www.mcs.anl.gov/petsc},
  Title =        {{PETSc} home page},
  Year =         2001
}

@techreport{BalaBuscGropKausKnep:2002,
  Author =       {Satish Balay and Kris Buschelman and William
                  D. Gropp and Dinesh Kaushik and Matt Knepley and
                  Lois Curfman McInnes and Barry F. Smith and Hong
                  Zhang},
  Institution =  {Argonne National Laboratory},
  Address =      {Argonne, IL},
  Number =       {ANL-95/11},
  Title =        {{PETSc} Users Manual Revision 2.1.3},
  Year =         2002,
  type =         {Tech. rep.}
}

@inproceedings{BalaGropMcInSmit:1997,
  Author =       {Satish Balay and William D. Gropp and Lois Curfman
                  McInnes and Barry F. Smith},
  Booktitle =    {Modern Software Tools for Scientific Computing},
  Editor =       {E. Arge and A. M. Bruaset and H. P. Langtangen},
  Pages =        {163--202},
  Publisher =    {Birkh\:{a}user Press},
  Address =      {Boston},
  Title =        {Efficient Management of Parallelism in
                  Object-Oriented Numerical Software Libraries},
  Year =         1997
}

@article{BarlTora:1995,
  Author =       {J. L. Barlow and G. Toraldo},
  Journal =      OptimMeth,
  Number =       3,
  Pages =        {235--245},
  Title =        {The effect of diagonal scaling on projected gradient
                  methods for bound constrained quadratic programming
                  problems},
  Volume =       5,
  Year =         1995
}

@article{BarzBorw:1988,
  Author =       {J. Barzilai and J. M. Borwein},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      IMANumerAna,
  Pages =        {141-148},
  Title =        {Two-point step size gradient methods},
  Volume =       8,
  Year =         1988
}

@Article{BeT03,
  author =       "Amir Beck and Marc Teboulle",
  title =        "Mirror descent and nonlinear projected subgradient
                  methods for convex optimization",
  journal =      "Operations Research Letters",
  year =         2003,
  volume =       31,
  page =         {167--175}
}

@Article{BeT06,
  author =       "Amir Beck and Marc Teboulle",
  title =        "A Linearly Convergent Dual-Based Gradient Projection
                  Algorithm for Quadratically Constrained Convex
                  Minimization",
  journal =      mathofor,
  year =         2006,
  volume =       31,
  number =       2,
  page =         {398--417},
  doi =          {10.1287/moor.1060.019}
}

@Techreport{BeT08,
  author =       "Amir Beck and Marc Teboulle",
  title =        "A Fast Iterative Shrinkage-Thresholding Algorithm
                  for Linear Inverse Problems",
  institution =  "Department of Industrial Engineering and Management,
                  Technion",
  address =      "Haifa",
  year =         2008
}

@inbook{Beal:1967,
  Address =      {Amsterdam},
  Author =       {E. M. L. Beale},
  Chapter =      7,
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Editor =       {J. Abadie},
  Publisher =    NorthHolland,
  Title =        {Nonlinear Programming},
  Year =         1967
}

@conference{HeilSchn:2005,
  Author =       {M. Heiler and C. Schnorr},
  Booktitle =    {Tenth IEEE International Conference on Computer
                  Vision},
  Date-Added =   {2007-09-27 11:25:06 -0700},
  Date-Modified ={2007-10-06 22:28:10 -0700},
  Month =        {October},
  Pages =        {1667-1674},
  Title =        {Learning non-negative sparse image codes by convex
                  programming},
  Volume =       {2},
  Year =         {2005}
}

@unpublished{Beaz:2001,
  Author =       {David M. Beazley},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Note =         {{\tt http://systems.cs.uchicago.edu/ply/}},
  Title =        {{PLY} {(Python Lex-Yacc)}},
  Year =         2001
}

@article{BeckBobiCand:2011,
  title =        {NESTA: A Fast and Accurate First-Order Method for
                  Sparse Recovery},
  publisher =    {SIAM},
  year =         2011,
  doi =          {DOI:10.1137/090756855},
  eissn =        19364954,
  coden =        {SJISBI},
  volume =       4,
  number =       1,
  pages =        {1-39},
  author =       {Stephen Becker and J√©r√¥me Bobin and Emmanuel
                  J. Cand√®s},
  keywords =     {Nesterov's method; smooth approximations of
                  nonsmooth functions; $\ell_1$ minimization; duality
                  in convex optimization; continuation methods;
                  compressed sensing; total-variation minimization;
                  90C06; 90C25; 94A08; },
  url =          {http://dx.doi.org/doi/10.1137/090756855},
}

@book{Ben-Nemi:2001,
  Address =      {Philadelphia},
  Author =       {A. Ben-Tal and A. Nemirovski},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Publisher =    SIAMPub,
  Series =       {MPS/SIAM Series on Optimization},
  Title =        {Lectures on Modern Convex Optimization: {A}nalysis,
                  Algorithms, and Engineering Applications},
  Volume =       2,
  Year =         2001
}

@InProceedings{BensCurfMoreSar:2004,
  author =       {S. J. Benson and L. Curfman McInnes and
                  J. J. Mor\'{e} and J. Sarich},
  title =        {Scalable Algorithms in Optimization: Computational
                  Experiments},
  year =         2004,
  booktitle =    {AIAA Multidisciplinary Analysis and Optimization},
  address =      {Albany, NY}
}

@techreport{BensSenShanVand:2003,
  Author =       {Hande Y. Benson and Arun Sen and David F. Shanno and
                  Robert J. Vanderbei},
  Institution =  {Operations Research and Financial Engineering,
                  Princeton University},
  Number =       {ORFE-03-02},
  Title =        {Interior-point algorithms, penalty methods and
                  equilibrium problems},
  Year =         2003
}

@misc{BensShan:2007,
  Author =       {H. Y. Benson and D. Shanno},
  Howpublished = {To appear in {\it Comp. Optim. Appl.}},
  Title =        {Interior-point methods for nonconvex nonlinear
                  programming: regularization and warmstarts},
  Year =         2007
}

@techreport{BensShanVand:2002,
  Author =       {Hande Y. Benson and David F. Shanno and Robert
                  J. Vanderbei},
  Institution =  {Operations Research and Financial Engineering,
                  Princeton University},
  Number =       {ORFE-02-02},
  Title =        {Interior-point methods for nonconvex nonlinear
                  programming: complementarity constraints},
  Year =         2002
}

@article{BenzGolu:2004,
  Abstract =     {In this paper we consider the solution of linear
                  systems of saddle point type by preconditioned
                  Krylov subspace methods. A preconditioning strategy
                  based on the symmetric/ skew-symmetric splitting of
                  the coefficient matrix is proposed, and some useful
                  properties of the preconditioned matrix are
                  established. The potential of this approach is
                  illustrated by numerical experiments with matrices
                  from various application areas.},
  Author =       {M. Benzi and G. H. Golub},
  Journal =      siammatrix,
  Number =       1,
  Pages =        {20-41},
  Title =        {A preconditioner for generalized saddle point
                  problems},
  Volume =       26,
  Year =         2004
}

@article{BenzGoluLies:2005,
  Author =       {M. Benzi and G. Golub and J. Liesen},
  Journal =      actanumerica,
  Month =        {April},
  Pages =        {1--137},
  Title =        {Numerical solution of saddle point problems},
  Volume =       14,
  Year =         2005
}

@PhdThesis{Berg:2009,
  author =       {E. van den Berg},
  title =        {Convex optimization for generalized sparse recovery},
  school =       {University of British Columbia},
  year =         2009,
  month =        {December}
}

@article{BergGondZill:2004,
  Author =       {Luca Bergamaschi and Jacek Gondzio and Giovanni
                  Zilli},
  Journal =      compapplopt,
  Month =        {July},
  Number =       2,
  Pages =        {149-171},
  Title =        {Preconditioning Indefinite Systems in Interior Point
                  Methods for Optimization},
  Volume =       28,
  Year =         2004
}

@book{Berman:1973,
  title =        {Cones, Matrices and Mathematical Programming},
  author =       {A. Berman},
  Series =       {Lecture Notes in Economics and Mathematical Systems},
  volume =    {79},
  year =         1973,
  publisher =    springer
}


@book{BermShak:2003,
  title =        {Completely positive matrices},
  author =       {A. Bermanand and N. Shaked-Monderer},
  year =         2003,
  publisher =    {World Scientific}
}

@article{Bert:1975,
  Author =       {D. P. Bertsekas},
  Journal =      MathProg,
  Pages =        {87--99},
  Title =        {Necessary and sufficient conditions for a penalty
                  method to be exact},
  Volume =       9,
  Year =         1975
}

@book{Bert:1982,
  Address =      {New York},
  Author =       {D. P. Bertsekas},
  Publisher =    Academic,
  Title =        {Constrained Optimization and {L}agrange Multiplier
                  Methods},
  Year =         1982
}

@book{Bert:1999,
  Address =      {Belmont, MA},
  Author =       {D. P. Bertsekas},
  Edition =      {Second},
  Publisher =    Athena,
  Title =        {Nonlinear Programming},
  Year =         1999
}

@book{Bert:2003,
  Address =      {Belmont, MA},
  Author =       {D. P. Bertsekas},
  Publisher =    Athena,
  Title =        {Convex Analysis and Optimization},
  Year =         2003
}

@article{NedBert:2000,
  title =        {Convergence rate of incremental subgradient
                  algorithms},
  author =       {Nedic, A. and Bertsekas, D.},
  journal =      {Stochastic Optimization: Algorithms and
                  Applications},
  pages =        {263--304},
  year =         2000,
  publisher =    {Kluwer Academic}
}


@Book{BertNediOzda:2003,
  author =       {D. P. Bertsekas and A. Nedic and A. E Ozdaglar},
  title =        {Convex analysis and optimization},
  publisher =    {Athena Scientific},
  year =         2003
}

@Book{BertTsit:1997,
  author =       {Dimitris Bertsimas and John N. Tsitsiklis},
  title =        {Introduction to Linear Optimization},
  publisher =    {Athena Scientific},
  year =         1997,
  address =      {Nashua, NH}
}

@article{BestBrauRittRobi:1981,
  Author =       {M. J. Best and J. Br{\"a}uninger and K. Ritter and
                  S. M. Robinson},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      Computing,
  Pages =        {141--155},
  Title =        {A Globally and Quadratically Convergent Algorithm
                  for General Nonlinear Programming Problems},
  Volume =       26,
  Year =         1981
}

@Inbook{BiY03,
  author =       "P. Biswas and Y. Ye",
  chapter =      "A Distributed Method for Solving Semidefinite
                  Programs Arising from Ad Hoc Wireless Sensor Network
                  Localization",
  title =        siammms,
  series =       "Nonconvex Optimization and Its Applications",
  publisher =    "Springer",
  year =         2003,
  volume =       82
}

@InProceedings{BiY04,
  author =       "Biswas, P. and Ye, Y.",
  title =        "Semidefinite programming for ad hoc wireless sensor
                  network localization",
  year =         2004,
  booktitle =    "The 3rd international symposium on information
                  processing in sensor networks",
  page =         {46--54}
}

@incollection{Bigg:1972,
  Address =      {London},
  Author =       {M. C. Biggs},
  Booktitle =    {Numerical Methods for Nonlinear Optimization},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Editor =       {F. A. Lootsma},
  Publisher =    Academic,
  Title =        {Constrained minimization using recursive equality
                  quadratic programming},
  Year =         1972
}

@article{BirgMartRayd:2000,
  Author =       {E. G. Birgin and J. M. Mart\'{i}nez and M. Raydan},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      SIAMOpt,
  Number =       4,
  Pages =        {1196-1211},
  Title =        {Nonmonotone spectral projected gradient methods on
                  convex sets},
  Volume =       10,
  Year =         2000
}

@article{BirgMartRayd:2001,
  Abstract =     {Fortran 77 software implementing the SPG method is
                  introduced. SPG is a nonmonotone projected gradient
                  algorithm for solving large-scale convex-constrained
                  optimization problems. It combines the classical
                  projected gradient method with the spectral gradient
                  choice of steplength and a nonmonotone line-search
                  strategy. The user provides objective function and
                  gradient values, and projections onto the feasible
                  set. Some recent numerical tests are reported on
                  very large location problems, indicating that SPG is
                  substantially more efficient than existing
                  general-purpose software on problems for which
                  projections can be computed efficiently.},
  Address =      {New York, NY, USA},
  Author =       {E. G. Birgin and J. M. Mart\'{i}nez and M. Raydan},
  Date-Added =   {2007-06-11 21:18:11 -0700},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Doi =          {http://doi.acm.org/10.1145/502800.502803},
  Issn =         {0098-3500},
  Journal =      acmmathsoft,
  Local-Url =
                  {file://localhost/Users/mpf/papers/BirgMartRayd01.pdf},
  Number =       3,
  Pages =        {340--349},
  Publisher =    {ACM Press},
  Title =        {Algorithm 813: {SPG}---{S}oftware for
                  Convex-Constrained Optimization},
  Volume =       27,
  Year =         2001
}

@article{BirgMartRayd:2003,
  Author =       {E. G. Birgin and J. M. Mart\'{i}nez and M. Raydan},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      IMANumerAna,
  Local-Url =    {file://localhost/Users/mpf/papers/BirgMartRad03.pdf},
  Pages =        {1196-1211},
  Title =        {Inexact spectral projected gradient methods on
                  convex sets},
  Volume =       23,
  Year =         2003
}

@article{BiroGhat:2005,
  Author =       {G. Biros and O. Ghattas},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Doi =          {10.1137/S106482750241565X},
  Journal =      siamscicomp,
  Keywords =     {sequential quadratic programming; nonlinear
                  equations; parallel algorithms; adjoint methods;
                  PDE-constrained optimization; optimal control;
                  Lagrange--Newton--Krylov--Schur methods;
                  Navier--Stokes; finite elements; preconditioners;
                  indefinite systems},
  Number =       2,
  Pages =        {687-713},
  Publisher =    {SIAM},
  Title =        {Parallel Lagrange--Newton--Krylov--Schur Methods for
                  PDE-Constrained Optimization. Part I: The
                  Krylov--Schur Solver},
  Url =          {http://link.aip.org/link/?SCE/27/687/1},
  Volume =       27,
  Year =         2005
}

@techreport{BiscCarlHovlKhadMaue:1998,
  Address =      {Argonne, IL},
  Author =       {Christian Bischof and Alan Carle and Paul Hovland
                  and Peyvand Khademi and Andrew Mauer},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Institution =  {Mathematics and Computer Science Division},
  Month =        {June},
  Number =       192,
  Title =        {{ADIFOR} 2.0 {Users' Guide}},
  Year =         1998
}

@article{BiscRohMaue:1997,
  Author =       {Christian Bischof and Lucas Roh and A. Mauer},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      {Software---Practice and Experience},
  Month =        {December},
  Number =       12,
  Pages =        {1427--1456},
  Title =        {{ADIC}: An Extensible Automatic Differentiation Tool
                  for {ANSI-C}},
  Volume =       27,
  Year =         1997
}

@book{Bjorck:1996,
  title =        {{Numerical Methods for Least Squares Problems}},
  author =       {Bj{\"o}rck, {\AA}.},
  year =         1996,
  publisher =    {Society for Industrial Mathematics}
}

@incollection{BoisPozoRemiBarrDong:1997,
  Address =      {London},
  Author =       {R. Boisvert and R. Pozo and K. Remington and
                  R. Barrett and J. Dongarra},
  Booktitle =    {The quality of numerical software: assessment and
                  enhancement},
  Editor =       {R. F. Boisvert},
  Pages =        {125--137},
  Publisher =    {Chapman \& Hall},
  Title =        {{Matrix Market}: {A} web resource for test matrix
                  collections},
  Year =         1997
}

@article{BongConnGoulToin:1995,
  Author =       {I. Bongartz and A. R. Conn and N. I. M. Gould and
                  {\mbox{Ph}}. L. Toint},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      ACMMathSoft,
  Month =        {March},
  Number =       1,
  Pages =        {123-160},
  Title =        {{CUTE}: Constrained and Unconstrained Testing
                  Environment},
  Volume =       21,
  Year =         1995
}

@book{BoydVand:2004,
  Address =      {Cambridge, UK},
  Author =       {Stephen Boyd and Lieven Vandenberghe},
  Date-Modified ={2007-07-26 16:36:59 -0700},
  Publisher =    CambridgePress,
  Title =        {Convex Optimization},
  Year =         2004
}

@techreport{Bran:1995,
  Address =      {Cornell Theory Center, Cornell University},
  Author =       {M. A. Branch},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Institution =  {Advanced Computing Research Institute},
  Month =        {September},
  Number =       {CTC94TR194},
  Title =        {Getting {CUTE} with \textsc{Matlab}},
  Year =         1995
}

@inproceedings{Brau:1977,
  Address =      {Berlin, New York},
  Author =       {J{\"u}rgen Br{\"a}uninger},
  Booktitle =    {Optimization Techniques, proceedings of the 8th
                  {IFIP} Conference, W{\"u}rzburg, Part 2, Lecture
                  Notes in Control and Inform. Sci.},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Pages =        {33-41},
  Publisher =    SPRINGER,
  Title =        {A Modification of {R}obinson's Algorithm for General
                  Nonlinear Programming Problems Requiring Only
                  Approximate Solutions of Subproblems with Linear
                  Equality Constraints},
  Year =         1977
}

@article{Brau:1981,
  Author =       {J{\"u}rgen Br{\"a}uninger},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      JOTA,
  Month =        {October},
  Number =       2,
  Pages =        {195-216},
  Title =        {A Globally Convergent Version of {R}obinson's
                  Algorithm for General Nonlinear Programming Problems
                  Without Using Derivatives},
  Volume =       35,
  Year =         1981
}

@Article{Bre67,
  author =       "L.M. Bregman",
  title =        "The Relaxation Method of Finding the Common Point of
                  Convex Sets and Its Application to the Solution of
                  Problems in Convex Programming ",
  journal =      "USSR Computational Mathematics and Mathematical
                  Physics",
  year =         1967,
  volume =       7,
  page =         {200--217}
}

@article{Bren:1972,
  Author =       {R. P. Brent},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      {IBM J. Research and Development},
  Note =         {email him for ref},
  Title =        {On the Davidenko-Branin method for solving
                  simultaneous nonlinear equations},
  Year =         1972
}

@article{BrenWinoWolf:1973,
  Author =       {R. P. Brent and S. Winograd and P. Wolfe},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      NumerMath,
  Pages =        {327-341},
  Title =        {Optimal iterative processes for rootfinding},
  Year =         1973
}

@article{BrodGourGree:1973,
  Author =       {K. W. Brodlie and A. R. Gourlay and J. Greenstadt},
  Journal =      instmathapp,
  Pages =        {73--82},
  Title =        {Rank-one and rank-two corrections to positive
                  definite matrices expressed in product form},
  Volume =       11,
  Number =       1,
  Year =         1973
}

@book{BrooKendMeer:1988,
  Address =      {Redwood City, CA},
  Author =       {A. Brooke and D. Kendrick and A. Meeraus},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Publisher =    Scientific,
  Title =        {{GAMS}: A User's Guide},
  Year =         1988
}

@article{Buck85,
  author =       {A. Buckley and A. {LeNir}},
  title =        {{BBVSCG}?îa variable storage algorithm for function
                  minimization},
  journal =      acmmathsoft,
  number =       11,
  year =         1985,
  pages =        {103??119}
}

@article{Rockafellar:1993,
  title =        {Lagrange Multipliers and Optimality},
  author =       {Rockafellar, R. T.},
  journal =      {SIAM Review},
  volume =       35,
  number =       2,
  pages =        {pp. 183-238},
  url =          {http://www.jstor.org/stable/2133143},
  ISSN =         00361445,
  abstract =     {Lagrange multipliers used to be viewed as auxiliary
                  variables introduced in a problem of constrained
                  minimization in order to write first-order
                  optimality conditions formally as a system of
                  equations. Modern applications, with their emphasis
                  on numerical methods and more complicated side
                  conditions than equations, have demanded deeper
                  understanding of the concept and how it fits into a
                  larger theoretical picture. A major line of research
                  has been the nonsmooth geometry of one-sided tangent
                  and normal vectors to the set of points satisfying
                  the given constraints. Another has been the
                  game-theoretic role of multiplier vectors as
                  solutions to a dual problem. Interpretations as
                  generalized derivatives of the optimal value with
                  respect to problem parameters have also been
                  explored. Lagrange multipliers are now being seen as
                  arising from a general rule for the
                  subdifferentiation of a nonsmooth objective function
                  which allows black-and-white constraints to be
                  replaced by penalty expressions. This paper traces
                  such themes in the current theory of Lagrange
                  multipliers, providing along the way a free-standing
                  exposition of basic nonsmooth analysis as motivated
                  by and applied to this subject.},
  year =         1993
}

@incollection{BuckDono:1995,
  Address =      {New York},
  Author =       {J. Buckheit and D. L. Donoho},
  Booktitle =    {Wavelets and Statistics},
  Editor =       {A. Anatoniadis},
  Publisher =    {Springer-Verlag},
  Title =        {{WaveLab} and reproducible research},
  Year =         1995
}

@article{BuckL83,
  author =       {A. Buckley and A. {LeNir}},
  title =        {{QN-like} variable storage conjugate gradients},
  journal =      MathProg,
  number =       27,
  year =         1983,
  pages =        {155-??75}
}

@article {BurerMont:2003,
  author =       {Burer, Samuel and Monteiro, Renato D.C.},
  affiliation =  {Department of Management Sciences, University of
                  Iowa, Iowa City, IA 52242-1000, e-mail:
                  burer@math.gatech.edu US},
  title =        {A nonlinear programming algorithm for solving
                  semidefinite programs via low-rank factorization},
  journal =      mathprog,
  pages =        {329-357},
  volume =       95,
  issue =        2,
  doi =         {10.1007/s10107-002-0352-8},
  abstract =     {In this paper, we present a nonlinear programming
                  algorithm for solving semidefinite programs (SDPs)
                  in standard form. The algorithm's distinguishing
                  feature is a change of variables that replaces the
                  symmetric, positive semidefinite variable X of the
                  SDP with a rectangular variable R according to the
                  factorization X = RR T . The rank of the
                  factorization, i.e., the number of columns of R , is
                  chosen minimally so as to enhance computational
                  speed while maintaining equivalence with the
                  SDP. Fundamental results concerning the convergence
                  of the algorithm are derived, and encouraging
                  computational results on some large-scale test
                  problems are also presented.},
  year =         2003
}

@article{Bure:2009,
  title =        {Optimizing a polyhedral-semidefinite relaxation of
                  completely positive programs},
  author =       {Sam Burer},
  journal =      {Journal Mathematical Programming Computation},
  volume =       2,
  number =       1,
  month =        {March},
  year =         2010,
  DOI =          {10.1007/s12532-010-0010-8},
  pages =        {1-19}
}

@article{Burk:1991,
  Author =       {J. V. Burke},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      siamcontrol,
  Number =       4,
  Pages =        {968--998},
  Title =        {An exact penalization viewpoint of constrained
                  optimization},
  Volume =       29,
  Year =         1991
}

@article{BurkDeng:2005,
  Author =       {J. V. Burke and S. Deng},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Issn =         {0025-5610},
  Journal =      MathProg,
  Mrclass =      {90C31 (49J52)},
  Mrnumber =     {MR2179237 (2006e:90125)},
  Number =       {2-3, Ser. B},
  Pages =        {235--261},
  Title =        {Weak sharp minima revisited. {II}. {A}pplication to
                  linear regularity and error bounds},
  Volume =       104,
  Year =         2005
}

@article{BurkFerr:1993,
  Author =       {J. V. Burke and M. C. Ferris},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      siamcontrol,
  Number =       5,
  Pages =        {1340--1359},
  Title =        {Weak sharp minima in mathematical programming},
  Volume =       31,
  Year =         1993
}

@article{BurkHan:1986,
  Author =       {J. Burke and {S.-P.} Han},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      mathofor,
  Month =        {November},
  Number =       4,
  Pages =        {632-643},
  Title =        {A {G}auss-{N}ewton Approach to Solving Generalized
                  Inequalities},
  Volume =       11,
  Year =         1986
}

@article{BurkMore:1994,
  Author =       {James V. Burke and Jorge J. Mor\'{e}},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      SIAMOpt,
  Month =        {August},
  Number =       3,
  Pages =        {573--595},
  Title =        {Exposing constraints},
  Volume =       4,
  Year =         1994
}

@techreport{Buso:1985,
  title =        {Handling degeneracy in a nonlinear L1 algorithm},
  author =       {Busovaca, S.},
  institution =  {Computer Science Department, University of Waterloo},
  type =         {Tech. Rep.},
  number =       {CS-85-34},
  year =         1985
}

@article{ByrdGoulNoceWalt:2004,
  Author =       {R. H. Byrd and N. I. M. Gould and J. Nocedal and
                  R. A. Waltz},
  Date-Modified ={2007-10-22 16:57:18 -0700},
  Journal =      mathprog,
  Number =       1,
  Pages =        {27--48},
  Title =        {An algorithm for nonlinear optimization using linear
                  programming and equality constrained subproblems},
  Volume =       100,
  Year =         2004
}

@techreport{ByrdGoulNoceWalt:2004b,
  Address =      {Northwestern University, Evanston, IL},
  Author =       {R. H. Byrd and N. I. M. Gould and J. Nocedal and
                  R. A. Waltz},
  Date-Modified ={2007-10-19 14:47:06 -0700},
  Institution =  {Optimization Technology Center},
  Number =       {OTC 5/2002},
  Title =        {On the convergence of successive linear programming
                  algorithms},
  Type =         {Tech. rep.},
  Year =         2004
}

@article{ByrdHribNoce:1999,
  Author =       {R. Byrd and M. E. Hribar and J. Nocedal},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      siamopt,
  Number =       4,
  Pages =        {877-900},
  Title =        {An Interior Point Method for Large Scale Nonlinear
                  Programming},
  Volume =       9,
  Year =         1999
}

@article{GouldToint:2010,
  author =       {N. I. M. Gould and Ph. L. Toint},
  title =        {Nonlinear programming without a penalty function or
                  a filter},
  journal =      mathprog,
  volume =       122,
  number =       1,
  year =         2010,
  page =         {155--196},
  note =         {Erratum: Math.\@ Prog.\@ B, 131(1-2) (2011)
                  pp.403-404}
}

@InCollection{ByrdNoceWalt:06,
  author =       {R. H. Byrd and J. Nocedal and R. A. Waltz},
  title =        {{KNITRO}: An Integrated Package for Nonlinear
                  Optimization},
  booktitle =    {Large-Scale Nonlinear Optimization},
  pages =        {35-59},
  publisher =    {Springer-Verlag},
  address =      {New York},
  year =         2006,
  editor =       {G. di Pillo and M. Roma}
}

@article{ByrdSchnShul:1987,
  Author =       {R. H. Byrd and R. B. Schnabel and G. A. Shultz},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      SIAMNumAnal,
  Month =        {October},
  Number =       5,
  Pages =        {1152-1170},
  Title =        {A Trust Region Algorithm for Nonlinearly Constrained
                  Optimization},
  Volume =       24,
  Year =         1987
}

@Techreport{CCS08,
  author =       "Jian-Feng Cai and Emmanuel J. Cand\'es and Zuowei
                  Shen",
  title =        "A singular value thresholding algorithm for matrix
                  completion",
  type =         "Report",
  institution =  "California Institute of Technology",
  address =      "Pasadena",
  month =        "September",
  URL =          {http://www.acm.caltech.edu/~emmanuel/papers/SVT.pdf},
  year =         2008
}

@article{CCS10,
  author =       "Jian-Feng Cai and Emmanuel J. Cand\'es and Zuowei
                  Shen",
  title =        "A Singular Value Thresholding Algorithm for Matrix
                  Completion",
  journal =      SIAMOpt,
  number =       20,
  pages =        {1956-1982},
  doi =          {10.1137/080738970},
  year =         2010
}

@article{CDS98,
  Author =       {S. S. Chen and D. L. Donoho and M. A. Saunders},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      siamscicomp,
  Number =       1,
  Pages =        {33-61},
  Publisher =    {SIAM},
  Title =        {Atomic decomposition by basis pursuit},
  Volume =       20,
  Year =         1998
}

@Article{CJSY06,
  author =       "Carter, Michael W. and Jin, Holly H. and Saunders,
                  Michael A. and Ye, Yinyu",
  title =        "Spaseloc: {A}n adaptive subproblem algorithm for
                  scalable wireless sensor network localization",
  journal =      siamopt,
  year =         2006,
  volume =       17,
  number =       4,
  page =         {1102--1128}
}

@article{CRT06a,
  Abstract =     {This paper considers the model problem of
                  reconstructing an object from incomplete frequency
                  samples. Consider a discrete-time signal f/spl
                  isin/C/sup N/ and a randomly chosen set of
                  frequencies /spl Omega/. Is it possible to
                  reconstruct f from the partial knowledge of its
                  Fourier coefficients on the set /spl Omega/? A
                  typical result of this paper is as follows. Suppose
                  that f is a superposition of |T| spikes f(t)=/spl
                  sigma//sub /spl tau//spl isin/T/f(/spl tau/)/spl
                  delta/(t-/spl tau/) obeying |T|/spl les/C/sub M//spl
                  middot/(log N)/sup -1/ /spl middot/ |/spl Omega/|
                  for some constant C/sub M/>0. We do not know the
                  locations of the spikes nor their amplitudes. Then
                  with probability at least 1-O(N/sup -M/), f can be
                  reconstructed exactly as the solution to the /spl
                  lscr//sub 1/ minimization problem. In short, exact
                  recovery may be obtained by solving a convex
                  optimization problem. We give numerical values for
                  C/sub M/ which depend on the desired probability of
                  success. Our result may be interpreted as a novel
                  kind of nonlinear sampling theorem. In effect, it
                  says that any signal made out of |T| spikes may be
                  recovered by convex programming from almost every
                  set of frequencies of size O(|T|/spl
                  middot/logN). Moreover, this is nearly optimal in
                  the sense that any method succeeding with
                  probability 1-O(N/sup -M/) would in general require
                  a number of frequency samples at least proportional
                  to |T|/spl middot/logN. The methodology extends to a
                  variety of other situations and higher
                  dimensions. For example, we show how one can
                  reconstruct a piecewise constant (one- or
                  two-dimensional) object from incomplete frequency
                  samples - provided that the number of jumps
                  (discontinuities) obeys the condition above - by
                  minimizing other convex functionals such as the
                  total variation of f.},
  Author =       {E. J. Cand\`{e}s and J. Romberg and T. Tao},
  Journal =      ieeetransinfo,
  Month =        {February},
  Number =       2,
  Pages =        {489-509},
  Title =        {Robust uncertainty principles: exact signal
                  reconstruction from highly incomplete frequency
                  information},
  Volume =       52,
  Year =         2006
}

@article{CRT06b,
  Author =       {E. J. Cand\`{e}s and J. Romberg and T. Tao},
  Journal =      {Comm. Pure Appl. Math.},
  Number =       8,
  Pages =        {1207-1223},
  Title =        {Stable Signal Recovery from Incomplete and
                  Inaccurate Measurements},
  Volume =       59,
  Year =         2006
}

@Misc{CVX:2009,
  author =       {M. Grant and S. Boyd},
  title =        {{CVX: Matlab} software for disciplined convex
                  programming (web page and software)},
  howpublished = {\url{http://stanford.edu/~boyd/cvx}},
  month =        {February},
  year =         2009
}

@misc{CaR08,
  Author =       {Emmanuel J. Cand\`{e}s and Benjamin Recht},
  Title =        {Exact matrix completion via convex optimization},
  URL =
                  {http://www.acm.caltech.edu/~emmanuel/papers/NoisyCompletion.pdf},
  Howpublished = {To appear in Found. of Comput. Math.},
  Year =         2008
}



@article{CaT05,
  Abstract =     {This paper considers a natural error correcting
                  problem with real valued input/output. We wish to
                  recover an input vector f/spl isin/R/sup n/ from
                  corrupted measurements y=Af+e. Here, A is an m by n
                  (coding) matrix and e is an arbitrary and unknown
                  vector of errors. Is it possible to recover f
                  exactly from the data y? We prove that under
                  suitable conditions on the coding matrix A, the
                  input f is the unique solution to the /spl lscr//sub
                  1/-minimization problem (/spl par/x/spl par//sub
                  /spl lscr/1/:=/spl Sigma//sub i/|x/sub i/|)
                  min(g/spl isin/R/sup n/) /spl par/y - Ag/spl
                  par//sub /spl lscr/1/ provided that the support of
                  the vector of errors is not too large, /spl
                  par/e/spl par//sub /spl lscr/0/:=|{i:e/sub i/ /spl
                  ne/ 0}|/spl les//spl rho//spl middot/m for some /spl
                  rho/>0. In short, f can be recovered exactly by
                  solving a simple convex optimization problem (which
                  one can recast as a linear program). In addition,
                  numerical experiments suggest that this recovery
                  procedure works unreasonably well; f is recovered
                  exactly even in situations where a significant
                  fraction of the output is corrupted. This work is
                  related to the problem of finding sparse solutions
                  to vastly underdetermined systems of linear
                  equations. There are also significant connections
                  with the problem of recovering signals from highly
                  incomplete measurements. In fact, the results
                  introduced in this paper improve on our earlier
                  work. Finally, underlying the success of /spl
                  lscr//sub 1/ is a crucial property we call the
                  uniform uncertainty principle that we shall describe
                  in detail.},
  Author =       {E. J. Cand\`{e}s and T. Tao},
  Journal =      ieeetransinfo,
  Month =        {December},
  Number =       12,
  Pages =        {4203-4215},
  Title =        {Decoding by linear programming},
  Volume =       51,
  Year =         2005
}

@article{CalvLewiReicSgal:2004,
  Abstract =     {Many numerical methods for the solution of ill-posed
                  problems are based on Tikhonov
                  regularization. Recently, Rojas and Steihaug
                  described a barrier method for computing nonnegative
                  Tikhonov-regularized approximate solutions of linear
                  discrete ill-posed problems. Their method is based
                  on solving a sequence of parameterized eigenvalue
                  problems. This paper describes how the solution of
                  parametrized eigenvalue problems can be avoided by
                  computing bounds that follow from the connection
                  between the Lanczos process, orthogonal polynomials
                  and Gauss quadrature.  },
  Author =       {Daniela Calvetti and Bryan Lewis and Lothar Reichel
                  and Fiorella Sgallari},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      {Electronic Transactions on Numerical Analysis},
  Keywords =     {Ill-posed problem, inverse problem, solution
                  constraint, Lanczos methods, Gauss quadrature},
  Pages =        {153--173},
  Title =        {Tikhonov regularization with nonnegativity
                  constraint},
  Volume =       18,
  Year =         2004
}

@article{Can08,
  title =        {The restricted isometry property and its
                  implications for compressed sensing},
  author =       {Cand\`es, E.J.},
  journal =      {Comptes rendus-Math{\'e}matique},
  volume =       346,
  number =       {9-10},
  pages =        {589--592},
  year =         2008
}

@article{CanR:2009,
  author =       "Emmanuel J. Candes and Ben Recht",
  title =        "Exact Matrix Completion via Convex Optimization",
  volume =       9,
  year =         2009,
  pages =        {717-772}
}

@inproceedings{Cand:2006,
  Author =       {E. J. Cand\`{e}s},
  Booktitle =    {Proceedings of the International Congress of
                  Mathematicians},
  Location =     {Madrid, Spain},
  Title =        {Compressive sampling},
  Year =         2006
}

@article{CandDemaDonoYing:2005,
  Author =       {E. J. Cand\`{e}s and L. Demanet and D. L. Donoho and
                  L.-X. Ying},
  Title =        {Fast discrete curvelet transforms},
  Journal =      siammms,
  Volume =       5,
  Pages =        {861--899},
  Year =         2005
}

@article{CandPlan:2010,
  Author =       {Emmanuel J. Cand\`{e}s and Yaniv Plan},
  Title =        {Matrix completion with noise},
  journal =      {Proc. IEEE},
  Year =         2010,
  pages =        {925-936},
  volume =       98,
  doi =          {10.1109/JPROC.2009.2035722}
}

@misc{CandRomb:2007,
  Author =       {E. J. Cand\`{e}s and J. Romberg},
  Date-Modified ={2007-07-26 16:37:57 -0700},
  Howpublished = {\url{http://www.l1-magic.org/}},
  Title =        {{$\ell_1$-magic}},
  Year =         2007
}

@article{CandTao:2006,
  Author =       {E. J. Cand\`{e}s and T. Tao},
  Doi =          {10.1109/TIT.2006.885507},
  Journal =      ieeetransinfo,
  Month =        {December},
  Number =       12,
  Pages =        {5406--5425},
  Title =        {Near-optimal signal recovery from random
                  projections: Universal encoding strategies?},
  Volume =       52,
  Year =         2006
}

@misc{CandTao:2009,
  Author =       {Emmanuel J. Cand\`{e}s and Terence Tao},
  Title =        {The power of convex relaxation: near-optimal matrix
                  completion},
  URL =
                  {http://www.acm.caltech.edu/~emmanuel/papers/NoisyCompletion.pdf},
  Howpublished = {Submitted},
  Month =        {March},
  Year =         2009
}

@article{CandesTao:2010,
  Author =       {Emmanuel J. Cand\`{e}s and Terence Tao},
  Title =        {The power of convex relaxation: near-optimal matrix
                  completion},
  Year =         2010,
  journal =      ieeetransinfo,
  month =        {May},
  pages =        {2053-2080},
  doi =          {10.1109/TIT.2010.2044061},
  volume =       56
}

@TechReport{CandWakiBoyd:2007tr,
  author =       {Cand\'es, E. J. and Wakin, M. B. and Boyd, S. P.},
  title =        {Enhancing Sparsity by Reweighted {L1} Minimization},
  institution =  {California Institute of Technology},
  year =         2007,
  month =        {October},
  Note =         {Available at
                  \url{http://www.acm.caltech.edu/~emmanuel/papers/rwl1-oct2007.pdf}},
}

@Article{CandWakiBoyd:2008,
  author =       {E. J. Cand\'es and M. B. Wakin and S. P. Boyd},
  title =        {Enhancing sparsity by reweighted {L1} minimization},
  journal =      {J. Fourier Anal. Appl.},
  year =         2008,
  volume =       14,
  number =       5,
  pages =        {877--905},
  doi =          {10.1007/s00041-008-9045-x}
}

@Techreport{Candes2008,
  author =       "Candes, E. J. and Recht, B.",
  title =        "Exact Matrix Completion via Convex Optimization",
  institution =  "California Institute of Technology",
  address =      "Pasadena",
  month =        "May",
  year =         2008
}

@inproceedings{Gleich-2011-skew-nuclear,
  author = {Gleich, David F. and Lim, Lek-Heng},
  title = {Rank aggregation via nuclear norm minimization},
  booktitle = {Proceedings of the 17th ACM SIGKDD international conference on Knowledge
	discovery and data mining},
  year = 2011,
  series = {KDD '11},
  pages = {60--68},
  address = {New York, NY, USA},
  publisher = {ACM},
  abstract = {The process of rank aggregation is intimately intertwined with the
	structure of skew-symmetric matrices. We apply recent advances in
	the theory and algorithms of matrix completion to skew-symmetric
	matrices. This combination of ideas produces a new method for ranking
	a set of items. The essence of our idea is that a rank aggregation
	describes a partially filled skew-symmetric matrix. We extend an
	algorithm for matrix completion to handle skew-symmetric data and
	use that to extract ranks for each item. Our algorithm applies to
	both pairwise comparison and rating data. Because it is based on
	matrix completion, it is robust to both noise and incomplete data.
	We show a formal recovery result for the noiseless case and present
	a detailed study of the algorithm on synthetic data and Netflix ratings.},
  acmid = 2020425,
  doi = {10.1145/2020408.2020425},
  file = {:Gleich 2011 - rank aggregation.pdf},
  isbn = {978-1-4503-0813-7},
  keywords = {self, nuclear norm, rank aggregation, skew symmetric},
  location = {San Diego, California, USA},
  numpages = 9,
  owner = {David F. Gleich},
  timestamp = {2010.01.30}
}

@inproceedings{CandesRomberg:2006,
  Author =       {E. J. Cand\`{e}s and J. Romberg},
  Booktitle =    {Computational Imaging III, Proc. SPIE Conf.},
  Title =        {Practical Signal Recovery from Random Projections},
  Editors =      {Charles A. Bouman, Eric L. Miller},
  volume =       5914,
  pages =        {76--86},
  month =        {March},
  year =         2005
}

@Book{CeZ97,
  author =       "Censor, Y. and Zenios, S.",
  title =        "Parallel Optimization: Theory, Algoritluns, and
                  Applications",
  publisher =    "Oxford University Press",
  year =         1997,
  address =      "New York"
}

@Article{ChT93,
  author =       {Chen, G. and Teboulle, M.},
  title =        {Convergence analysis of a proximal-like minimization
                  algorithm using {B}regman functions},
  journal =      siamopt,
  year =         1993,
  pages =        {538--543}
}

@article{ChaSanParWil11,
  Author =       {V. Chandrasekaran and S. Sanghavi and P. P. Parrilo
                  and A. S. Willsky},
  Title =        {Rank-Sparsity Incoherence for Matrix Decomposition},
  Journal =      siamopt,
  Year =         2011,
  number =       2,
  volume =       21,
  pages =        {572-596},
  doi =          {10.1137/090761793},
  Abstract =     {Suppose we are given a matrix that is formed by
                  adding an unknown sparse matrix to an unknown
                  low-rank matrix. Our goal is to decompose the given
                  matrix into its sparse and low-rank components. Such
                  a problem arises in a number of applications in
                  model and system identification, and is NP-hard in
                  general. In this paper we consider a convex
                  optimization formulation to splitting the specified
                  matrix into its components, by minimizing a linear
                  combination of the $\ell_1$ norm and the nuclear
                  norm of the components. We develop a notion of
                  rank-sparsity incoherence, expressed as an
                  uncertainty principle between the sparsity pattern
                  of a matrix and its row and column spaces, and use
                  it to characterize both fundamental identifiability
                  as well as (deterministic) sufficient conditions for
                  exact recovery. Our analysis is geometric in nature,
                  with the tangent spaces to the algebraic varieties
                  of sparse and low-rank matrices playing a prominent
                  role. When the sparse and low-rank matrices are
                  drawn from certain natural random ensembles, we show
                  that the sufficient conditions for exact recovery
                  are satisfied with high probability. We conclude
                  with simulation results on synthetic matrix
                  decomposition problems.}
}

@article{ChamDevoLeeLuci:1998,
  Author =       {Chambolle, A. and De Vore, R.A. and Nam-Yong Lee and
                  Lucier, B.J.},
  Date-Added =   {2008-01-06 20:42:42 -0800},
  Date-Modified ={2008-01-08 20:52:36 -0800},
  Doi =          {10.1109/83.661182},
  Issn =         {1057-7149},
  Journal =      ieeetransimagproc,
  Keywords =     {Gaussian noise, data compression, image coding,
                  image representation, minimisation, parameter
                  estimation, transform coding, wavelet
                  transformsGaussian noise, SNR, SureShrink method,
                  accurate error bounds, approximate minimizers,
                  coding error, dyadic level, exact minimizers,
                  experimental results, i.i.d. noise, image
                  compression, mean zero noise, near-optimal shrinkage
                  parameters, noise removal, nonlinear wavelet image
                  processing, parameter estimation, shrinkage
                  parameters, signal-to-noise ratio, variational
                  problems, visual perception, wavelet based image
                  processing algorithms, wavelet representation,
                  wavelet shrinkage},
  Month =        {March},
  Number =       3,
  Pages =        {319-335},
  Title =        {Nonlinear wavelet image processing: variational
                  problems, compression, and noise removal through
                  wavelet shrinkage},
  Volume =       7,
  Year =         1998
}

@article{ChanMoraBaraMitt:2008,
  author =       {W. L. Chan and M. L. Moravec and R. G. Baraniuk and
                  D. M. Mittleman},
  journal =      {Opt. Lett.},
  keywords =     {Ultrafast measurements; Terahertz imaging},
  number =       9,
  pages =        {974--976},
  publisher =    {OSA},
  title =        {Terahertz imaging with compressed sensing and phase
                  retrieval},
  volume =       33,
  year =         2008,
  url =
                  {http://www.opticsinfobase.org/abstract.cfm?URI=ol-33-9-974},
}

@INPROCEEDINGS{ChartrandYin:2008,
  author =       {Chartrand, R. and Wotao Yin},
  booktitle =    {Acoustics, Speech and Signal Processing,
                  2008. ICASSP 2008. IEEE International Conference on},
  title =        {Iteratively reweighted algorithms for compressive
                  sensing},
  year =         2008,
  month =        {31 2008-april 4},
  pages =        {3869 -3872},
  keywords =     {compressive sensing theory;iteratively reweighted
                  algorithm;reweighted least-squares algorithm;signal
                  reconstruction;iterative methods;least squares
                  approximations;signal reconstruction;},
  doi =          {10.1109/ICASSP.2008.4518498},
  ISSN =         {1520-6149},
}

@article{ChenDonoSaun:2001,
  Author =       {S. S. Chen and D. L. Donoho and M. A. Saunders},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      SIAMReview,
  Number =       1,
  Pages =        {129--159},
  Title =        {Atomic decomposition by basis pursuit},
  Volume =       43,
  Year =         2001
}

@article{ChenHuo:2006,
  Author =       {J. Chen and X. Huo},
  Title =        {Theoretical Results on Sparse Represenations of
                  Multiple-Measurement Vectors},
  Journal =      ieeetranssigproc,
  Volume =       54,
  Issue =        12,
  Year =         2006,
  Pages =        {4634--4643}
}

@techreport{ChinFlet:2001,
  Address =      {UK},
  Author =       {C.M. Chin and R. Fletcher},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Institution =  {Department of Mathematics, University of Dundee},
  Number =       {NA/199},
  Title =        {On the Global Convergence of an {SLP}-Filter
                  Algorithm that takes {EQP} steps},
  Type =         {Numerical Analysis Report},
  Year =         2001
}

@article{ChinFlet:2003,
  Author =       {C.M. Chin and R. Fletcher},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      MathProg,
  Number =       1,
  Pages =        {161--177},
  Title =        {On the Global Convergence of an {SLP}-Filter
                  Algorithm that takes {EQP} steps},
  Volume =       96,
  Year =         2003
}

@article{ColeHulb:1989,
  Author =       {T. F. Coleman and L. A. Hulbert},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      {Math. Program., Series~B},
  Number =       3,
  Pages =        {373--406},
  Title =        {A direct active set algorithm for large sparse
                  quadratic programs with simple bounds},
  Volume =       45,
  Year =         1989
}

@article{ColeLi:1996,
  Abstract =     {We propose a new algorithm, a reflective Newton
                  method, for the minimization of a quadratic function
                  of many variables subject to upper and lower bounds
                  on some of the variables.  The method applies to a
                  general (indefinite) quadratic function for which a
                  local minimum subject to bounds is required and is
                  particularly suitable for the large-scale
                  problem. Our new method exhibits strong convergence
                  properties and global and second-order convergence
                  and appears to have significant practical
                  potential. Strictly feasible points are
                  generated. We provide experimental results on
                  moderately large and sparse problems based on both
                  sparse Cholesky and preconditioned conjugate
                  gradient linear solvers.},
  Author =       {T. F. Coleman and Y. Li},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      siamopt,
  Number =       4,
  Pages =        {1040--1058},
  Title =        {A Reflective {N}ewton Method for Minimizing a
                  Quadratic Function Subject to Bounds on Some of the
                  Variables},
  Volume =       6,
  Year =         1996
}

@Article{ComWaj2005,
  author =       {Patrick L. Combettes and Val\'erie R. Wajs},
  title =        {Signal recovery by proximal forward-backward
                  splitting},
  journal =      siammms,
  year =         2005,
  volume =       4,
  number =       4,
  pages =        {1168-1200}
}

@article{ConnGoulSartToin:1996,
  Author =       {A. R. Conn and N. I. M. Gould and A. Sartenaer and
                  {\mbox{Ph}}. L. Toint},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      siamopt,
  Month =        {August},
  Number =       3,
  Pages =        {674-703},
  Title =        {Convergence properties of an augmented {L}agrangian
                  algorithm for optimization with a combination of
                  general equality and linear constraints},
  Volume =       6,
  Year =         1996
}

@article{ConnGoulToin:1988,
  author =       {A. R. Conn and N. I. M. Gould and
                  \mbox{Ph}. L. Toint},
  Abstract =     {We describe the results of a series of tests upon a
                  class of new methods of trust region type for
                  solving the simple bound constrained minimization
                  problem. The results are encouraging and lead us to
                  believe that the method will prove useful in solving
                  large problems.},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  journal =      mathcomp,
  Pages =        {399--430},
  Summary =      {The results of tests on the trust-region methods
                  proposed by \citebb{ConnGoulToin88a} for solving the
                  bound constrained minimization problem are
                  discussed.},
  title =        {Testing a class of methods for solving minimization
                  problems with simple bounds on the variables},
  Volume =       50,
  year =         1988
}

@article{ConnGoulToin:1991,
  Author =       {A. R. Conn and N. I. M. Gould and
                  {\mbox{Ph}}. L. Toint},
  Journal =      siamnumanal,
  Month =        {April},
  Number =       2,
  Pages =        {545--572},
  Title =        {A Globally Convergent Augmented {L}agrangian
                  Algorithm for Optimization with General Constraints
                  and Simple Bounds},
  Volume =       28,
  Year =         1991
}

@book{ConnGoulToin:1992,
  Address =      {Berlin},
  Author =       {A. R. Conn and N. I. M. Gould and
                  {\mbox{Ph}}. L. Toint},
  Date-Modified ={2007-10-22 16:04:53 -0700},
  Publisher =    SPRINGER,
  Series =       {Springer Series in Computational Mathematics},
  Title =        {{\sf LANCELOT}: a {F}ortran package for Large-scale
                  Nonlinear Optimization ({R}elease {A})},
  Year =         1992
}

@inproceedings{ConnGoulToin:1992a,
  Author =       {A. R. Conn and N. I. M. Gould and
                  {\mbox{Ph}}. L. Toint},
  Booktitle =    {Numerical Analysis 1991, Pitman Res. Notes
                  Math. Ser.},
  Date-Modified ={2007-10-13 18:35:11 -0700},
  Editor =       {D. F. Griffiths and G. A. Watson},
  Pages =        {49--68},
  Publisher =    {Longman Scientific {\&} Technical, Harlow, UK},
  Title =        {On the number of inner iterations per outer
                  iteration of a globally convergent algorithm for
                  optimization with general nonlinear equality
                  constraints and simple bounds},
  Year =         1992
}

@article{ConnGoulToin:1997,
  Abstract =     {This paper considers the number of inner iterations
                  required per outeriteration for the algorithm
                  proposed by Conn et al.{$[$}9{$]$}. We show that
                  asymptotically, under suitable reasonable
                  assumptions, a single inner iteration suffices.},
  Author =       {A. R. Conn and N. Gould and {\mbox{Ph}}. L. Toint},
  Date-Added =   {2007-10-13 18:38:05 -0700},
  Date-Modified ={2007-10-22 16:05:40 -0700},
  Journal =      {Computational Optimization and Applications},
  M3 =           {10.1023/A:1008667728545},
  Number =       1,
  Pages =        {41--69},
  Title =        {On the Number of Inner Iterations Per Outer
                  Iteration of a Globally Convergent Algorithm for
                  Optimization with General Nonlinear Inequality
                  Constraints and Simple Bounds},
  Ty =           {JOUR},
  Url =          {http://dx.doi.org/10.1023/A:1008667728545},
  Volume =       7,
  Year =         1997
}

@book{ConnGoulToin:2000,
  Address =      {Philadelphia},
  Author =       {A. R. Conn and N. I. M. Gould and
                  {\mbox{Ph}}. L. Toint},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Publisher =    SIAMpub,
  Series =       {{MPS-SIAM} Series on Optimization},
  Title =        {Trust-Region Methods},
  Year =         2000
}

@TechReport{ConnSinc:1975,
  author =       {A. R. Conn and J. W. Sinclair},
  title =        {Quadratic programming via a nondifferentiable
                  penalty function},
  institution =  {Faculty of Mathematics, University of Waterloo,
                  Waterloo},
  year =         1975,
  type =         {Tech. Rep.},
  number =       {CORR 75/15}
}

@book{CormLeisRiveStei:2001,
  Address =      {Cambridge, Massachussetts},
  Author =       {Thomas H. Cormen and Charles E. Leiserson and Ronald
                  L. Rivest and Clifford Stein},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Edition =      {Second},
  Month =        {September},
  Publisher =    {MIT Press},
  Title =        {Introduction to Algorithms},
  Year =         2001
}

@article{CottRaoEngaKreu:2005,
  Author =       {S. F. Cotter and B. D. Rao and K. Engan and
                  K. Kreutz-Delgado},
  Title =        {Sparse Solutions to Linear Inverse Problems with
                  Multiple Measurement Vectors},
  Journal =      ieeetranssigproc,
  Volume =       53,
  Issue =        7,
  Year =         2005,
  Pages =        {2477--2488}
}

@article{Cour:1943,
  Author =       {Richard Courant},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      BullAMS,
  Pages =        {1--23},
  Title =        {Variational methods for the solution of problems
                  with equilibrium and variation},
  Volume =       49,
  Year =         1943
}

@book{CoveThom:1991,
  Address =      {New York},
  Author =       {Thomas Cover and Joy Thomas},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Publisher =    {Wiley},
  Title =        {Elements of Information Theory},
  Year =         1991
}

@misc{Curvelet,
  Author =       {E. J. Cand\`{e}s and L. Demanet and D. L. Donoho and
                  L.-X. Ying},
  Howpublished = {\url{http://www.curvelet.org/}},
  Title =        {{CurveLab}},
  Year =         2007
}

@Article{DBG08,
  author =       "{\noopsort{Asprement}}{D'Aspremont}, A. and Onureena
                  Banerjee and Laurent El Ghaoui",
  title =        "First-order methods for sparse covariance selection",
  journal =      siammatrix,
  year =         2008,
  volume =       30,
  number =       1,
  pages =        "56--66"
}

@article{DDD04,
  Author =       {I. Daubechies and M. Defrise and C. De Mol},
  Issue =        11,
  Journal =      {Comm. Pure Appl. Math.},
  Pages =        {1413--1457},
  Title =        {An iterative thresholding algorithm for linear
                  inverse problems with a sparsity constraint},
  Volume =       57,
  Year =         2004
}

@article{DET06,
  Author =       {D. L. Donoho and M. Elad and V. Temlyakov},
  Journal =      ieeetransinfo,
  Number =       1,
  Pages =        {6-18},
  Title =        {Stable Recovery of Sparse Overcomplete
                  Representations in the Presence of Noise},
  Volume =       52,
  Year =         2006
}

@Techreport{DKQW08,
  author =       "Ding, Y. and Krislock, N. and Qian, J. and
                  Wolkowicz, H.",
  title =        "Sensor Network Localization, Euclidean Distance
                  Matrix Completions, and Graph Realization",
  institution =  "Department of Combinatorics and Optimization,
                  University of Waterloo",
  address =      "Waterloo",
  month =        "February",
  year =         2008
}

@InProceedings{DPE01,
  author =       "Doherty, L. and Pister, K. S. J. and El Ghaoui, L.",
  title =        "Convex position estimation in wireless sensor
                  networks",
  year =         2001,
  booktitle =    "20th INFOCOM",
  volume =       3,
  page =         {1655--1663},
}

@misc{DST07,
  Author =       {David L. Donoho and V. C. Stodden and Yaakov Tsaig},
  Howpublished = {\url{http://sparselab.stanford.edu/}},
  Title =        {Sparselab},
  Year =         2007
}

@techreport{DTDS06,
  Author =       {David L. Donoho and Yaakov Tsaig and Iddo Drori and
                  Jean-Luc Starck},
  Title =        {Sparse Solution of Underdetermined Linear Equations
                  by Stagewise Orthogonal Matching Pursuit},
  Institution =  {Dept. of Statistics, Stanford University},
  Number =       {2006-2},
  Month =        {April},
  Url =          {http://www-stat.stanford.edu/~idrori/StOMP.pdf,
                  http://www-stat.stanford.edu/reports/abstracts/06-02.pdf},
  Year =         2006
}

@TechReport{DaG08,
  author =       {M. E. Davies and R. Gribonval},
  title =        {Restricted isometry constants where $\ell^p$ sparse
                  recovery can fail for $0<p\le1$},
  institution =  {Institut de Recherche en Informatique et Syst\'emes
                  Al\'eatoires},
  year =         2008,
  type =         {Publication interne},
  number =       1899,
  month =        {July}
}

@Article{DaW80,
  author =       "Dasarathy, B. and White, L. J.",
  title =        "A maxmin location problem",
  journal =      "Oper. Res.",
  year =         1980,
  volume =       28,
  number =       6,
  page =         {1385--1401}
}

@article{DaiFlet:2005,
  Author =       {Y.-H. Dai and R. Fletcher},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      NumerMath,
  Pages =        {21-47},
  Title =        {Projected {B}arzilai-{B}orwein methods for
                  large-scale box-constrained quadratic programming},
  Volume =       100,
  Year =         2005
}

@article{DaiHageSchitZhan:2006,
  Author =       {Y. Dai and W. W. Hager and K. Schittkowski and
                  H. Zhang},
  Date-Added =   {2008-01-10 11:07:30 -0800},
  Date-Modified ={2008-01-10 11:08:16 -0800},
  Title =        {The cyclic {Barzilai-Borwein} method for
                  unconstrained optimization},
  journal =      imanumerana,
  year =         2006,
  Volume =       7,
  pages =        {604--627}
}

@article{Dani:1973,
  Author =       {James W. Daniel},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      NumerMath,
  Pages =        {381-387},
  Title =        {{N}ewton's {M}ethod for Nonlinear Inequalities},
  Volume =       21,
  Year =         1973
}

@book{Dantzig:1998,
  abstract =     {In real-world problems related to finance, business,
                  and management, mathematicians and economists
                  frequently encounter optimization problems. In this
                  classic book, George Dantzig looks at a wealth of
                  examples and develops linear programming methods for
                  their solutions. He begins by introducing the basic
                  theory of linear inequalities and describes the
                  powerful simplex method used to solve
                  them. Treatments of the price concept, the
                  transportation problem, and matrix methods are also
                  given, and key mathematical concepts such as the
                  properties of convex sets and linear vector spaces
                  are covered.  George Dantzig is properly acclaimed
                  as the "father of linear programming." Linear
                  programming is a mathematical technique used to
                  optimize a situation. It can be used to minimize
                  traffic congestion or to maximize the scheduling of
                  airline flights. He formulated its basic theoretical
                  model and discovered its underlying computational
                  algorithm, the "simplex method," in a pathbreaking
                  memorandum published by the United States Air Force
                  in early 1948. {\it Linear Programming and
                  Extensions} provides an extraordinary account of the
                  subsequent development of his subject, including
                  research in mathematical theory, computation,
                  economic analysis, and applications to industrial
                  problems. Dantzig first achieved success as a
                  statistics graduate student at the University of
                  California, Berkeley. One day he arrived for a class
                  after it had begun, and assumed the two problems on
                  the board were assigned for homework. When he handed
                  in the solutions, he apologized to his professor,
                  Jerzy Neyman, for their being late but explained
                  that he had found the problems harder than
                  usual. About six weeks later, Neyman excitedly told
                  Dantzig, "I've just written an introduction to one
                  of your papers. Read it so I can send it out right
                  away for publication." Dantzig had no idea what he
                  was talking about. He later learned that the
                  "homework" problems had in fact been two famous
                  unsolved problems in statistics.},
  author =       {Dantzig, George B.},
  isbn =         0691059136,
  keywords =     {linear, programming},
  month =        {August},
  publisher =    {Princeton University Press},
  title =        {Linear Programming and Extensions},
  year =         1998
}

@article{DasDenn:1997,
  Author =       {I. Das and J. E. Dennis},
  Date-Added =   {2007-12-31 17:27:34 -0800},
  Date-Modified ={2007-12-31 17:28:48 -0800},
  Journal =      {Struct. Optim.},
  Pages =        {63--69},
  Title =        {A closer look at drawbacks of minimizing weighted
                  sums of objectives for {Pareto} set generation in
                  multicriteria optimization problems},
  Volume =       14,
  Year =         1997
}

@article {DaubDevoFornSina:2009,
  author =       {Daubechies, Ingrid and DeVore, Ronald and Fornasier,
                  Massimo and G√ºnt√ºrk, C. Si?nan},
  title =        {Iteratively reweighted least squares minimization
                  for sparse recovery},
  journal =      {Communications on Pure and Applied Mathematics},
  volume =       63,
  number =       1,
  publisher =    {Wiley Subscription Services, Inc., A Wiley Company},
  issn =         {1097-0312},
  url =          {http://dx.doi.org/10.1002/cpa.20303},
  doi =          {10.1002/cpa.20303},
  pages =        {1--38},
  year =         2010,
  abstract =     {Abstract Under certain conditions (known as the
                  restricted isometry property, or RIP) on the m ? N
                  matrix Œ¶ (where m < N), vectors x ???ùN that are
                  sparse (i.e., have most of their entries equal to 0)
                  can be recovered exactly from y := Œ¶x even though
                  Œ¶??(y) is typically an (N ??m)?îdimensional
                  hyperplane; in addition, x is then equal to the
                  element in Œ¶??(y) of minimal ??1-norm. This minimal
                  element can be identified via linear programming
                  algorithms. We study an alternative method of
                  determining x, as the limit of an iteratively
                  reweighted least squares (IRLS) algorithm. The main
                  step of this IRLS finds, for a given weight vector
                  w, the element in Œ¶??(y) with smallest
                  ??2(w)-norm. If x(n) is the solution at iteration
                  step n, then the new weight w(n) is defined by
                  w?âi(n) := [|x?âi(n)|2 + Œµ?ân2]??/2, i = 1, ?? N, for a
                  decreasing sequence of adaptively defined Œµn; this
                  updated weight is then used to obtain x(n + 1) and
                  the process is repeated. We prove that when Œ¶
                  satisfies the RIP conditions, the sequence x(n)
                  converges for all y, regardless of whether Œ¶??(y)
                  contains a sparse vector. If there is a sparse
                  vector in Œ¶??(y), then the limit is this sparse
                  vector, and when x(n) is sufficiently close to the
                  limit, the remaining steps of the algorithm converge
                  exponentially fast (linear convergence in the
                  terminology of numerical optimization). The same
                  algorithm with the ?úheavier??weight w?âi(n) =
                  [|x?âi(n)|2 + Œµ?ân2]??+?/2, i = 1, ?? N, where 0 < ? <
                  1, can recover sparse solutions as well; more
                  importantly, we show its local convergence is
                  superlinear and approaches a quadratic rate for ?
                  approaching 0. ¬© 2009 Wiley Periodicals, Inc.},
}

@Article{DaubFornLori:2007,
  author =       {I. Daubechies and M. Fornasier and I. Loris},
  title =        {Accelereated projected gradient method for linear
                  inverse problems with sparsity constraints},
  journal =      {J. Fourier Anal. Appl.},
  year =         2007,
  note =         {To appear}
}

@Techreport{Davies2008,
  author =       "Davies, M. E. and Gribonval, R.",
  title =        "Restricted isometry constants where $\ell-p$ sparse
                  recovery can fail for $0 < p \le 1$",
  institution =  "IRISA",
  number =       1899,
  address =      "Rennes",
  month =        "May",
  year =         2008
}

@article{Dax:1992,
  Author =       {A. Dax},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Doi =          {10.1137/0802029},
  Journal =      SIAMOpt,
  Keywords =     {lp least norm problems; regularization; optimality
                  conditions; behavior of regularized solutions;
                  duality relations},
  Number =       4,
  Pages =        {602-618},
  Publisher =    {SIAM},
  Title =        {On Regularized Least Norm Problems},
  Url =          {http://link.aip.org/link/?SJE/2/602/1},
  Volume =       2,
  Year =         1992
}

@article{Debr:1952,
  Author =       {Gerard Debreu},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      {Econometrica},
  Month =        {April},
  Number =       2,
  Pages =        {295--300},
  Title =        {Definite and semidefinite quadratic forms},
  Volume =       20,
  Year =         1952
}


@Article{DelGil:05,
  author =       {F. Delbos and J. Gilbert},
  title =        {Global linear convergence of an augmented
                  {L}agrangian algorithm for solving convex quadratic
                  optimization problems},
  journal =      {J. Convex Anal.},
  volume =       12,
  pages =        {45--69},
  year =         2005
}




@article{DembEiseStei:1982,
  Author =       {Ron S. Dembo and Stanley C. Eisenstat and Trond
                  Steihaug},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      SIAMNumAnal,
  Number =       2,
  Pages =        {400--408},
  Title =        {Inexact {N}ewton methods},
  Volume =       19,
  Year =         1982
}

@article{DennEl-AWill:1999,
  Author =       {J. E. Dennis and Majmoud {El-Alem} and Karen
                  Williamson},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      SIAMOpt,
  Number =       2,
  Pages =        {291-315},
  Title =        {A trust-region approach to nonlinear systems of
                  equalities and inequalities},
  Volume =       9,
  Year =         1999
}

@book{DennSchn:1996,
  Address =      {Philadelphia},
  Author =       {J. E. Dennis and R. B. Schnabel},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Note =         {Originally published: Prentice-Hall, New Jersey,
                  1983},
  Publisher =    SIAMpub,
  Series =       {Classics in Applied Mathematics},
  Title =        {Numerical Methods for Unconstrained Optimization and
                  Nonlinear Equations},
  Year =         1996
}

@book{DevrGyorLugo:1996,
  Address =      {New York},
  Author =       {L. Devroye and L. Gyorfi and G. Lugosi},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Publisher =    Springer,
  Title =        {A Probabilistic Theory of Pattern Recognition},
  Year =         1996
}

@techreport{DiniGomeSant:1998,
  Abstract =     {In this work, we focus our attention on the
                  quadratic subproblem of trust-region algorithms for
                  large-scale bound-constrained minimization. An
                  approach that combines a mild active set strategy
                  with gradient projection techniques is employed in
                  the solution of large-scale bound-constrained
                  quadratic problems. To fill in some gaps that have
                  appeared in previous work, we propose, test and
                  analyze heuristics which dynamically choose the
                  parameters in charge of the decision of leaving or
                  not the current face of the feasible set. The
                  numerical analysis is based on problems from CUTE
                  collection and randomly generated convex problems
                  with controlled conditioning and degeneracy. The
                  practical consequences of an appropriate decision of
                  such parameters are shown to be crucial,
                  particularly when dual degenerate and
                  ill-conditioned problems are solved.},
  Address =      {Campinas, Brasil},
  Author =       {M. A. Diniz{-}Ehrhardt and M. A. Gomes{-}Ruggiero
                  and S. A. Santos},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Institution =  {Department of Applied Mathematics, IMECC-UNICAMP},
  Number =       {52/98},
  Title =        {Numerical analysis of leaving-face parameters in
                  bound-constrained quadratic minimization},
  Year =         1998
}

@article{DoE03,
  Abstract =     {Given a dictionary D = {dk} of vectors dk, we seek
                  to represent a signal S as a linear combination S =
                  {sum}k {gamma}(k)dk, with scalar coefficients
                  {gamma}(k). In particular, we aim for the sparsest
                  representation possible. In general, this requires a
                  combinatorial optimization process. Previous work
                  considered the special case where D is an
                  overcomplete system consisting of exactly two
                  orthobases and has shown that, under a condition of
                  mutual incoherence of the two bases, and assuming
                  that S has a sufficiently sparse representation,
                  this representation is unique and can be found by
                  solving a convex optimization problem: specifically,
                  minimizing the {ell}1 norm of the
                  coefficients{gamma} . In this article, we obtain
                  parallel results in a more general setting, where
                  the dictionary D can arise from two or several
                  bases, frames, or even less structured systems. We
                  sketch three applications: separating linear
                  features from planar ones in 3D data, noncooperative
                  multiuser encoding, and identification of
                  over-complete independent component models. },
  Author =       {D. L. Donoho and M. Elad},
  Doi =          {10.1073/pnas.0437847100},
  Eprint =       {http://www.pnas.org/cgi/reprint/100/5/2197.pdf},
  Journal =      ProcNAS,
  Number =       5,
  Pages =        {2197-2202},
  Title =        {Optimally sparse representation in general
                  (nonorthogonal) dictionaries via $\ell_1$
                  minimization},
  Url =          {http://www.pnas.org/cgi/content/abstract/100/5/2197},
  Volume =       100,
  Year =         2003
}

@article{DoH01,
  Abstract =     {Suppose a discrete-time signal $S(t)$, $0 \leq t <
                  N$, is a superposition of atoms taken from a
                  combined time-frequency dictionary made of spike
                  sequences $1_{t=\tau}$ and sinusoids $\exp\{2\pi iw
                  t/N\}/\sqrt{N}$.  Can one recover, from knowledge of
                  $S$ alone, the precise collection of atoms going to
                  make up $S$? Because every discrete-time signal can
                  be represented as a superposition of spikes alone,
                  or as a superposition of sinusoids alone, there is
                  no unique way of writing S as a sum of spikes and
                  sinusoids in general. We prove that if $S$ is
                  representable as a highly sparse superposition of
                  atoms from this time-frequency dictionary, then
                  there is only one such highly sparse representation
                  of $S$, and it can be obtained by solving the convex
                  optimization problem of minimizing the $\ell^1$ norm
                  of the coefficients among all decompositions. Here
                  ``highly sparse'' means that $N_t+N_w < \sqrt{N}/2$
                  where $N_t$ is the number of time atoms, $N_w$ is
                  the number of frequency atoms, and $N$ is the length
                  of the discrete-time signal. Underlying this result
                  is a general $\ell^1$ uncertainty principle which
                  says that if two bases are mutually incoherent, no
                  nonzero signal can have a sparse representation in
                  both bases simultaneously. For the above setting,
                  the bases are sinusoids and spikes, and mutual
                  incoherence is measured in terms of the largest
                  inner product between different basis elements. The
                  uncertainty principle holds for a variety of
                  interesting basis pairs, not just sinusoids and
                  spikes. The results have idealized applications to
                  band-limited approximation with gross errors, to
                  error-correcting encryption, and to separation of
                  uncoordinated sources. Related phenomena hold for
                  functions of a real variable, with basis pairs such
                  as sinusoids and wavelets, and for functions of two
                  variables, with basis pairs such as wavelets and
                  ridgelets. In these settings, if a function f is
                  representable by a sufficiently sparse superposition
                  of terms taken from both bases, then there is only
                  one such sparse representation; it may be obtained
                  by minimum $\ell^1$ norm atomic decomposition. The
                  condition ``sufficiently sparse'' becomes a
                  multiscale condition; for example, that the number
                  of wavelets at level $j$ plus the number of
                  sinusoids in the $j$th dyadic frequency band are
                  together less than a constant times $2^{j/2}$.  },
  Author =       {David L. Donoho and Xiaoming Huo},
  Journal =      ieeetransinfo,
  Keywords =     {Basis pursuit, combinatorial optimization, convex
                  optimization, error-correcting encryption, harmonic
                  analysis, Logan's phenomenon, matching pursuit,
                  multiple-basis signal representation, overcomplete
                  representation, ridgelet analysis, uncertainty
                  principle, wavelet analysis},
  Month =        {November},
  Number =       7,
  Pages =        {2845--2862},
  Title =        {Uncertainty Principles and Ideal Atomic
                  Decomposition},
  Url =
                  {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=959265},
  Volume =       47,
  Year =         2001
}

@article{DoJ94,
  Author =       {D. L. Donoho and I. M. Johnstone},
  Journal =      {Biometrika},
  Number =       3,
  Pages =        {425--455},
  Title =        {Ideal spatial adaptation by wavelet shrinkage},
  Url =          {http://citeseer.ist.psu.edu/donoho93ideal.html},
  Volume =       81,
  Year =         1994
}

@Article{DoJ95,
  author =       "Donoho, D. L. and Johnstone, I. M.",
  title =        "Adapting to unknown smoothness via wavelet
                  shrinkage",
  journal =      "Journal of the American Statistical Association",
  year =         1995,
  volume =       90,
  number =       432,
  page =         {1200--1224}
}

@article{DoT05,
  Abstract =     {Consider an underdetermined system of linear
                  equations y = Ax with known y and d x n matrix A. We
                  seek the nonnegative x with the fewest nonzeros
                  satisfying y = Ax. In general, this problem is
                  NP-hard. However, for many matrices A there is a
                  threshold phenomenon: if the sparsest solution is
                  sufficiently sparse, it can be found by linear
                  programming. We explain this by the theory of convex
                  polytopes. Let aj denote the jth column of A, 1
                  [&le;] j [&le;] n, let a0 = 0 and P denote the
                  convex hull of the aj. We say the polytope P is
                  outwardly k-neighborly if every subset of k vertices
                  not including 0 spans a face of P. We show that
                  outward k-neighborliness is equivalent to the
                  statement that, whenever y = Ax has a nonnegative
                  solution with at most k nonzeros, it is the
                  nonnegative solution to y = Ax having minimal
                  sum. We also consider weak neighborliness, where the
                  overwhelming majority of k-sets of ajs not
                  containing 0 span a face of P. This implies that
                  most nonnegative vectors x with k nonzeros are
                  uniquely recoverable from y = Ax by linear
                  programming. Numerous corollaries follow by invoking
                  neighborliness results. For example, for most large
                  n by 2n underdetermined systems having a solution
                  with fewer nonzeros than roughly half the number of
                  equations, the sparsest solution can be found by
                  linear programming. },
  Author =       {D. L. Donoho and J. Tanner},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Eprint =       {http://www.pnas.org/cgi/reprint/102/27/9446.pdf},
  Journal =      ProcNAS,
  Number =       27,
  Pages =        {9446-9451},
  Title =        {Sparse nonnegative solution of underdetermined
                  linear equations by linear programming},
  Url =
                  {http://www.pnas.org/cgi/content/abstract/102/27/9446},
  Volume =       102,
  Year =         2005
}

@article{DolaFourMoreMuns:2002,
  Author =       {Elizabeth D. Dolan and Robert Fourer and Jorge
                  J. Mor\'{e} and Todd S. Munson},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      {{SIAM} {N}ews},
  Month =        {July/August},
  Number =       6,
  Title =        {Optimization on the {NEOS} server},
  Volume =       35,
  Year =         2002
}

@techreport{DolaMore:2000,
  Address =      {Argonne, IL},
  Author =       {Elizabeth D. Dolan and Jorge J. Mor\'{e}},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Institution =  {Mathematics and Computer Science Division, Argonne
                  National Laboratory},
  Note =         {Revised January 2001},
  Number =       {ANL/MCS-246},
  Title =        {Benchmarking Optimization Software with {COPS}},
  Year =         2000
}

@techreport{DolaMore:2001,
  Address =      {Argonne, IL},
  Author =       {Elizabeth D. Dolan and Jorge J. Mor\'{e}},
  Institution =  {Mathematics and Computer Science Division, Argonne
                  National Laboratory},
  Number =       {ANL/MCS-P861-1200},
  Title =        {Benchmarking Optimization Software with Performance
                  Profiles},
  Year =         2001
}

@article{DolaMore:2002,
  Author =       {Elizabeth D. Dolan and Jorge J. Mor\'{e}},
  Journal =      MathProg,
  Number =       2,
  Pages =        {201-213},
  Title =        {Benchmarking Optimization Software with Performance
                  Profiles},
  Volume =       91,
  Year =         2002
}

@article{DollGoulSchiWath:2006,
  Abstract =     {We consider conjugate-gradient like methods for
                  solving block symmetric indefinite linear systems
                  that arise from saddle-point problems or, in
                  particular, regularizations thereof. Such methods
                  require preconditioners that preserve certain
                  sub-blocks from the original systems but allow
                  considerable flexibility for the remaining
                  blocks. We construct a number of families of
                  implicit factorizations that are capable of
                  reproducing the required sub-blocks and (some) of
                  the remainder. These generalize known implicit
                  factorizations for the unregularized case. Improved
                  eigenvalue clustering is possible if additionally
                  some of the noncrucial blocks are
                  reproduced. Numerical experiments confirm that these
                  implicit-factorization preconditioners can be very
                  effective in practice.  },
  Author =       {H. S. Dollar and N. Gould and W. Schilders and
                  A. J. Wathen},
  Doi =          {10.1137/05063427X},
  Journal =      {{SIAM} J. Math. Anal.},
  Keywords =     {regularized saddle-point systems;
                  implicit-factorization preconditioners},
  Number =       1,
  Pages =        {170-189},
  Publisher =    {SIAM},
  Title =        {Implicit-Factorization Preconditioning and Iterative
                  Solvers for Regularized Saddle-Point Systems},
  Url =          {http://link.aip.org/link/?SML/28/170/1},
  Volume =       28,
  Year =         2006
}

@Techreport{Don06a,
  author =       "Donoho, D. L.",
  title =        "For Most Large Underdetermined Systems of Linear
                  Equations the Minimal l1-norm Near-Solution
                  Approximates the Sparsest near-Solution",
  institution =  "Department of Statistics, Stanford University,
                  Stanford",
  year =         2006
}

@Article{Don06b,
  author =       "Donoho, D. L.",
  title =        "For Most Large Underdetermined Systems of Linear
                  Equations, the Minimal l1-norm Solution is also the
                  Sparsest Solution",
  journal =      "Communications on Pure and Applied Mathematics",
  year =         2006,
  volume =       59,
  page =         {797--929}
}

@Article{Don06c,
  author =       "Donoho, D. L., Elad, M., and Temlyakov, V. N.",
  title =        "Stable recovery of sparse overcomplete
                  representations in the presence of noise",
  journal =      "Information Theory, IEEE Transactions",
  year =         2006,
  volume =       52,
  page =         {6--18}
}

@article{Dono:2006b,
  Author =       {D. L. Donoho},
  Journal =      ieeetransinfo,
  Month =        {April},
  Number =       4,
  Pages =        {1289--1306},
  Title =        {Compressed sensing},
  Volume =       52,
  Year =         2006
}

@article{DonoTann:2005b,
  Author =       {David L. Dohono and Jared Tanner},
  Title =        {Neighborliness of randomly-projected simplices in
                  high dimensions},
  Journal =      ProcNAS,
  Volume =       102,
  Number =       27,
  Year =         2005,
  Pages =        {9452--9457},
  URL =
                  {http://www.pnas.org/cgi/content/abstract/102/27/9452},
  Eprint =       {http://www.pnas.org/cgi/reprint/102/27/9452},
  Keywords =     {Neighborly polytopes, convex hull of Gaussian
                  sample, underdetermined systems of linear equations,
                  uniformly distributed random projections, phase
                  transitions},
  Abstract =     {Let $A$ be a $d \times n$ matrix and $T = T^{n-1}$
                  be the standard simplex in $R^n$. Suppose that $d$
                  and $n$ are both large and comparable: $d \approx
                  \delta n$, $\delta \in (0,1)$. We count the faces of
                  the projected simplex $AT$ when the projector $A$ is
                  chosen uniformly at random from the Grassmann
                  manifold of $d$-dimensional orthoprojectors of
                  $R^n$. We derive $\rho_N(\delta)> 0$ with the
                  property that, for any $\rho < \rho_N(\delta)$, with
                  overwhelming probability for large $d$, the number
                  of $k$-dimensional faces of $P = AT$ is exactly the
                  same as for $T$, for $0 \leq k \leq \rho d$. This
                  implies that $P$ is $\lfloor\rho
                  d\rfloor$-neighborly, and its skeleton
                  $\mathrm{Skel}_{\lfloor\rho d\rfloor}(P)$ is
                  combinatorially equivalent to
                  $\mathrm{Skel}_{\lfloor\rho d\rfloor}(T)$. We also
                  study a weaker notion of neighborliness where the
                  numbers of $k$-dimensional faces $f_k(P) \geq
                  f_k(T)(1-\varepsilon)$. Vershik and Sporyshev
                  previously showed existence of a threshold
                  $\rho_{VS}(\delta) > 0$ at which phase transition
                  occurs in $k/d$. We compute and display $\rho_{VS}$
                  and compare with $\rho_N$. Corollaries are as
                  follows. (1) The convex hull of $n$ Gaussian samples
                  in $R^d$, with $n$ large and proportional to $d$,
                  has the same $k$-skeleton as the $(n - 1)$ simplex,
                  for $k < \rho_N (d/n)d(1 + o_P(1))$.  (2) There is a
                  ``phase transition'' in the ability of linear
                  programming to find the sparsest nonnegative
                  solution to systems of underdetermined linear
                  equations.  For most systems having a solution with
                  fewer than $\rho_{VS}(d/n)d(1+o(1))$ nonzeros,
                  linear programming will find that solution.}
}

@unpublished{DonoTsai:2006,
  Author =       {David L. Donoho and Yaakov Tsaig},
  Month =        {October},
  Note =         {\url{http://www.stanford.edu/~tsaig/research.html}},
  Title =        {Fast solution of {L1}-norm minimization problems
                  when the solution may be sparse},
  Year =         2006
}

@Article{Donoho1994,
  author =       "Donoho, D. L. and Johnstone, I. M.",
  title =        "Ideal spatial adaptation by wavelet shrinkage",
  journal =      "Biometrika",
  year =         1994,
  volume =       81,
  page =         {425--455}
}

@Article{Donoho2001,
  author =       "Donoho. D. L. and Huo, X.",
  title =        "Uncertainty principles and ideal atomic
                  decomposition",
  journal =      "Information Theory, IEEE Transactions",
  year =         2001,
  volume =       47,
  page =         {2845--2862}
}

@Proceedings{Donoho2003,
  author =       "Donoho, D. L. and Elad, M.",
  title =        "Optimally sparse representation in general
                  (nonorthogonal) dictionaries via $\ell-1$
                  minimization",
  year =         2003,
  organization = "Nat. Acad. Sci.",
  volume =       100,
  page =         {2197--2202},
}

@Techreport{Donoho2006d,
  author =       "Donoho, D. L., Tsaig, Y., Drori, I., and Starek,
                  J.-L.",
  title =        "Sparse solution of underdetermined linear equations
                  by stagewise orthogonal matching pursuit",
  institution =  "Department of Statistics, Stanford University,
                  Stanford",
  year =         2006
}

@article{Dost:1991,
  Abstract =     {An upper bound for the difference of the exact
                  solution of the problem of minimization of a
                  quadratic functional on the subspace and its penalty
                  approximation is given. The paper supplies a
                  numerical example.},
  Author =       {Z. Dost\'{a}l},
  Journal =      {Kybernetika},
  Number =       2,
  Pages =        {151--154},
  Title =        {On the penalty approximation of quadratic
                  programming problem},
  Volume =       27,
  Year =         1991
}

@article{Dost:1996,
  Abstract =     {We review our recent results on the solution of
                  quadratic programming problems with simple bounds by
                  means of the conjugate gradient method with inexact
                  solution of auxiliary subproblems and
                  projections. Precision of the solution of auxiliary
                  problems is controlled by the product of a positive
                  constant Gamma with the norm of violation of the
                  Kuhn-Tucker contact conditions. The resulting
                  algorithm converges for any positive Gamma and
                  reaches the solution in a finite number of steps
                  provided the problem is nondegenerate. A lower bound
                  on Gamma is given so that the finite termination
                  property is preserved even for degenerate
                  problems. The algorithm may be implemented with
                  projections so that it can drop and add many
                  constraints whenever the active set is
                  changed. Applications to the solution of inner
                  obstacle problems and contact problems of elasticity
                  are reported.},
  Author =       {Z. Dost\'{a}l},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      {Zeitschrift f\"{u}r Angewandte Mathematik und
                  Mechanik},
  Number =       {S3},
  Pages =        {413--414},
  Title =        {Box constrained quadratic programming with
                  controlled precision of auxiliary problems and
                  applications},
  Volume =       76,
  Year =         1996
}

@article{Dost:1997,
  Abstract =     {Two new closely related concepts are introduced that
                  depend on a positive constant Gamma . An iteration
                  is proportional if the norm of violation of the
                  Kuhn-Tucker conditions at active variables does not
                  excessively exceed the norm of the part of the
                  gradient that corresponds to free variables, while a
                  progressive direction determines a descent direction
                  that enables the released variables to move far
                  enough from the boundary in a step called
                  proportioning. An algorithm that uses the conjugate
                  gradient method to explore the face of the region
                  defined by the current iterate until a
                  disproportional iteration is generated is
                  proposed. It then changes the face by means of the
                  progressive direction. It is proved that for
                  strictly convex problems, the proportioning is a
                  spacer iteration so that the algorithm converges to
                  the solution. If the solution is nondegenerate then
                  the algorithm finds the solution in a finite number
                  of steps. Moreover, a simple lower bound on Gamma is
                  given to ensure finite termination even for problems
                  with degenerate solutions. The theory covers a class
                  of algorithms, allowing many constraints to be added
                  or dropped at a time and accepting approximate
                  solutions of auxiliary problems. Preliminary
                  numerical results are promising.},
  Author =       {Z. Dost\'{a}l},
  Journal =      SIAMOpt,
  Number =       3,
  Pages =        {871--887},
  Title =        {Box constrained quadratic programming with
                  proportioning and projections},
  Volume =       7,
  Year =         1997
}

@inproceedings{DostFrieSant:1998,
  Address =      {Dordrecht, The Netherlands},
  Author =       {Z. Dost\'{a}l and A. Friedlander and S. A. Santos},
  Booktitle =    {High Performance Algorithms and Software in
                  Nonlinear Optimization},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Editor =       {R. De Leone and A. Murli and P. M. Pardalos and
                  G. Toraldo},
  Pages =        {161--173},
  Publisher =    {Kluwer Academic},
  Title =        {Adaptive precision control in quadratic programming
                  with simple bounds and/or equality constraints},
  Year =         1998
}

@article{DostFrieSant:1999,
  Abstract =     {In this paper we introduce an augmented Lagrangian
                  type algorithm for strictly convex quadratic
                  programming problems with equality constraints. The
                  new feature of the proposed algorithm is the
                  adaptive precision control of the solution of
                  auxiliary problems in the inner loop of the basic
                  algorithm. Global convergence and boundedness of the
                  penalty parameter are proved and an error estimate
                  is given that does not have any term that accounts
                  for the inexact solution of the auxiliary
                  problems. Numerical experiments illustrate
                  efficiency of the algorithm presented.},
  Author =       {Z. Dost\'{a}l and A. Friedlander and S. A. Santos},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      compapplopt,
  Local-Url =
                  {file://localhost/Users/mpf/papers/DostFrieSant99.pdf},
  Number =       1,
  Pages =        {37--53},
  Title =        {Augmented {L}agrangians with adaptive precision
                  control for quadratic programming with equality
                  constraints},
  Volume =       14,
  Year =         1999
}

@article{DostFrieSant:2003,
  Author =       {Z. Dost\'{a}l and A. Friedlander and S. A. Santos},
  Journal =      siamopt,
  Local-Url =
                  {file://localhost/Users/mpf/papers/DostFrieSant03.pdf},
  Number =       4,
  Pages =        {1120--1140},
  Title =        {Augmented {L}agrangians with adaptive precision
                  control for quadratic programming with simple bounds
                  and equality constraints},
  Volume =       13,
  Year =         2003
}

@article{Drud:1994,
  Author =       {A. S. Drud},
  Journal =      {{ORSA} J. Computing},
  Pages =        {207--216},
  Title =        {A large scale {GRG} code},
  Volume =       6,
  Year =         1994
}

@article{DuAnge:2006,
  Author =       {P.-C Du and Ruth H. Angeletti},
  Title =        {Automatic deconvolution of isotope-resolved mass
                  spectra using variable selection and quantized
                  peptide mass distribution},
  Journal =      {Analytical Chemistry},
  Volume =       78,
  Number =       10,
  Month =        {May},
  Year =         2006,
  Pages =        {3385--3392}
}

@inproceedings{DuchShalSingChan:2008,
  Author =       {J. Duchi and S. Shalev-Shwartz and Y. Singer and
                  T. Chandra},
  Title =        {Efficient projections onto the $\ell_1$-ball for
                  learning in high dimensions},
  booktitle =    {Proceedings of the 25th International Conference on
                  Machine Learning},
  year =         2008,
  pages =        {272--279}
}

@article{Duff:2004,
  Author =       {Iain S. Duff},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      acmmathsoft,
  Number =       2,
  Pages =        {118--144},
  Title =        {{MA57}---a code for the solution of sparse symmetric
                  definite and indefinite systems},
  Volume =       30,
  Year =         2004
}

@incollection{Dunn:1994,
  Author =       {J. C. Dunn},
  Booktitle =    {Large Scale Optimization: State of the Art},
  Date-Added =   {2007-07-04 23:43:57 -0700},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Editor =       {W. W. Hager, D. W. Hearn, and P. M. Pardalos},
  Pages =        {95-114},
  Publisher =    {Kluwer},
  Title =        {Gradient-Related Constrained Minimization Algorithms
                  in Function Spaces: Convergence Properties and
                  Computational Implications},
  Year =         1994
}

@InProceedings{EGWYMAB04,
  author =       "Eren, T. and Goldenberg, D. K. and Whiteley, W. and
                  Yang, Y. R. and Morse, A. S. and Anderson,
                  B. D. O. and Belhumeur, P.N.",
  title =        "Rigidity, computation, and randomization in network
                  localization",
  year =         2004,
  booktitle =    "23rd INFOCOM",
  volume =       4,
  page =         {2673--2684}
}

@Article{Eck93,
  author =       "Jonathan Eckstein",
  title =        "Nonlinear Proximal Point Algorithms Using {Bregman}
                  Functions, with Applications to Convex Programming",
  journal =      mathofor,
  year =         1993,
  volume =       18,
  number =       1,
  page =         {202--226}
}

@article{EfroHastJohnTibs:2004,
  Author =       {B. Efron and T. Hastie and I. Johnstone and
                  R. Tibshirani},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      {Ann. Statist.},
  Local-Url =
                  {file://localhost/Users/mpf/papers/EfroHastJohnTibs04.pdf},
  Number =       2,
  Pages =        {407-499},
  Title =        {Least angle regression},
  Volume =       32,
  Year =         2004
}

@article{El--TapiT.TsY.Zh:1996,
  Author =       {A.~S. {El--Bakry} and R.~A. Tapia and T.~Tsuchiya
                  and Y.~Zhang},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      {Journal of Optimization Theory and Applications},
  Month =        {June},
  Pages =        {507--541},
  Part =         3,
  Title =        {On the formulation and theory of {Newton}
                  interior-point method for nonlinear programming},
  Volume =       89,
  Year =         1996
}

@article{EladMilaRubi:2007,
  author =       {M. Elad and P. Milanfar and R. Rubinstein},
  title =        {Analysis Versus Synthesis in Signal Priors},
  journal =      {Inverse Problems},
  volume =       23,
  number =       3,
  pages =        {947-968},
  month =        {June},
  year =         2007
}

@article{EldaMish:2008,
  Author =       {Yonina C. Eldar and Moshe Mishali},
  Title =        {Robust Recovery of Signals From a Union of
                  Subspaces},
  journal =      ieeetransinfo,
  doi =          {10.1109/TIT.2009.2030471 },
  volume =       55,
  Year =         2009,
  abstract =     {Traditional sampling theories consider the problem
                  of reconstructing an unknown signal x from a series
                  of samples. A prevalent assumption which often
                  guarantees recovery from the given measurements is
                  that x lies in a known subspace. Recently, there has
                  been growing interest in nonlinear but structured
                  signal models, in which x lies in a union of
                  subspaces. In this paper, we develop a general
                  framework for robust and efficient recovery of such
                  signals from a given set of samples. More
                  specifically, we treat the case in which x lies in a
                  sum of k subspaces, chosen from a larger set of m
                  possibilities. The samples are modeled as inner
                  products with an arbitrary set of sampling
                  functions. To derive an efficient and robust
                  recovery algorithm, we show that our problem can be
                  formulated as that of recovering a block-sparse
                  vector whose nonzero elements appear in fixed
                  blocks. We then propose a mixed lscr2/lscr1 program
                  for block sparse recovery. Our main result is an
                  equivalence condition under which the proposed
                  convex algorithm is guaranteed to recover the
                  original signal. This result relies on the notion of
                  block restricted isometry property (RIP), which is a
                  generalization of the standard RIP used extensively
                  in the context of compressed sensing. Based on RIP,
                  we also prove stability of our approach in the
                  presence of noise and modeling errors. A special
                  case of our framework is that of recovering multiple
                  measurement vectors (MMV) that share a joint
                  sparsity pattern. Adapting our results to this
                  context leads to new MMV recovery methods as well as
                  equivalence conditions under which the entire set
                  can be determined efficiently.  }
}

@article{EldaMish:2009,
  Author =       {Yonina C. Eldar and Moshe Mishali},
  Title =        {Robust Recovery of Signals From a Union of
                  Subspaces},
  Year =         2009,
  doi =          {10.1109/TIT.2009.2030471},
  volume =       55,
  journal =      ieeetransinfo,
  pages =        {5302-5316}
}

@article{Elde:1990,
  Abstract =     {We study a linear, discrete ill-posed problem, by
                  which we mean a very ill-conditioned linear least
                  squares problem.  In particular we consider the case
                  when one is primarily interested in computing a
                  functional defined on the solution rather than the
                  solution itself. In order to alleviate the
                  ill-conditioning we require the norm of the solution
                  to be smaller than a given constant. Thus we are
                  lead to minimizing a linear functional subject to
                  two quadratic constraints. We study existence and
                  uniqueness for this problem and show that it is
                  essentially equivalent to a least squares problem
                  with a linear and a quadratic constraint, which is
                  easier to handle computationally. Efficient
                  algorithms are suggested for this problem.  },
  Address =      {Lawrence, KS, USA},
  Author =       {Lars Eld\'{e}n},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      BIT,
  Keywords =     {ill-posed, least squares, constraint, functional,
                  algorithm},
  Number =       3,
  Pages =        {466--483},
  Publisher =    {BIT Computer Science and Numerical Mathematics},
  Title =        {Algorithms for the Computation of functionals
                  defined on the solution of a discrete ill-posed
                  problem},
  Volume =       30,
  Year =         1990
}

@article{EldeHansRoja:2005,
  Abstract =     {The minimization of linear functionals defined on
                  the solutions of discrete ill-posed problems arises,
                  e.g., in the computation of confidence intervals for
                  these solutions. In 1990, Eld\'{e}n proposed an
                  algorithm for this minimization problem based on a
                  parametric programming reformulation involving the
                  solution of a sequence of trust-region problems, and
                  using matrix factorizations. In this paper, we
                  describe MLFIP, a largescale version of this
                  algorithm where a limited-memory trust-region solver
                  is used on the subproblems. We illustrate the use of
                  our algorithm in connection with an inverse heat
                  conduction problem.  },
  Author =       {Lars Eld\'{e}n and Per Christian Hansen and Marielba
                  Rojas},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      BIT,
  Keywords =     {Discrete ill-posed problems, confidence intervals,
                  large-scale algorithms, trust regions},
  Number =       2,
  Pages =        {329--340},
  Title =        {Minimization of linear functionals defined on
                  solutions of large-scale discrete-ill posed
                  problems},
  Volume =       45,
  Year =         2005
}

@InProceedings{EvP04,
  author =       "Evgeniou, T. and Pontil, M.",
  title =        "Regularized multi-task learning",
  year =         2004,
  booktitle =    "10th ACM SIGKDD international conference on
                  Knowledge discovery and data mining",
  page =         {109--117}
}

@InProceedings{FHB01,
  author =       "Fazel, M. and Hindi, H. and Boyd, S. P.",
  title =        "A Rank Minimization Heuristic with Application to
                  Minimum Order System Approximation",
  year =         2001,
  address =      "Arlington",
  booktitle =    "American Control Conference",
  page =         {4734--4739}
}

@Article{FHHT07,
  author =       {Friedman, J. and Hastie, T. and H\"{o}fling, H. and
                  Tihshirani, R.},
  title =        "Pathwise coordinate optimization",
  journal =      "Ann. Appl. Stat.",
  year =         2007,
  volume =       1,
  page =         {302--332}
}

@Article{FHT07,
  author =       "Friedman, J. and Hastie, T. and Tibshirani, R.",
  title =        "Sparse inverse covariance estimation with the
                  graphical lasso",
  journal =      "Biostatistics",
  year =         2007,
  page =         {1--10}
}

@Techreport{FHT08,
  author =       "Friedman, J. and Hastie, T. and Tihshirani, R.",
  title =        "Regularization paths for generalized linear models
                  via coordinate descent",
  institution =  "Department of Statistics, Stanford University,
                  Stanford",
  type =         {Report},
  year =         2008,
  month =        "July"
}

@Book{FaP03,
  author =       "Facchinei, F. and Pang, J.-S.",
  title =        "Finite-Dimensional Variational Inequalities and
                  Complementarity Problems",
  volume =       "I and II",
  publisher =    "Springer",
  year =         2003,
  address =      "New York"
}

@PhdThesis{Fazel:2002,
  title =        {{Matrix rank minimization with applications}},
  author =       {Fazel, M.},
  school =       {Elec. Eng. Dept, Stanford University},
  year =         2002
}

@article{FeM91,
  Author =       {Ferris, M. C. and Mangasarian, O. L.},
  Journal =      {Appl. Math. Optim.},
  Number =       3,
  Pages =        {263--273},
  Title =        {Finite perturbation of convex programs},
  Volume =       23,
  Year =         1991
}

@Article{FeM94,
  author =       "Ferris, M. C. and Mangasarian, O. L.",
  title =        "Parallel variable distribution",
  journal =      siamopt,
  year =         1994,
  volume =       4,
  page =         {815--832}
}

@article{FeP97,
  Author =       {M. C. Ferris and J. S. Pang},
  Journal =      siamreview,
  Number =       4,
  Pages =        {669-713},
  Title =        {Engineering and Economic Applications of
                  Complementarity Problems},
  Volume =       39,
  Year =         1997
}

@article{FessSutt:2003,
  Author =       {Jeffrey A. Fessler and Bradley P. Sutton},
  Date-Modified ={2007-09-18 22:12:17 -0700},
  Journal =      {{IEEE} Trans. Sig. Proc.},
  Number =       2,
  Pages =        {560-574},
  Title =        {Nonuniform fast Fourier transforms using min-max
                  interpolation},
  Url =          {\url{http://www.dsp.rice.edu/software/rwt.shtml}},
  Volume =       51,
  Year =         2003
}

@misc{Fevo:2007,
  Author =       {C. F\'{e}votte},
  Date-Added =   {2007-09-18 21:01:54 -0700},
  Date-Modified ={2007-09-18 21:01:54 -0700},
  Title =        {{Audio Source Separation Demo Webpage}},
  Url =          {http://www.tsi.enst.fr/~fevotte/bass_demo.html},
  Year =         2007
}

@article{FiacLiu:1993,
  Author =       {Anthony V. Fiacco and Jiming Liu},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      {Ann. Oper. Res.},
  Pages =        {61-80},
  Title =        {Degeneracy in {NLP} and the Development of Results
                  Motivated by its Presence},
  Volume =       46,
  Year =         1993
}

@book{FiacMcCo:1968,
  Address =      {New York},
  Author =       {Anthony V. Fiacco and Garth P. McCormick},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Publisher =    {Wiley},
  Title =        {Nonlinear Programming: Sequential Unconstrained
                  Minimization Techniques},
  Year =         1968
}

@Article{FigNow:2003,
  author =       {M\'ario A. T. Figueiredo and Robert D. Nowak},
  title =        {An {EM} algorithm for wavelet-based image
                  restoration},
  journal =      ieeetransimagproc,
  year =         2003,
  volume =       12,
  number =       8,
  pages =        {906-916},
  month =        {August}
}

@article{FiguNowaWrig:2007,
  title =        {{Gradient Projection for Sparse Reconstruction:
                  Application to Compressed Sensing and Other Inverse
                  Problems}},
  author =       {Figueiredo, M. and Nowak, R. and Wright, S. J.},
  journal =      {Sel. Top. in Signal Process., IEEE J.},
  volume =       1,
  number =       4,
  pages =        {586--597},
  year =         2007
}

@InProceedings{Fle94,
  author =       "Fletcher, R.",
  title =        "An overview of unconstrained optimization",
  booktitle =    "Algorithms for Continuous Optimization",
  editor =       "E. Spedicato",
  organization = "Kluwer Academic",
  address =      "Dordrecht",
  year =         1994,
  page =         {109--143}
}

@article{Flet:1971,
  Abstract =     {An effective algorithm is presented for quadratic
                  programming which is of general applicability, but
                  which is not dependent upon the availability of a
                  linear programming code for its implementation. It
                  is an algorithm of exchange type, the exchanges
                  being chosen so as to avoid the accumulation of
                  error to as large an extent as possible.},
  Author =       {R. Fletcher},
  Journal =      {J. Institute Math. Appl.},
  Pages =        {76--91},
  Title =        {A general quadratic programming algorithm},
  Volume =       7,
  Year =         1971
}

@incollection{Flet:1974,
  Address =      {London},
  Author =       {R. Fletcher},
  Booktitle =    {Numerical Methods for Constrained Optimization},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Editor =       {P. E. Gill and W. Murray},
  Pages =        {219--239},
  Publisher =    Academic,
  Title =        {Methods Related to Lagrangian Functions},
  Year =         1974
}

@inproceedings{Flet:1985,
  Address =      {Philadelphia},
  Author =       {R. Fletcher},
  Booktitle =    {Numerical Optimization. 1984},
  Editor =       {P. T. Boggs and R. H. Byrd and R. B. Schnabel},
  Pages =        {26-40},
  Publisher =    SIAMPub,
  Title =        {An $\ell_1$ penalty method for nonlinear
                  constraints},
  Year =         1985
}

@article{CurtisNocedal:2008,
  journal =      {IMA Journal of Numerical Analysis},
  year =         2008,
  volume =       28,
  pages =        {749??69},
  doi =          {10.1093/imanum/drn003},
  title =        {Flexible penalty functions for nonlinear constrained
                  optimization},
  author =       {Frank E. Curtis and Jorge Nocedal}
}

@book{Flet:1987,
  Address =      {Chichester, UK},
  Author =       {R. Fletcher},
  Date-Modified ={2007-11-09 15:14:02 -0800},
  Edition =      {Second},
  Publisher =    {Wiley},
  Title =        {Practical Methods of Optimization},
  Year =         1987
}

@inproceedings{Flet:1987b,
  author =       {R. Fletcher},
  title =        {Recent developments in linear and quadratic
                  programming},
  editor =       {Iserles, A. and Powell, M. J. D.},
  booktitle =    {State of the Art in Numerical Analysis. Proceedings
                  of the Joint IMA/SIAM Conference},
  publisher =    {Oxford University Press, Oxford, England},
  year =         1987,
  pages =        {213--243},
  abstract =     {Describes recent developments in linear programming,
                  including the ellipsoid algorithm, the Karmarkar
                  algorithm, new strategies for updating LU factors in
                  the simplex method, and methods with guaranteed
                  termination in the presence of degeneracy and
                  round-off errors. Various new algorithms for
                  quadratic programming are discussed, and the choice
                  of matrix factorizations and their updates is
                  considered. The use of $\ell_1$ penalty functions in
                  linear and quadratic programming is also mentioned
                  briefly.}
}

@techreport{Flet:1991,
  Address =      {Dundee, Scotland},
  Author =       {R. Fletcher},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Institution =  {University of Dundee},
  Number =       {NA-135},
  Title =        {Resolving degeneracy in quadratic programming},
  Year =         1991
}

@article{Flet:1993,
  Abstract =     {A technique for the resolution of degeneracy in an
                  active set method for quadratic programming is
                  described. The approach generalises Fletcher's
                  method (1988) which applies to the LP case. The
                  method is described in terms of a linear
                  complementarity problem tableau, which is seen to
                  provide useful insights. It is shown that the
                  degeneracy procedure only needs to operate when the
                  degenerate constraints are linearly dependent on
                  those in the active set. No significant overheads
                  are incurred by the degeneracy procedure. It is
                  readily implemented in a null space format, and no
                  complications in the matrix algebra are
                  introduced. The guarantees of termination provided
                  by Fletcher's method, extending in particular to the
                  case where round-off error is present, are preserved
                  in the QP case. It is argued that the technique
                  gives stronger guarantees than are available with
                  other popular methods such as Wolfe's method (1963)
                  or the method of Goldfarb and Idnani (1983).},
  Author =       {R. Fletcher},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      {Ann. Oper. Res.},
  Number =       {1--4},
  Pages =        {307--334},
  Title =        {Resolving degeneracy in quadratic programming},
  Volume =       {46--47},
  Year =         1993
}

@techreport{FletLeyf:1997,
  Address =      {Scotland},
  Author =       {R. Fletcher and S. Leyffer},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Institution =  {Dept. of Mathematics, University of Dundee},
  Number =       {Numerical Analysis Report NA/171},
  Title =        {Nonlinear programming without a penalty function},
  Year =         1997
}

@techreport{GillWong:2010,
  title =        {Sequential quadratic programming methods},
  author =       {Philip E. Gill and Elizabeth Wong},
  type =         {Technical Report},
  number =       {NA-10-03},
  month =        {August},
  year =         2010,
  institution =  {UCSD Department of Mathematics}
}

@techreport{BettsFrank:1997,
  author =       {J.T. Betts and W.P. Huffman},
  title =        {Sparse optimal control software {SOCS}},
  type =         {Mathematics and Engineering Analysis Technical
                  Document},
  number =       {MEA-LR-085},
  institution =  {Boeing Information and Support Services, The Boeing
                  Company},
  address =      {PO Box 3707, Seattle, WA 98124-2207},
  month =        {July},
  year =         1997
}

@article{BettsFrank:1994,
  title =        {A sparse nonlinear optimization algorithm},
  author =       {Betts, J.T. and Frank, P.D.},
  journal =      {Journal of Optimization Theory and Applications},
  volume =       82,
  number =       3,
  pages =        {519--541},
  year =         1994,
  publisher =    {Springer}
}

@techreport{FletLeyf:1998,
  Author =       {R. Fletcher and S. Leyffer},
  Institution =  {University of Dundee},
  Month =        {March},
  Number =       {NA-181},
  Title =        {User manual for {FilterSQP}},
  Year =         1999
}

@techreport{FletLeyf:2002,
  Author =       {R. Fletcher and S. Leyffer},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Institution =  {University of Dundee},
  Month =        {August},
  Number =       {NA-210},
  Title =        {Numerical experience with solving {MPECs} as {NLPs}},
  Year =         2002
}

@article{FletLeyf:2002a,
  Abstract =     {In this paper the solution of nonlinear programming
                  problems by a Sequential Quadratic Programming (SQP)
                  trust--region algorithm is considered. The aim of
                  the present work is to promote global convergence
                  without the need to use a penalty function. Instead,
                  a new concept of a ``filter'' is introduced which
                  allows a step to be accepted if it reduces either
                  the objective function or the constraint violation
                  function. Numerical tests on a wide range of test
                  problems are very encouraging and the new algorithm
                  compares favourably with LANCELOT and an
                  implementation of S$l_1$QP.},
  Author =       {R. Fletcher and S. Leyffer},
  Journal =      mathprog,
  Month =        {January},
  Number =       2,
  Pages =        {239--269},
  Summary =      {A Sequential Quadratic Programming (SQP)
                  trust-region algorithm for nonlinear programming is
                  considered, which is globally convergent without the
                  need to use a penalty function. Instead, the concept
                  of a ``filter'' is introduced which allows a step to
                  be accepted if it reduces either the objective
                  function or the constraint violation
                  function. Numerical tests on a wide range of test
                  problems are very encouraging and the new algorithm
                  compares favourably with {\sf LANCELOT} and an
                  implementation of S$l_1$QP.},
  Title =        {Nonlinear programming without a penalty function},
  Volume =       91,
  Year =         2002
}

@techreport{FletLeyfRalpScho:2002,
  Author =       {R. Fletcher and S. Leyffer and Danny Ralph and
                  Stefan Scholtes},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Institution =  {University of Dundee},
  Month =        {May},
  Number =       {NA-209},
  Title =        {Local convergence of {SQP} methods for Mathematical
                  Programs with Equilibrium Constraints},
  Year =         2002
}

@techreport{FletLeyfToin:1998,
  Address =      {Dundee DD1 4HN, Scotland, UK},
  Author =       {R. Fletcher and S. Leyffer and \mbox{Ph}. Toint},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Institution =  {Department of Mathematics, University of Dundee},
  Month =        {August},
  Note =         {Revised October 1999},
  Number =       {NA/183},
  Title =        {On the global convergence of an {SLP}-filter
                  algorithm},
  Type =         {Numerical Analysis Report},
  Year =         1998
}

@article{FletLeyfToin:2002,
  Author =       {R. Fletcher and S. Leyffer and Ph. Toint},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      siamopt,
  Number =       13,
  Pages =        {44--59},
  Title =        {On the Global Convergence of a Filter-{SQP}
                  Algorithm},
  Year =         2002
}

@article{FletMaza:1989,
  Author =       {R. Fletcher and E. \mbox{Sainz} de la Maza},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      mathprog,
  Number =       3,
  Pages =        {235--256},
  Title =        {Nonlinear programming and non-smooth optimization by
                  succssive linear programming},
  Volume =       43,
  Year =         1989
}

@techreport{FlieHeerMolz:2006,
  Author =       {J. Fliege and C. Heermann and D. Molz},
  Date-Added =   {2007-10-12 18:17:53 -0700},
  Date-Modified ={2007-10-19 18:39:05 -0700},
  Institution =  {School of Mathematics, Univ. of Birmingham},
  Number =       {2006/34},
  Title =        {An adaptive primal-dual warm-start technique for
                  quadratic multiobjective optimization},
  Type =         {Tech. rep.},
  Year =         2006
}

@misc{FornRauh:2007,
  title =        {Recovery algorithms for vector valued data with
                  joint sparsity constraints},
  author =       {Fornasier, M. and Rauhut, H.},
  journal =      {Arxiv preprint math/0608124},
  year =         2006,
  note =         {To appear in {\it SIAM J. Numer. Anal.}}
}

@article{Fors:2002,
  Author =       {Forsgren, Anders},
  Coden =        {ANMAEL},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Fjournal =     appnummath,
  Issn =         {0168-9274},
  Journal =      {Appl. Numer. Math.},
  Mrclass =      {90C55 (65F05 65K05 90C51)},
  Mrnumber =     {MR1936104 (2003i:90120)},
  Number =       {1-2},
  Pages =        {91--107},
  Title =        {Inertia-controlling factorizations for optimization
                  algorithms},
  Volume =       43,
  Year =         2002
}

@article{ForsGill:1998,
  Author =       {A. Forsgren and P. E. Gill},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      SIOPT,
  Pages =        {1132--1152},
  Title =        {Primal-dual interior methods for nonconvex nonlinear
                  programming},
  Volume =       8,
  Year =         1998
}

@article{ForsGillGrif:2007,
  Author =       {A. Forsgren and P. E. Gill and J. D. Griffin},
  Date-Added =   {2007-10-13 12:06:04 -0700},
  Date-Modified ={2007-10-19 14:39:56 -0700},
  Doi =          {10.1137/060650210},
  Journal =      siamopt,
  Keywords =     {large-scale nonlinear programming; nonconvex
                  optimization; interior methods; augmented systems;
                  KKT systems; iterative methods; conjugate-gradient
                  method; constraint preconditioning},
  Number =       2,
  Pages =        {666-690},
  Publisher =    {SIAM},
  Title =        {Iterative Solution of Augmented Systems Arising in
                  Interior Methods},
  Url =          {http://link.aip.org/link/?SJE/18/666/1},
  Volume =       18,
  Year =         2007
}

@article{ForsGillMurr:1995,
  Author =       {Anders Forsgren and P. E. Gill and W. Murray},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      siamscicomp,
  Number =       1,
  Pages =        {139--150},
  Title =        {Computing Modified {Newton} Directions Using a
                  Partial {Cholesky} Factorization},
  Volume =       16,
  Year =         1995
}

@article{ForsGillWrig:2002,
  Author =       {Anders Forsgren and P. E. Gill and Margaret
                  H. Wright},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Doi =          {10.1137/S0036144502414942},
  Journal =      siamreview,
  Keywords =     {nonlinear programming; constrained minimization;
                  nonlinear constraints; primal-dual methods; interior
                  methods; penalty methods; barrier methods},
  Number =       4,
  Pages =        {525-597},
  Publisher =    {SIAM},
  Title =        {Interior Methods for Nonlinear Optimization},
  Url =          {http://link.aip.org/link/?SIR/44/525/1},
  Volume =       44,
  Year =         2002
}

@book{FourGayKern:1993,
  Address =      {San Francisco},
  Author =       {R. Fourer and D. M. Gay and B. W. Kernighan},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Publisher =    Scientific,
  Title =        {{AMPL}: A Modeling Language for Mathematical
                  Programming},
  Year =         1993
}

@book{FourGayKern:2003,
  Address =      {Pacific Grove, CA},
  Author =       {R. Fourer and D. M. Gay and B. W. Kernighan},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Edition =      {2nd},
  Publisher =    {Duxbury/Brooks/Cole},
  Title =        {{AMPL}: A Modeling Language for Mathematical
                  Programming},
  Year =         2003
}

@article{FrieMart:1994,
  Author =       {A. Friedlander and J. M. Mart\'{\i}nez},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      siamopt,
  Number =       1,
  Pages =        {177--192},
  Title =        {On the Maximization of a Concave Quadratic Function
                  with Box Constraints},
  Volume =       4,
  Year =         1994
}

@Article{FuM81,
  author =       "Fukushima, M. and Mine, H.",
  title =        "A generalized proximal point algorithm for certain
                  non-convex minimization problems",
  journal =      "International Journal of Systems Science",
  year =         1981,
  volume =       12,
  page =         {989--1000}
}

@article{Fuc04,
  Author =       {Jean-Jacques Fuchs},
  Journal =      ieeetransinfo,
  Month =        {June},
  Number =       6,
  Pages =        {1341--1344},
  Title =        {On Sparse Representations in Arbitrary Redundant
                  Bases},
  Url =
                  {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1302316},
  Volume =       50,
  Year =         2004
}

@Article{Fuc05,
  Author =       {Jean-Jacques Fuchs},
  title =        "Recovery of exact sparse representations in the
                  presence of bounded noise",
  Journal =      ieeetransinfo,
  year =         2005,
  volume =       51,
  page =         {3601--3608}
}

@Article{Fuk98,
  author =       "Fukushima, M.",
  title =        "Parallel variable transformation in unconstrained
                  optimization",
  journal =      siamopt,
  year =         1998,
  volume =       8,
  page =         {658--672}
}

@inproceedings{FukuPang:1999,
  Address =      {Berlin, Heidelberg, and New York},
  Author =       {M. Fukushima and J. S. Pang},
  Booktitle =    {Ill-Posed Variational Problems and Regularization
                  Techniques},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Editor =       {M. Thera and R. Tichatschke},
  Pages =        {99-110},
  Publisher =    SPRINGER,
  Title =        {Convergence of smoothing continuation method for
                  mathematical programs with complementarity
                  constraints},
  Year =         1999
}

@article{FukuTsen:2002,
  Author =       {M. Fukushima and P. Tseng},
  Journal =      siamopt,
  Pages =        {724--739},
  Title =        {An implementable active-set algorithm for computing
                  a {B}-stationary point of the mathematical program
                  with linear complementarity constraints},
  Volume =       12,
  Year =         2002
}

@techreport{GHMSW86,
  Address =      {Stanford, CA},
  Author =       {P.E. Gill and S.J. Hammarling and W.Murray and
                  M.A. Saunders and M.H. Wright},
  Institution =  {Stanford University},
  Number =       {SOL86-1},
  Title =        {User's Guide for {LSSOL} ({Version} 1.0): {A}
                  {Fortran} package for constrained linear
                  least-squares and convex quadratic programming},
  Year =         1986
}

@InProceedings{GMS03,
  author =       "Gilbert, A. C. and Muthukrishnan, S. and Strauss, M
                  .J.",
  title =        "Approximation of functions over redundant
                  dictionaries using coherence",
  booktitle =    "14th Annual ACM-SIAM Symposium on Discrete
                  Algorithms",
  organization = "ACM",
  address =      "New York",
  year =         2003,
  page =         {243--252}
}

@article{GarcRest:1981,
  Author =       {U. Garc\'{\i}a-Palomares and A. Restuccia},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      MathProg,
  Pages =        {290-300},
  Title =        {A Global Quadratic Algorithm for Solving a System of
                  Mixed Equalities and Inequalities},
  Volume =       21,
  Year =         1981
}

@article{GarcRest:1983,
  Author =       {U. Garc\'{\i}a-Palomares and A. Restuccia},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      JOTA,
  Month =        {November},
  Number =       3,
  Pages =        {405-415},
  Title =        {Application of the {A}rmijo stepsize rule to the
                  solution of a nonlinear system of equalities and
                  inequalities},
  Volume =       41,
  Year =         1983
}

@mastersthesis{Garr:2008,
  Address =      {Vancouver},
  Author =       {M. F. Garrido},
  Month =        {August},
  School =       {Dept. Computer Science, University of British
                  Columbia},
  Title =        {An all-at-once approach for computing nonnegative
                  tensor factorizations},
  Year =         2008
}

@incollection{Gay:1996,
  Address =      {Philadelphia},
  Author =       {David M. Gay},
  Booktitle =    {Computational Differentiation: Techniques,
                  Applications, and Tools},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Editor =       {M. Berz and C. Bischof and G. Corliss and
                  A. Griewank},
  Pages =        {173--184},
  Publisher =    SIAMpub,
  Title =        {More {AD} of Nonlinear {AMPL} Models: Computing
                  {H}essian Information and Exploiting Partial
                  Separability},
  Year =         1996
}

@techreport{Gay:1997,
  Address =      {Murray Hill, NJ},
  Author =       {David M. Gay},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Institution =  {Computing Sciences Research Center, Bell
                  Laboratories},
  Month =        {April},
  Number =       {97-4-06},
  Title =        {Hooking Your Solver to {AMPL}},
  Year =         1997
}

@Article{GilbL89,
  author =       {Jean Charles Gilbert and Claude Lemar\`echal},
  title =        {Some numerical experiments with variable-storage
                  quasi-newton algorithms},
  journal =      MathProg,
  year =         1989,
  number =       45,
  pages =        {407--435}
}

@article{GillKroy:2004,
  Author =       {P. E. Gill and Julia Kroyan},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      siamopt,
  Number =       4,
  Pages =        {1-20},
  Title =        {Trust-search methods for unconstrained optimization},
  Volume =       12,
  Year =         2004
}

@article{GillMurr:1974,
  Author =       {P. E. Gill and W. Murray},
  Journal =      MathProg,
  Pages =        {311--350},
  Title =        {Newton-type methods for unconstrained and linearly
                  constrained optimization},
  Volume =       29,
  Year =         1974
}

@incollection{GillMurrPick:1977,
  Address =      {Wilkinson House, Jordan Hill Road, Oxford, England},
  Author =       {P. E. Gill and W. Murray and Susan M. Picken},
  Booktitle =    {The {NAG} {Fortran} Library Manual {Mark 6}},
  Chapter =      {E04},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Editor =       {{Numerical Algorithms Group Limited}},
  Note =         {Withdrawn March 13, 1988},
  Pages =        {170--220},
  Publisher =    {Numerical Algorithms Group Limited},
  Title =        {{E04UAF}, {E04VAF}, {E04VBF}, {E04WAF}, constrained
                  optimization using sequential augmented {Lagrangian}
                  methods},
  Year =         1977
}

@article{GillMurrPoncSaun:1992,
  Address =      {Philadelphia, PA, USA},
  Author =       {P. E. Gill and W. Murray and D. B. Poncele\'{o}n and
                  M. A. Saunders},
  Doi =          {http://dx.doi.org/10.1137/0613022},
  Issn =         {0895-4798},
  Journal =      siammatrix,
  Number =       1,
  Pages =        {292--311},
  Publisher =    {SIAM},
  Title =        {Preconditioners for indefinite systems arising in
                  optimization},
  Volume =       13,
  Year =         1992
}

@techreport{GillMurrSaun:1995,
  Address =      {Stanford University, Stanford},
  Author =       {P. E. Gill and W. Murray and M. A. Saunders},
  Institution =  {Department of Operations Research},
  Number =       {SOL 95-4},
  Title =        {User's Guide for {QPOPT} 1.0: A {F}ortran package
                  for quadratic programming},
  Type =         {Tech. rep.},
  Year =         1995
}

@techreport{GillMurrSaun:1997,
  Address =      {Department of Operations Research, Stanford
                  University, Stanford, CA},
  Author =       {P. E. Gill and W. Murray and M. A. Saunders},
  Institution =  {Systems Optimization Laboratory},
  Month =        {May},
  Number =       {98-1},
  Title =        {User's Guide for {SNOPT 5.3}: A {Fortran} Package
                  for Large-scale Nonlinear Programming},
  Type =         {Tech. rep.},
  Year =         1997
}

@techreport{GillMurrSaun:1997a,
  Address =      {University of California, San Diego},
  Author =       {P. E. Gill and W. Murray and M. A. Saunders},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Institution =  {Department of Mathematics},
  Number =       {Report NA 97-4},
  Title =        {User's Guide for {SQOPT} 5.3: a {F}ortran Package
                  for Large-Scale Linear and Quadratic Programming},
  Type =         {Technical Report},
  Year =         1997
}

@techreport{GillMurrSaun:1997b,
  Address =      {Department of Operations Research, Stanford
                  University, Stanford, CA},
  Author =       {P. E. Gill and W. Murray and M. A. Saunders},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Institution =  {Systems Optimization Laboratory, Stanford
                  University},
  Month =        {August},
  Number =       {97-3},
  Title =        {{SNOPT}: An {SQP} Algorithm for Large-Scale
                  Constrained Optimization},
  Year =         1997
}

@article{GillMurrSaun:2002,
  Author =       {P. E. Gill and W. Murray and M. A. Saunders},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      siamopt,
  Number =       4,
  Pages =        {979--1006},
  Title =        {{SNOPT}: An {SQP} algorithm for large-scale
                  constrained optimization},
  Volume =       12,
  Year =         2002
}

@article{GillMurrSaun:2005,
  Author =       {P. E. Gill and W. Murray and M. A. Saunders},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      siamreview,
  Number =       1,
  Pages =        {99--131},
  Title =        {{SNOPT}: An {SQP} algorithm for large-scale
                  constrained optimization},
  Volume =       47,
  Year =         2005
}

@article{GillMurrSaunWrig:1989,
  title =        {A practical anti-cycling procedure for linearly
                  constrained optimization},
  author =       {Gill, P.E. and Murray, W. and Saunders, M.A. and
                  Wright, M.H.},
  journal =      MathProg,
  volume =       45,
  number =       1,
  pages =        {437--474},
  year =         1989
}

@inproceedings{GillMurrSaunWrig:1990,
  Author =       {P. E. Gill and W. Murray and M. A. Saunders and
                  Margaret H. Wright},
  Booktitle =    {Reliable Numerical Computation},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Editor =       {M. G. Cox and S. J. Hammarling},
  Pages =        {113--138},
  Publisher =    OxfordPress,
  Title =        {A {Schur}-Complement Method for Sparse Quadratic
                  Programming},
  Year =         1990
}

@article{GillMurrSaunWrig:1991,
  Abstract =     {Active-set quadratic programming (QP) methods use a
                  working set to define the search direction and
                  multiplier estimates. In the method proposed by
                  Fletcher in 1971, and in several subsequent
                  mathematically equivalent methods, the working set
                  is chosen to control the inertia of the reduced
                  Hessian, which is never permitted to have more than
                  one nonpositive eigenvalue. (Such methods will be
                  called inertia-controlling.) This paper presents an
                  overview of a generic inertia-controlling QP method,
                  including the equations satisfied by the search
                  direction when the reduced Hessian is positive
                  definite, singular and indefinite. Recurrence
                  relations are derived that define the search
                  direction and Lagrange multiplier vector through
                  equations related to the Karush-Kuhn-Tucker system.
                  Discussion is included of connections with
                  inertia-controlling methods that maintain an
                  explicit factorization of the reduced Hessian
                  matrix.},
  Author =       {P. E. Gill and W. Murray and M. A. Saunders and
                  M. H. Wright},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      siamreview,
  Number =       1,
  Pages =        {1--36},
  Title =        {Inertia-controlling methods for general quadratic
                  programming},
  Volume =       33,
  Year =         1991
}

@incollection{GillMurrSaunWrig:1992,
  Author =       {P. E. Gill and W. Murray and M. A. Saunders and
                  Margaret H. Wright},
  Booktitle =    {Advances in Optimization and Parallel Computing},
  Editor =       {P. M. Pardalos},
  Pages =        {101-128},
  Publisher =    {Elsevier},
  Title =        {Some Theoreical Properties of an augmented
                  {L}agrangian Merit Function},
  Year =         1992
}

@book{GillMurrWrig:1981,
  Address =      {London},
  Author =       {P. E. Gill and W. Murray and Margaret H. Wright},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Pages =        {xvi+401},
  Publisher =    Academic,
  Title =        {Practical Optimization},
  Year =         1981
}

@article{GillSaunShin:1996,
  Author =       {P. E. Gill and M. A. Saunders and Joseph
                  R. Shinnerl},
  Date-Modified ={2007-09-06 10:22:11 -0700},
  Journal =      siammatrix,
  Local-Url =
                  {file://localhost/Users/mpf/papers/GillSaunShinn96.pdf},
  Month =        {January},
  Number =       1,
  Pages =        {35--46},
  Title =        {On the stability of {C}holesky factorization for
                  symmetric quasidefinite systems},
  Volume =       17,
  Year =         1996
}

@Techreport{GoK08,
  author =       "Gonzaga, C. C. and Karas, E. W.",
  title =        "Optimal steepest descent algorithms for
                  unconstrained convex problems: fine timing
                  Nesterov's method",
  institution =  "Departnient of Mathematics, Federal University of
                  Santa Catarina",
  address =      "Florian\'opolis",
  year =         2008,
  month =        "August"
}

@Article{GoY05,
  author =       "Goldfarb, D. and Yin, W.",
  title =        "Second-order cone programming methods for total
                  variation-based image restoration",
  journal =      siamcomp,
  year =         2005,
  volume =       27,
  page =         {622--645}
}

@article{GoluGrei:2003,
  Author =       {Gene H. Golub and Chen Greif},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      siamscicomp,
  Number =       6,
  Pages =        {2076--2092},
  Title =        {On solving block-structured indefinite linear
                  systems},
  Volume =       24,
  Year =         2003
}

@article{GoluGreiVara:2006,
  Author =       {G.H. Golub and C. Greif and J.M. Varah},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      siammatrix,
  Number =       3,
  Pages =        {779-792},
  Title =        {An Algebraic Analysis of a Block Diagonal
                  Preconditioner for Saddle Point Systems},
  Volume =       27,
  Year =         2006
}

@article{GoluHansOLea:1999,
  Author =       {G. H. Golub and P. C Hansen and D. P. O'Leary},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      siammatrix,
  Number =       1,
  Pages =        {185-194},
  Title =        {Tikhonov Regularization and Total Least Squares},
  Volume =       21,
  Year =         1999
}

@book{GoluLoan:1989,
  Address =      {Baltimore},
  Author =       {G. H. Golub and C. F. Van Loan},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Edition =      {second},
  Publisher =    {Johns Hopkins University Press},
  Title =        {Matrix Computations},
  Year =         1989
}

@article{GoluMatt:1991,
  Abstract =     {We consider the following problem: Compute a vector
                  $x$ such that $\Vert Ax-b\Vert_2 = \min$, subject to
                  the constraint $\Vert x\Vert_2 = \alpha$. A new
                  approach to this problem based on Gauss quadrature
                  is given. The method is especially well suited when
                  the dimensions of $A$ are large and the matrix is
                  sparse.  It is also possible to extend this
                  technique to a constrainted quadratic form: For a
                  symmetric matrix $A$ we consider the minimization of
                  $x^TAx - 2b^Tx$ subject to the constraint $\Vert
                  x\Vert_2 = \alpha$.  Some numerical examples are
                  given.  },
  Author =       {Gene H. Golub and Urs von Matt},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      {Numer. Math.},
  Pages =        {561--580},
  Title =        {Quadratically constrained least squares and
                  quadratic problems},
  Volume =       59,
  Year =         1991
}

@article{GoluvonM:1991,
  Abstract =     {We consider the following problem: Compute a vector
                  $x$ such that $\Vert Ax-b\Vert_2 = \min$, subject to
                  the constraint $\Vert x\Vert_2 = \alpha$. A new
                  approach to this problem based on Gauss quadrature
                  is given. The method is especially well suited when
                  the dimensions of $A$ are large and the matrix is
                  sparse.  It is also possible to extend this
                  technique to a constrainted quadratic form: For a
                  symmetric matrix $A$ we consider the minimization of
                  $x^TAx - 2b^Tx$ subject to the constraint $\Vert
                  x\Vert_2 = \alpha$.  Some numerical examples are
                  given.  },
  Author =       {Gene H. Golub and Urs von Matt},
  Date-Added =   {2007-12-13 11:48:35 -0800},
  Date-Modified ={2007-12-13 11:48:35 -0800},
  Journal =      {Numer. Math.},
  Pages =        {561--580},
  Title =        {Quadratically constrained least squares and
                  quadratic problems},
  Volume =       59,
  Year =         1991
}

@techreport{GondGrot:2006,
  Author =       {J. Gondzio and A. Grothey},
  Date-Added =   {2007-10-12 18:19:15 -0700},
  Date-Modified ={2007-10-12 18:20:31 -0700},
  Institution =  {School of Mathematics, University of Edinburgh},
  Number =       {MS-06-005},
  Title =        {A new unblocking technique to warmstart
                  interior-point methods based on sensitivity
                  analysis},
  Type =         {Tech. rep.},
  Year =         2006
}

@techreport{Gonz:2003,
  Address =      {Santa Catarina, Brazil},
  Author =       {C. C. Gonzaga},
  Date-Modified ={2007-07-26 16:41:38 -0700},
  Institution =  {Dept.~of Mathematics, Federal University of Santa
                  Catarina},
  Month =        {April},
  Title =        {Generation of degenerate linear programming
                  problems},
  Year =         2003
}

@article{GotsGuShef:2003,
  Author =       {C. Gotsman and X. Gu and A. Sheffer},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      {ACM Transactions on Graphics},
  Number =       3,
  Pages =        {358--363},
  Title =        {Fundamentals of Spherical Parameterization for {3D}
                  Meshes},
  Volume =       22,
  Year =         2003
}

@Article{GouLeyToi:2004,
  author =       {N. I. M. Gould and S. Leyffer and \mbox{Ph.}
                  L. Toint},
  title =        {A multidimensional filter algorithm for nonlinear
                  equations and nonlinear least-squares},
  journal =      siamopt,
  year =         2004,
  volume =       15,
  number =       1,
  pages =        {17--38},
}

@article{Goul:1989,
  Author =       {N. I. M. Gould},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      SIAMNumAnal,
  Pages =        {107--128},
  Title =        {On the convergence of a sequential penalty function
                  method for constrained minimization},
  Volume =       26,
  Year =         1989
}

@article{GoulHribNoce:2001,
  Author =       {Nicholas I. M. Gould and Mary E. Hribar and Jorge
                  Nocedal},
  Doi =          {10.1137/S1064827598345667},
  Journal =      siamcomp,
  Keywords =     {nonlinear optimization; conjugate gradient method;
                  quadratic programming; preconditioning; iterative
                  refinement},
  Number =       4,
  Pages =        {1376-1395},
  Publisher =    {SIAM},
  Title =        {On the Solution of Equality Constrained Quadratic
                  Programming Problems Arising in Optimization},
  Url =          {http://link.aip.org/link/?SCE/23/1376/1},
  Volume =       23,
  Year =         2001
}

@article{ErwayMarcia:2012,
  title =        {Limited-memory {BFGS} systems with diagonal updates},
  author =       {Erway, J.B. and Marcia, R.F.},
  journal =      {Linear Algebra and its Applications},
  year =         2012,
  pages =        {333--334},
  publisher =    {Elsevier}
}

@article{ErwayMarcia:2011,
  title =        {A backward stability analysis of diagonal pivoting
                  methods for solving unsymmetric tridiagonal systems
                  without interchanges},
  author =       {Erway, J.B. and Marcia, R.F.},
  journal =      {Numerical Linear Algebra with Applications},
  volume =       18,
  number =       1,
  pages =        {41--54},
  year =         2011,
  publisher =    {Wiley Online Library}
}

@article{Ye:1992,
  title =        {On the finite convergence of interior-point
                  algorithms for linear programming},
  author =       {Ye, Yinyu},
  journal =      mathprog,
  volume =       57,
  number =       {1-3},
  pages =        {325--335},
  year =         1992
}

@article{Hare:2009,
  title =        {A proximal method for identifying active manifolds},
  author =       {Hare, WL},
  journal =      compapplopt,
  volume =       43,
  number =       2,
  pages =        {295--306},
  year =         2009,
  publisher =    {Springer}
}

@article{yamashita2004identification,
  title =        {On the identification of degenerate indices in the
                  nonlinear complementarity problem with the proximal
                  point algorithm},
  author =       {Yamashita, Nobuo and Dan, Hiroshige and Fukushima,
                  Masao},
  journal =      {Mathematical programming},
  volume =       99,
  number =       2,
  pages =        {377--397},
  year =         2004,
  publisher =    {Springer}
}

@misc{Alipanahi:2012,
  title =        {Determining Protein Structures from {NOESY} Distance
                  Constraints by Semidefinite Programming},
  author =      {Babak Alipanahi and Nathan Krislock and Ali Ghodsi
                  and Henry Wolkowicz and Logan Donaldson and Ming Li},
  year =         2012,
  note =         {To appear in {\it Journal of Computational Biology}}
}

@article{GoulLuciRomaToin:1999,
  Author =       {Nicholas I. M. Gould and Stefano Lucidi and Massimo
                  Roma and Philippe L. Toint},
  Doi =          {10.1137/S1052623497322735},
  Journal =      siamopt,
  Keywords =     {trust-region subproblem; Lanczos method; conjugate
                  gradients; preconditioning},
  Local-Url =
                  {file://localhost/Users/mpf/papers/GoulLuciToin99.pdf},
  Number =       2,
  Pages =        {504-525},
  Publisher =    {SIAM},
  Title =        {Solving the Trust-Region Subproblem using the
                  Lanczos Method},
  Url =          {http://link.aip.org/link/?SJE/9/504/1},
  Volume =       9,
  Year =         1999
}

@article{GoulOrbaToin:2003,
  Author =       {N. I. M. Gould and D. Orban and
                  {\mbox{Ph}}. L. Toint},
  Date-Modified ={2007-09-14 15:58:13 -0700},
  Journal =      acmmathsoft,
  Local-Url =    {file://localhost/Users/mpf/papers/CUTEr.ps},
  Month =        dec,
  Number =       4,
  Pages =        {373--394},
  Title =        {{CUTEr} and {SifDec}: A Constrained and
                  Unconstrained Testing Environment, revisited},
  Url =          {http://doi.acm.org/10.1145/962437.962439},
  Volume =       29,
  Year =         2003
}

@Article{GoulOrbaToin:2004,
  author =       {N.I.M. Gould and D. Orban and {Ph}.L. Toint},
  title =        {{GALAHAD}, a library of thread-safe {Fortran} 90
                  packages for large-scale nonlinear optimization},
  journal =      acmmathsoft,
  volume =       29,
  number =       4,
  pages =        {353-372},
  year =         2004
}

@InCollection{GoulToin:2000,
  author =       {N. I. M. Gould and \mbox{Ph}. L. Toint},
  title =        {{SQP} methods for large-scale nonlinear programming},
  booktitle =    {System Modelling and Optimization, Methods, Theory
                  and Applications},
  pages =        {149-178},
  publisher =    {Kluwer Academic},
  address =      {Boston},
  year =         2000,
  editor =       {M. J. D. Powell and S. Scholtes}
}

@InCollection{GoulToin:2002a,
  author =       {N. I. M. Gould and \mbox{Ph}. L. Toint},
  title =        {Numerical methods for large-scale non-convex
                  quadratic programming},
  booktitle =    {Trends in Industrial and Applied Mathematics},
  pages =        {149-179},
  publisher =    {Kluwer Academic},
  address =      {Deordrecht, The Netherlands},
  year =         2002,
  editor =       {A. H. Siddiqi and M. Kocvara},
}

@Article{Gwinner:1985,
  author =       "J. Gwinner",
  title =        "An extension lemma and homogeneous programming",
  journal =      "Journal of Optimization Theory and Applications",
  year =         1985,
  volume =       47,
  pages =         {321--336},
}

@incollection{PilloGrippo:1984,
  author =       {G. Di Pillo and L. Grippo},
  title =        {A class of continuously differentiable exact penalty
                  function algorithms for nonlinear programming
                  problems},
  booktitle =    {System Modelling and Optimization},
  editor =       {E. P. Toft-Christensen},
  publisher =    {Springer-Verlag},
  address =      {Berlin},
  year =         1984,
  pages =        {246??56}
}
@InCollection{Fletcher:1973,
  author =       {R. Fletcher},
  title =        {A Class of Methods for Non-Linear Programming {III}:
                  Rates of Convergence},
  booktitle =    {Numerical Methods for Nonlinear Optimization},
  editors =      {F. A. Lootsma},
  publisher =    {Academic Press},
  address =      {NY},
  pages =        {371--393},
  year =         1973,
}

@Article{AvelinoVicente:2003,
  author =       {C. P. Avelino and L. N. Vicente},
  title =        {Updating the Multipliers Associated with Inequality
                  Constraints in an Augmented Lagrangian Multiplier
                  Method},
  journal =      jota,
  year =         2003,
  volume =       119,
  number =       2,
  pages =        {215--233}
}

@Article{Fletcher:1973b,
  author =       {R. Fletcher},
  title =        {An exact penalty function for nonlinear programming
                  with inequalities},
  journal =      mathprog,
  year =         1973,
  volume =       5,
  pages =        {129--150}
}

@InCollection{Fletcher:1975,
  author =       {R. Fletcher},
  title =        {An ideal penalty function for constrained
                  optimization},
  booktitle =    {Nonlinear Prog.},
  pages =        {121-163},
  publisher =    {Academic Press},
  year =         1975,
  editor =       {O. Mangasarian and R. Meyer and S. Robinson},
  volume =       2
}

@Article{GoulToin:2002b,
  Abstract =     {We consider a working-set method for solving
                  large-scale quadratic programming problems for which
                  there is no requirement that the objective function
                  be convex. The methods are iterative at two levels,
                  one level relating to the selection of the current
                  working set, and the second due to the method used
                  to solve the equality-constrained problem for this
                  working set. A preconditioned conjugate gradient
                  method is used for this inner iteration, with the
                  preconditioner chosen especially to ensure
                  feasibility of the iterates. The preconditioner is
                  updated at the conclusion of each outer iteration to
                  ensure that this feasibility requirement
                  persists. The well-known equivalence between the
                  conjugate-gradient and Lanczos methods is exploited
                  when finding directions of negative
                  curvature. Details of an implementation---the
                  Fortran 90 package {\tt QPA} in the forthcoming {\sf
                  GALAHAD} library---are given.},
  author =       {Nicholas I. M. Gould and {\mbox{Ph}}. L. Toint},
  title =        {An iterative working-set method for large-scale
                  nonconvex quadratic programming},
  journal =      appnummath,
  year =         2002,
  volume =       43,
  pages =        {109-128}
}

@article{GrN03,
  Abstract =     {The purpose of this correspondence is to generalize
                  a result by Donoho and Huo and Elad and Bruckstein
                  on sparse representations of signals in a union of
                  two orthonormal bases for $\mathbb{R}^N$. We
                  consider general (redundant) dictionaries for
                  $\mathbb{R}^N$, and derive sufficient conditions for
                  having unique sparse representations of signals in
                  such dictionaries. The special case where the
                  dictionary is given by the union of $L \geq 2$
                  orthonormal bases for $\mathbb{R}^N$ is studied in
                  more detail. In particular, it is proved that the
                  result of Donoho and Huo, concerning the replacement
                  of the $\ell^0$ optimization problem with a linear
                  programming problem when searching for sparse
                  representations, has an analog for dictionaries that
                  may be highly redundant.},
  Author =       {R{\'e}mi Gribonval and Morten Nielsen},
  Journal =      ieeetransinfo,
  Keywords =     {Dictionaries, Grassmannian frames, linear
                  programming, mutually incoherent bases, nonlinear
                  approximation, sparse representations},
  Month =        {December},
  Number =       12,
  Pages =        {3320--3325},
  Title =        {Sparse Representations in Unions of Bases},
  Url =
                  {http://ieeexplore.ieee.org/xpls/abs_all.jsp?arnumber=1255564&isnumber=28084},
  Volume =       49,
  Year =         2003
}

@InCollection{GranBoyd:2008,
  author =       {M. Grant and S. Boyd},
  editor =       {V. Blondel, S. Boyd, and H. Kimura},
  title =        {Lecture Notes in Control and Information Sciences},
  chapter =      {Graph implementations for nonsmooth convex programs},
  publisher =    {Springer},
  year =         2008,
  pages =        {95--110}
}

@article{GreiRees:2007,
  Abstract =     {We explore a preconditioning technique applied to
                  the problem of solving linear systems arising from
                  primal-dual interior point algorithms in linear and
                  quadratic programming.  The preconditioner has the
                  attractive property of improved eigenvalue
                  clustering with increased illconditioning of the
                  (1,1) block of the saddle point matrix. It fits well
                  into the optimization framework since the interior
                  point iterates yield increasingly ill-conditioned
                  linear systems as the solution is approached. We
                  analyze the spectral characteristics of the
                  preconditioner, utilizing projections onto the null
                  space of the constraint matrix, and demonstrate
                  performance on problems from the NETLIB and CUTEr
                  test suites. The numerical experiments include
                  results based on inexact inner iterations.},
  Author =       {C. Greif and T. Rees},
  Journal =      siamcomp,
  Number =       5,
  Pages =        {1992-2007},
  Title =        {A Preconditioner for Linear Systems Arising from
                  Interior Point Optimization Methods},
  Url =          {http://www.cs.ubc.ca/~greif/Papers/rg2006.pdf},
  Volume =       29,
  Year =         2007
}

@Article{Gribonval2003,
  author =       "Gribonval, R. and Nielsen. M.",
  title =        "Sparse representations in unions of bases",
  journal =      "Information Theory, IEEE Transactions",
  year =         2003,
  volume =       49,
  page =         {3320--3325}
}


@Article{Wright:2002,
  author =       {S. J. Wright},
  title =        {Modifying {SQP} for degenerate problems},
  journal =      siamopt,
  year =         2002,
  volume =       13,
  number =       2,
  pages =        {470--497}
}

@article{GrifStew:1961,
  Author =       {R. E. Griffith and R. A. Stewart},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      ManageSci,
  Pages =        {379-392},
  Title =        {A Nonlinear Programming Technique for the
                  Optimization of Continuous Processing Systems},
  Volume =       7,
  Year =         1961
}

@article{grippo1994class,
  title =        {A class of unconstrained minimization methods for
                  neural network training},
  author =       {Grippo, L.},
  journal =      optimmeth,
  volume =       4,
  number =       2,
  pages =        {135--150},
  year =         1994,
  publisher =    {Taylor \& Francis}
}

@Article{GripScia:1999,
  author =       {L. Grippo and M. Sciandrone},
  title =        {On the Convergence of the Block Nonlinear
                  Gauss-Seidel Method under Convex Constraints},
  journal =      {Operations Research Letter 26},
  year =         1999,
  pages =        {127-136}
}

@techreport{GrodWolk:2005,
  Abstract =     {We present a new method for regularization of
                  ill-conditioned problems, such as those that arise
                  in image restoration or mathematical processing of
                  medical data. The method extends the traditional
                  trust-region subproblem, TRS, approach that makes
                  use of the L-curve maximum curvature criterion, a
                  strategy recently proposed to find a good
                  regularization parameter. We use derivative
                  information, and properties of an algorithm for
                  solving the TRS, to efficiently move along points on
                  the L-curve and reach the point of maximum
                  curvature. We do not find a complete
                  characterization of the L-curve. A MATLAB code for
                  the algorithm is tested and a comparison to the
                  conjugate gradient least squares, CGLS, approach is
                  given and analyzed.  },
  Address =      {Waterloo, Canada},
  Author =       {Oleg Grodzevich and Henry Wolkowicz},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Institution =  {Department of Combinatorics \& Optimization,
                  University of Waterloo},
  Keywords =     {Regularization, trust region subproblem,
                  ill-conditioned problems, L-curve, image
                  restoration},
  Month =        {May},
  Number =       {Research Report CORR 2005-11},
  Title =        {Regularization using a parameterized trust region
                  subproblem},
  Year =         2005
}

@article{GuddWackZule:1984,
  Author =       {J\"{u}rgen Guddat and Hansj\"{o}rg Wacker and
                  W. Zulehner},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      MathProgStudy,
  Pages =        {79-96},
  Title =        {On Imbedding and Parametric Optimization---A Concept
                  of a Globally Convergent Algorithm for Nonlinear
                  Optimization Problems},
  Volume =       21,
  Year =         1984
}

@Techreport{HGP08,
  author =       "Hoda, S. and Gilpin, A. and Pefla, J.",
  title =        "Smoothing techniques for computing Nash equilibria
                  of sequential games",
  institution =  "Carnegie Mellon University",
  address =      "Pittsburg",
  year =         2008,
  month =        "March"
}

@techreport{HYZ07,
  Address =      {Rice University, Houston, TX},
  Author =       {Elaine Hale and Wotao Yin and Yin Zhang},
  Institution =  {Department of Computational and Applied Mathematics},
  Number =       {TR07-07},
  Title =        {A Fixed-Point Continuation Method for
                  $\ell1$-Regularized Minimization with Applications
                  to Compressed Sensing},
  Year =         2007
}

@article{Hage:1987,
  Author =       {W. W. Hager},
  Issn =         {0022-3239},
  Journal =      JOTA,
  Mrclass =      {90C30 (49D07 49D29)},
  Mrnumber =     {89j:90220},
  Number =       1,
  Pages =        {37--71},
  Title =        {Dual techniques for constrained optimization},
  Volume =       55,
  Year =         1987
}

@article{HaleYinZhang:2009,
  authors =      {Elaine T. Hale, Wotao Yin, Yin Zhang},
  journal =      {J. Comp. Math.},
  volume =       28,
  number =       2,
  year =         2010,
  pages =        {170??94},
  doi =          {doi:10.4208/jcm.2009.10-m1007},
  title =        {Fixed-point continuation applied to compressed
                  sensing: implementation and numerical experiments}
}

@book{Hampel,
  Author =       {Frank R. Hampel and Elvezio M. Ronchetti and Peter
                  J. Rousseeuw and Werner A. Stahel},
  Publisher =    {Wiley},
  Title =        {Robust Statistics: The Approach Based on Influence
                  Functions},
  Edition =      {2nd},
  Year =         1986
}

@article{HanMang:1979,
  Author =       {S.-P. Han and O. L. Mangasarian},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      MathProg,
  Pages =        {251--269},
  Title =        {Exact penalty functions in nonlinear programming},
  Volume =       17,
  Year =         1979
}

@article{Hans:1992,
  Abstract =     {When discrete ill-posed problems are analyzed and
                  solved by various numerical regularization
                  techniques, a very convenient way to display
                  information about the regularized solution is to
                  plot the norm or seminorm of the solution versus the
                  norm of the residual vector. In particular, the
                  graph associated with Tikhonov regularization plays
                  a central role. The main purpose of this paper is to
                  advocate the use of this graph in the numerical
                  treatment of discrete ill-posed problems. The graph
                  is characterized quantitatively, and several
                  important relations between regularized solutions
                  and the graph are derived. It is also demonstrated
                  that several methods for choosing the regularization
                  parameter are related to locating a characteristic
                  L-shaped ``corner'' of the graph.  },
  Author =       {Per Christian Hansen},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      siamreview,
  Keywords =     {discrete ill-posed problems, least squares,
                  generalized SVD, regularization},
  Pages =        {561--580},
  Title =        {Analysis of discrete ill-posed problems by means of
                  the {L}-curve},
  Volume =       34,
  Year =         1992
}

@book{Hans:1998,
  Address =      {Philadelphia},
  Author =       {P. C. Hansen},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Publisher =    SIAMPub,
  Title =        {Rank-Deficient and Discrete Ill-Posed Problems},
  Year =         1998
}

@article{HansOLea:1993,
  Abstract =     {Regularization algorithms are often used to produce
                  reasonable solutions to ill-posed problems. The
                  L-curve is a plot---for all valid regularization
                  parameters---of the size of the regularized solution
                  versus the size of the corresponding residual. Two
                  main results are established. First a unifying
                  characterization of various regularization methods
                  is given and it is shown that the measurement of
                  ``size'' is dependent on the particular
                  regularization method chosen. For example, the
                  2-norm is appropriate for Tikhonov regularization,
                  but a 1-norm in the coordinate system of the
                  singular value decomposition (SVD) is relevant to
                  truncated SVD regularization. Second, a new method
                  is proposed for choosing the regularization
                  parameter based on the L-curve, and it is shown how
                  this method can be implemented efficiently. The
                  method is compared to generalized cross validation
                  and this new method is shown to be more robust in
                  the presence of correlated errors.  },
  Author =       {Per Christian Hansen and Dianne Prost O'Leary},
  Date-Modified ={2008-01-01 21:28:50 -0800},
  Journal =      siamscicomp,
  Keywords =     {ill-posed problems, regularization, L-curve,
                  parameter choice, generalized cross validation,
                  discrepancy principle},
  Local-Url =    {file://localhost/Users/mpf/papers/HansOlea93.pdf},
  Month =        {November},
  Number =       6,
  Pages =        {1487--1503},
  Title =        {The use of the {L}-curve in the regularization of
                  discrete ill-posed problems},
  Volume =       14,
  Year =         1993
}

@Book{HastTibsFrie:2001,
  author =       {T. Hastie and R. Tibshirani and J. Friedman},
  title =        {The Elements of Statistical Learning. Data mining,
                  inference, and prediction},
  publisher =    {Springer},
  year =         2001,
}

@article{HazaPolaShas:2005,
  Author =       {Tamir Hazan and Simon Polak and Amnon Shashua},
  Date-Added =   {2007-09-13 22:03:22 -0700},
  Date-Modified ={2007-10-22 16:32:33 -0700},
  Doi =
                  {http://doi.ieeecomputersociety.org/10.1109/ICCV.2005.228},
  Issn =         {1550-5499},
  Journal =      {International Conference on Computer Vision},
  Pages =        {50-57},
  Publisher =    {IEEE Computer Society},
  Title =        {Sparse Image Coding Using a 3D Non-Negative Tensor
                  Factorization},
  Volume =       1,
  Year =         2005
}

@inproceedings{HennHerr:2005,
  Author =       {G. Hennenfent and F. J. Herrmann},
  Booktitle =    {SEG International Exposition and 75th Annual
                  Meeting},
  Title =        {Sparseness-constrained data continuation with
                  frames: Applications to missing traces and aliased
                  signals in {2/3-D}},
  Url =
                  {http://slim.eos.ubc.ca/Publications/Public/Conferences/SEG/hennenfent05seg.pdf},
  Year =         2005
}

@article{HennHerr:2007a,
  author =       {G. Hennenfent and F. J. Herrmann},
  title =        {Simply denoise: Wavefield reconstruction via
                  jittered undersampling},
  publisher =    {SEG},
  MONTH =        {May-June},
  year =         2008,
  journal =      geophysics,
  volume =       73,
  number =       3,
  pages =        {V19-V28},
  keywords =     {Fourier transforms; geophysical techniques; seismic
                  waves; seismology},
  url =          {http://link.aip.org/link/?GPY/73/V19/1},
  doi =          {10.1190/1.2841038}
}

@inproceedings{HennHerr:2007b,
  Author =       {G. Hennenfent and F. J. Herrmann},
  Booktitle =    {SEG International Exposition and 77th Annual
                  Meeting},
  Date-Added =   {2007-09-18 20:14:13 -0700},
  Date-Modified ={2007-09-18 20:14:13 -0700},
  Title =        {Random sampling: new insights into the
                  reconstruction of coarsely-sampled wavefields},
  Url =
                  {http://slim.eos.ubc.ca/Publications/Public/Conferences/SEG/2007/hennenfent07seg.pdf},
  Year =         2007
}

@inproceedings{HennHerr:2007c,
  Author =       {G. Hennenfent and F. J. Herrmann},
  Booktitle =    {EAGE 69th Conference \& Exhibition},
  Date-Added =   {2007-09-18 20:14:13 -0700},
  Date-Modified ={2007-09-18 20:14:13 -0700},
  Title =        {Irregular sampling: from aliasing to noise},
  Url =
                  {http://slim.eos.ubc.ca/Publications/Private/Conferences/EAGE/2007/hennenfent07eage.pdf},
  Year =         2007
}

@article{HerrHenn:2008,
  TITLE =        {Non-parametric seismic data recovery with curvelet
                  frames},
  AUTHOR =       {F. J. Herrmann and Gilles Hennenfent},
  JOURNAL =      {Geophys. J. Int.},
  YEAR =         2008,
  VOLUME =       173,
  MONTH =        {April},
  PAGES =        {233-248},
  URL =
                  {http://slim.eos.ubc.ca/Publications/Public/Journals/CRSI.pdf},
  ABSTRACT =     {Seismic data recovery from data with missing traces
                  on otherwise regular acquisition grids forms a
                  crucial step in the seismic processing flow. For
                  instance, unsuccessful recovery leads to imaging
                  artifacts and to erroneous predictions for the
                  multiples, adversely affecting the performance of
                  multiple elimination. A non-parametric
                  transform-based recovery method is presented that
                  exploits the compression of seismic data volumes by
                  recently developed curvelet frames. The elements of
                  this transform are multidimensional and directional
                  and locally resemble wavefronts present in the data,
                  which leads to a compressible representation for
                  seismic data. This compression enables us to
                  formulate a new curvelet-based seismic data recovery
                  algorithm through sparsity-promoting inversion. The
                  concept of sparsity- promoting inversion is in
                  itself not new to geophysics. However, the recent
                  insights from the field of compressed sensing are
                  new since they clearly identify the three main
                  ingredients that go into a successful formulation of
                  a recovery problem, namely a sparsifying transform,
                  a sampling strategy that subdues coherent aliases
                  and a sparsity-promoting program that recovers the
                  largest entries of the curvelet-domain vector while
                  explaining the measurements. These concepts are
                  illustrated with a stylized experiment that stresses
                  the importance of the degree of compression by the
                  sparsifying transform. With these findings, a
                  curvelet- based recovery algorithms is developed,
                  which recovers seismic wavefields from seismic data
                  volumes with large percentages of traces missing.
                  During this construction, we benefit from the main
                  three ingredients of compressive sampling, namely
                  the curvelet compression of seismic data, the
                  existence of a favorable sampling scheme and the
                  formulation of a large- scale sparsity-promoting
                  solver based on a cooling method. The recovery
                  performs well on synthetic as well as real data and
                  performs better by virtue of the sparsifying
                  property of curvelets. Our results are applicable to
                  other areas such as global seismology.}
}

@article{Hest:1969,
  Author =       {M. R. Hestenes},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      JOTA,
  Number =       5,
  Pages =        {303--320},
  Title =        {Multiplier and Gradient Methods},
  Volume =       4,
  Year =         1969
}

@book{High:1998,
  Address =      {Philadelphia},
  Author =       {N. J. Higham},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Edition =      {Second},
  Isbn =         {0-89871-420-6},
  Pages =        {xvi+302},
  Publisher =    SIAMpub,
  Title =        {Handbook of Writing for the Mathematical Sciences},
  Year =         1998
}

@book{HockSchi:1981,
  Address =      {Berlin and New York},
  Author =       {W. Hock and K. Schittkowski},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Publisher =    SPRINGER,
  Series =       {Lecture Notes in Economics and Mathematical Systems
                  187},
  Title =        {Test Examples for Nonlinear Programming Codes},
  Year =         1981
}

@article{Horn:1979,
  Author =       {J. Horning},
  Journal =      {ACM SIGSOFT Software Engineering Notes},
  Note =         {Cited in \cite{trop84}},
  Number =       4,
  Pages =        6,
  Title =        {Note on Program Reliability},
  Volume =       4,
  Year =         1979
}

@book{HornJohn:1985,
  Author =       {R. A. Horn and Charles R. Johnson},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Isbn =         {0-521-30586-1},
  Pages =        {xiii+561},
  Publisher =    CambridgePress,
  Title =        {Matrix Analysis},
  Year =         1985
}

@book{HornJohn:1991,
  Author =       {R. A. Horn and Charles R. Johnson},
  Isbn =         {0-521-30587-X},
  Pages =        {viii+607},
  Publisher =    CambridgePress,
  Title =        {Topics in Matrix Analysis},
  Year =         1991
}



@book{HosL00,
  title =        {Applied logistic regression},
  author =       {Hosmer, D.W. and Lemeshow, S.},
  year =         2000,
  publisher =    {Wiley-Interscience}
}

@article{HuRalp:2004,
  Author =       {X. Hu and D. Ralph},
  Journal =      JOTA,
  Title =        {Convergence of a penalty method for mathematical
                  programs with complementarity constraints},
  Volume =       {forthcoming},
  Year =         2004
}

@InCollection{bertsekas-incremental:2010,
  title =        {{Incremental Gradient, Subgradient, and Proximal
                  Methods for Convex Optimization: A Survey}},
  author =       {Bertsekas, D.P.},
  editor =       {Suvrit Sra and Sebastian Nowozin and Stephen
                  J. Wright},
  booktitle =    {Optimization for machine learning},
  year =         2012,
  pages =        {85--115},
  chapter =      4,
  publisher =    {MIT Press}
}


@article{Hutchinson:1990,
  author =       {Hutchinson, M.F.},
  title =        {A stochastic estimator of the trace of the influence
                  matrix for laplacian smoothing splines},
  journal =      {Comm. Statist. Simulation Comput.},
  volume =       19,
  number =       2,
  pages =        {433-450},
  year =         1990,
  doi =          {10.1080/03610919008812866},
  URL =
                  {http://www.tandfonline.com/doi/abs/10.1080/03610919008812866},
  eprint =
                  {http://www.tandfonline.com/doi/pdf/10.1080/03610919008812866},
  abstract =     { An unbiased stochastic estimator of tr(I-A), where
                  A is the influence matrix associated with the
                  calculation of Laplacian smoothing splines, is
                  described. The estimator is similar to one recently
                  developed by Girard but satisfies a minimum variance
                  criterion and does not require the simulation of a
                  standard normal variable. It uses instead
                  simulations of the discrete random variable which
                  takes the values 1, -1 each with probability
                  1/2. Bounds on the variance of the estimator,
                  similar to those established by Girard, are obtained
                  using elementary methods. The estimator can be used
                  to approximately minimize generalised cross
                  validation (GCV) when using discretized iterative
                  methods for fitting Laplacian smoothing splines to
                  very large data sets. Simulated examples show that
                  the estimated trace values, using either the
                  estimator presented here or the estimator of Girard,
                  perform almost as well as the exact values when
                  applied to the minimization of GCV for n as small as
                  a few hundred, where n is the number of data
                  points. }
}

@article{IshuScho:1986,
  Author =       {V. S. Ishutkin and K. Sch\"{o}nefeld},
  Journal =      Computing,
  Pages =        {151-169},
  Title =        {On the Globalization of {Wilson}-type Optimization
                  Methods by Means of Generalized Reduced Gradient
                  Methods},
  Volume =       37,
  Year =         1986
}

@Techreport{JLNS07,
  author =       "Juditsky, A. and Lan, G. and Nemirovski, A. and
                  Shapiro, A.",
  title =        "Stochastic Approximation approach to Stochastic
                  Programming",
  institution =  "to appear in SIAM J. Optim.",
  year =         2007,
}

@book{JongJonkTwil:1986,
  Address =      {Frankfurt, Germany},
  Author =       {H. Th. Jongen and P. Jonker and F. Twilt},
  Publisher =    {Peter Lang Verlag},
  Title =        {Nonlinear Optimization in $\mathcal{R}^n$ II:
                  Transversality, Flows, Parametric Aspects},
  Year =         1986
}

@Techreport{KKW08,
  author =       "Kim, S. and Kojima, M. and Waki, H.",
  title =        "Exploiting sparsity in SDP relaxation for sensor
                  network localization, report B-447",
  institution =  "Tokyo Institute of Technology",
  address =      "Tokyo",
  year =         2008,
  month =        "October"
}

@Techreport{KPW06,
  author =       "Krislock, N. and Piccialli, V. and Wolkowicz, H.",
  title =        "Robust semidefinite programming approaches for
                  sensor network localization with anchors",
  institution =  "Department of Combinatorics and Optimization,
                  University of Waterloo",
  address =      "Waterloo",
  year =         2006,
  month =        "May"
}

@article{KanzQiQi:2003,
  Author =       {C. Kanzow and H. Qi and L. Qi},
  Journal =      JOTA,
  Pages =        {333-345},
  Title =        {On the minimum norm solution of linear programs},
  Volume =       116,
  Year =         2003
}

@article{Karl:1970,
  Author =       {L. Karlovitz},
  Journal =      {J. of Approx. Theory},
  Title =        {Construction of nearest points in the $\ell^p$, $p$
                  even and $\ell^1$ norms},
  Volume =       3,
  Year =         1970
}

@book{Kell:1995,
  Address =      {Philadelphia},
  Author =       {C. T. Kelley},
  Publisher =    {SIAM},
  Series =       {Frontiers in applied mathematics},
  Title =        {Iterative Methods for Linear and Nonlinear
                  Equations},
  Volume =       16,
  Year =         1995
}

@article{KellGoulWath:2000,
  Author =       {C. Keller and N. I. M. Gould and A. J. Wathen},
  Journal =      siammatrix,
  Number =       4,
  Pages =        {1300--1317},
  Title =        {Constraint Preconditioning for Indefinite Linear
                  Systems},
  Url =          {citeseer.ist.psu.edu/keller00constraint.html},
  Volume =       21,
  Year =         2000
}

@article{KimKimKim:2006,
  title =        {Blockwise sparse regression},
  author =       {Kim, Y. and Kim, J. and Kim, Y.},
  journal =      {Statistica Sinica},
  volume =       16,
  number =       2,
  pages =        {375--390},
  year =         2006
}

@Article{KimKohLustBoydGori:2007,
  Author =       {S.-J. Kim and K. Koh and M. Lustig and S. Boyd and
                  D. Gorinevsky},
  title =        {An Interior-Point Method for Large-Scale
                  {L1}-Regularized Least Squares},
  journal =      {IEEE J. Sel. Top. Signal Process.},
  year =         2007,
  volume =       1,
  number =       4,
  pages =        {606-617},
  doi =          {10.1109/JSTSP.2007.910971}
}

@Article{Kiw03,
  author =       "Kiwiel, K. C.",
  title =        "Convergence of Approximate and Incremental
                  Subgradient Methods for Convex Optimization",
  journal =      siamopt,
  year =         2003,
  volume =       14,
  page =         {807--840}
}

@Article{Kiw07,
  author =       "Kiwiel, K. C.",
  title =        "On Linear-Time Algorithms for the Continuous
                  Quadratic Knapsack Problem",
  journal =      "Journal of Optimization Theory and Applications",
  year =         2007,
  volume =       134,
  page =         {549--554}
}

@article{Kiw95,
  Author =       {Kiwiel, Krzysztof C.},
  Coden =        {AMOMBN},
  Fjournal =     {Applied Mathematics and Optimization. An
                  International Journal with Applications to
                  Stochastics},
  Issn =         {0095-4616},
  Journal =      {Appl. Math. Optim.},
  Keywords =     {Regularization, linear programs},
  Mrclass =      {90C08 (49J52 90C25)},
  Mrnumber =     {MR1340043 (96d:90051)},
  Mrreviewer =   {Stefan Scholtes},
  Number =       3,
  Pages =        {235--254},
  Title =        {Finding normal solutions in piecewise linear
                  programming},
  Volume =       32,
  Year =         1995
}

@article{Kiw95b,
  Author =       {Kiwiel, Krzysztof C.},
  Coden =        {LAAPAW},
  Fjournal =     {Linear Algebra and its Applications},
  Issn =         {0024-3795},
  Journal =      {Linear Algebra Appl.},
  Keywords =     {Regularization, linear programs},
  Mrclass =      {90C08 (49M37 90C30)},
  Mrnumber =     {MR1352835 (96g:90042)},
  Mrreviewer =   {Stephan Dempe},
  Pages =        {1--7},
  Title =        {Iterative schemes for the least {$2$}-norm solution
                  of piecewise linear programs},
  Volume =       229,
  Year =         1995
}

@Article{Kiw97,
  author =       "Kiwiel, K. C.",
  title =        "Proximal Minimization Methods with Generalized
                  {Bregman} Functions",
  journal =      "SIAM Journal on Control and Optimization",
  year =         1997,
  volume =       35,
  page =         {1142--1168}
}

@Article{KobeSuhl:2007,
  author =       {A. Koberstein and U. H. Suhl},
  title =        {Progress in the dual simplex method for large scale
                  {LP} problems: practical dual phase 1 algorithms},
  journal =      compapplopt,
  year =         2007,
  volume =       37,
  number =       1,
  pages =        {49-65},
  month =        {May},
  doi =          {10.1007/s10589-007-9022-3}
}

@techreport{Kold:2006,
  Author =       {T. G. Kolda},
  Institution =  {Sandia National Laboratories},
  Local-Url =    {file://localhost/Users/mpf/papers/Kold06.pdf},
  Title =        {Multilinear operators for higher-order
                  decompositions},
  Year =         2006
}

@article{KoldBade:2009,
  author =       {Tamara G. Kolda and Brett W. Bader},
  title =        {Tensor Decompositions and Applications},
  journal =      {SIAM Review},
  month =        {September},
  year =         2009,
  volume =       51,
  number =       3,
  pages =        {455--500},
  doi =          {10.1137/07070111X}
}

@book{Kull:1959,
  Address =      {New York},
  Author =       {Solomon Kullback},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Publisher =    {Wiley},
  Title =        {Information Theory and Statistics},
  Year =         1959
}

@Techreport{LLM06,
  author =       "G. Lan and Z. Lu and R. D. C. Monteiro",
  title =        "Primal-dual first-order methods with
                  $O(1/e)O(1/\epsilon)$ iteration-complexity for cone
                  programming",
  institution =  "School of Industrial and Systems Engineering,
                  Georgia Institute of Technology",
  address =      "Atlanta",
  year =         2006,
  month =        "December"
}

@Techreport{LMY08,
  author =       "Lu, Z. and Monteiro, R. D. C. and Yuan, M.",
  title =        "Convex optimization methods for dimension reduction
                  and coefficient estimation in multivariate linear
                  regression",
  institution =  "School of Industrial and Systems Engineering,
                  Georgia Institute of Technology",
  address =      "Atlanta",
  year =         2008,
  month =        "January",
  note =         "revised March 2009"
}

@Article{LNM07,
  author =       "Lu, Z. and Nemirovski, A. S. and Monteiro, R. D. C.",
  title =        "Large-scale semidefinite programming via a saddle
                  point Mirror-Prox algorithm",
  journal =      "Mathematical Programming",
  year =         2007,
  volume =       109,
  page =         {211--237}
}

@article {LST:2011,
  author =       {Liu, Yong-Jin and Sun, Defeng and Toh, Kim-Chuan},
  affiliation =  {Faculty of Science, Shenyang Aerospace University,
                  110136 Shenyang, People?ôs Republic of China},
  title =        {An implementable proximal point algorithmic
                  framework for nuclear norm minimization},
  journal =      {Mathematical Programming},
  publisher =    {Springer Berlin / Heidelberg},
  issn =         {0025-5610},
  keyword =      {Mathematics and Statistics},
  pages =        {1-38},
  url =          {http://dx.doi.org/10.1007/s10107-010-0437-8},
  note =         {10.1007/s10107-010-0437-8},
  year =         2011
}

@Techreport{LWY04,
  author =       "Liang, T.-C. and Wang, T.-C. and Ye, Y.",
  title =        "A gradient search method to round the semidefinite
                  programming relaxation solution for ad hoc wireless
                  sensor network localization",
  institution =  "Electrical Engineering, Stanford University",
  year =         2004,
  month =        "October"
}

@misc{Lars:2001,
  Author =       {R. M. Larsen},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Note =         {\url{http://sun.stanford.edu/~rmunk/PROPACK/}},
  Title =        {Combining implicit restart and partial
                  reorthogonalization in {L}anczos bidiagnalization},
  Year =         2001
}

@article{LathMoorVand:2000,
  Author =       {Lieven De Lathauwer and Bart De Moor and Joos
                  Vandewalle},
  Date-Added =   {2007-10-06 17:34:41 -0700},
  Date-Modified ={2007-10-06 17:35:04 -0700},
  Doi =          {10.1137/S0895479898346995},
  Journal =      {{SIAM} J. Matrix Anal. Appl.},
  Keywords =     {multilinear algebra; singular value decomposition;
                  higher-order tensor; rank reduction},
  Number =       4,
  Pages =        {1324-1342},
  Publisher =    {SIAM},
  Title =        {On the Best Rank-1 and Rank-(R[sub 1],R[sub
                  2],. . .,R[sub N]) Approximation of Higher-Order
                  Tensors},
  Url =          {http://link.aip.org/link/?SML/21/1324/1},
  Volume =       21,
  Year =         2000
}

@book{LawsHans:1995,
  Address =      {Philadelphia},
  Author =       {Charles L. Lawson and Richard J. Hanson},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Note =         {Originally published: Prentice-Hall, Englewood
                  Cliffs, NJ, 1974},
  Number =       15,
  Publisher =    SIAMpub,
  Series =       {Classics in Applied Mathematics},
  Title =        {Solving Least Squares Problems},
  Year =         1995
}

@article{LeeSeun:1999,
  Author =       {D. D. Lee and H. S. Seung},
  Journal =      {Nature},
  Pages =        {788--791},
  Title =        {Learning the parts of objects by non-negative matrix
                  factorization},
  Volume =       401,
  Year =         1999
}

@inproceedings{LeeSeun:2001,
  Author =       {D. D. Lee and H. S. Seung},
  Booktitle =    {Advances in Neural Information Processing Systems
                  13},
  Editor =       {Todd K.Leen and Thomas G. Dietterich and Volker
                  Tresp},
  Pages =        {556--562},
  Publisher =    {MIT Press},
  Title =        {Algorithms for non-negative matrix factorization},
  Year =         2001
}

@article{LemaNemiNest:1995,
  author =       {C. Lemar\'echal and A. Nemirovskii and Y Nesterov},
  title =        {New variants of bundle methods},
  year =         1995,
  pages =        {111--147},
  journal =      MathProg,
  volume =       69
}

@article{LewiOver:1996,
  Author =       {A. S. Lewis and M. L. Overton},
  Journal =      actanumerica,
  Pages =        {149--190},
  Title =        {Eigenvalue optimization},
  Volume =       {xx},
  Year =         1996
}

@article{NedBer:2000,
  title =        {{Convergence rate of incremental subgradient
                  algorithms}},
  author =       {Nedic, A. and Bertsekas, D.},
  journal =      {Stochastic Optimization: Algorithms and
                  Applications},
  pages =        {263--304},
  year =         2000,
  publisher =    {Kluwer Academic Pub}
}

@article{bertsekas:2010,
  title =        {{Incremental Gradient, Subgradient, and Proximal
                  Methods for Convex Optimization: A Survey}},
  author =       {Bertsekas, D.P.},
  year =         2010
}

@article{bertsekas1997new,
  title =        {{A new class of incremental gradient methods for
                  least squares problems}},
  author =       {Bertsekas, D.P.},
  journal =      siamopt,
  volume =       7,
  number =       4,
  pages =        {913--926},
  year =         1997,
  publisher =    {Citeseer}
}

@article{Levy:2005,
  title =        {A generic algorithm for solving inclusions},
  author =       {Levy, A.B.},
  journal =      siamopt,
  volume =       15,
  number =       2,
  pages =        {430--455},
  year =         2005,
}

@article{Lewis:1995,
  title =        {The convex analysis of unitarily invariant matrix
                  functions},
  author =       {Lewis, Adrian S.},
  journal =      jconvexanal,
  volume =       2,
  number =       1,
  pages =        {173--183},
  year =         1995
}

@misc{Leyf:2000,
  Author =       {S. Leyffer},
  Note =         {\verb+http://www.mcs.anl.gov/\~{}leyffer/MacMPEC.+},
  Title =        {{MacMPEC}: {AMPL} collection of {MPECs}},
  Year =         2000
}

@techreport{Leyf:2002,
  Author =       {S. Leyffer},
  Institution =  {University of Dundee},
  Month =        {Februaru},
  Title =        {The Penalty Interior Point Method fails to converge
                  for Mathematical Programs with Equilibrium
                  Constraints},
  Year =         2002
}

@techreport{Leyf:2005,
  Address =      {Illinois},
  Author =       {S. Leyffer},
  Institution =  {Mathematics and Computer Science Division, Argonne
                  National Laboratory},
  Keywords =     {multiobjective, complementarity, pareto},
  Month =        {September},
  Number =       {ANL/MCS-P1290-0905},
  Title =        {A note on multiobjective optimization and
                  complementarity constraints},
  Type =         {Preprint},
  Year =         2005
}

@Techreport{LiV08,
  author =       "Liu, Z. and Vandenberghe, L.",
  title =        "Interior-point method for nuclear norm approximation
                  with application to system identification",
  institution =  "Electrical Engineering Department, UCLA",
  address =      "Los Angeles",
  year =         2008
}

@article{Lin:2007,
  title =        {Projected gradient methods for nonnegative matrix
                  factorization},
  author =       {Chih-Jen Lin},
  journal =      {Neural Computation},
  volume =       19,
  number =       10,
  pages =        {2756--2779},
  year =         2007,
  publisher =    {MIT Press}
}

@article{LinMore:1999,
  Author =       {Chih-Jen Lin and Jorge J. Mor\'{e}},
  Issn =         {1064-8275},
  Journal =      SIAMComp,
  Number =       1,
  Pages =        {24--45},
  Publisher =    {SIAM},
  Title =        {Incomplete Cholesky Factorizations with Limited
                  Memory},
  Volume =       21,
  Year =         1999
}

@article{LinMore:1999b,
  Author =       {Ch.-J. Lin and J. J. Mor\'{e}},
  Journal =      siamopt,
  Number =       4,
  Pages =        {1100--1127},
  Title =        {Newton's Method for Large Bound-Constrained
                  Optimization Problems},
  Volume =       9,
  Year =         1999
}

@techreport{LiuSun:2001,
  Author =       {Xinwei Liu and Jie Sun},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Institution =  {National University of Singapore},
  Title =        {Generalized stationary points and an interior point
                  method for mathematical programs with equilibrium
                  constraints},
  Year =         2001
}

@article{Loan:2000,
  Author =       {C. F. Van Loan},
  Date-Added =   {2007-09-27 14:46:49 -0700},
  Date-Modified ={2007-09-27 14:54:56 -0700},
  Journal =      compapplmath,
  Month =        {November},
  Pages =        {85-100},
  Title =        {The ubiquitous {Kroneckar} product},
  Volume =       123,
  Year =         2000
}

@book{LoveMorrWeso:1988,
  Author =       {R. F. Love and J. G. Morris and G. O. Wesolowsky},
  Title =        {Facilities location: models and methods},
  Year =         1988,
  Address =      {New York},
  Publisher =    {North-Holland}
}

@Techreport{Lu08,
  author =       "Lu, Z.",
  title =        "Smooth optimization approach for sparse covariance
                  selection",
  institution =  "Department of Mathematics, Simon Fraser University",
  address =      "Burnaby",
  year =         2008,
  month =        "January",
  note =         "submitted to SIAM J. Optim."
}

@article{LuDo:2007,
  Author =       {Y. M. Lu and M. N. Do},
  Title =        {Multidimensional directional filter banks and
                  surfacelets},
  Journal =      ieeetransimproc,
  Volume =       16,
  Number =       4,
  Month =        {April},
  Pages =        {918--931},
  Year =         2007
}

@Article{LuT92,
  author =       "Luo, Z. Q. and Tseng, P.",
  title =        "On the linear convergence of descent methods for
                  convex essentially smooth minimization",
  journal =      siamcontrol,
  year =         1992,
  volume =       30,
  page =         {408--425}
}

@Article{LuT93,
  author =       "Luo, Z. Q. and Tseng, P.",
  title =        "On the convergence rate of dual ascent methods for
                  linearly constrained convex minimization",
  journal =      "Math. Oper. Res.",
  year =         1993,
  volume =       18,
  page =         {846--867}
}

@Article{LuT94,
  author =       "Luo, Z. Q. and Tseng, P.",
  title =        "Error bounds and convergence analysis of feasible
                  descent methods: a general approach",
  journal =      "Annals of Operations Research",
  year =         1993,
  volume =       46,
  page =         {157--178}
}

@Article{LuT94b,
  author =       "Luo, Z. Q. and Tseng, P.",
  title =        "On the rate of convergence of a distributed
                  asynchronous routing algorithm",
  journal =      "Automatic Control, IEEE Transactions",
  year =         1994,
  volume =       39,
  page =         {1123--1129}
}

@article{Luci:1987,
  Author =       {Lucidi, S.},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Fjournal =     {Journal of Optimization Theory and Applications},
  Journal =      jota,
  Number =       1,
  Pages =        {103--117},
  Title =        {A new result in the theory and computation of the
                  least-norm solution of a linear program},
  Volume =       55,
  Year =         1987
}

@article{Luci:1987b,
  Author =       {Lucidi, S.},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Fjournal =     {Optimization. A Journal of Mathematical Programming
                  and Operations Research},
  Journal =      {Optimization},
  Number =       6,
  Pages =        {809--823},
  Title =        {A finite algorithm for the least two-norm solution
                  of a linear program},
  Volume =       18,
  Year =         1987
}

@book{luenberger2008linear,
  title =        {{Linear and nonlinear programming}},
  author =       {Luenberger, D.G. and Ye, Y.},
  year =         2008,
  publisher =    {Springer Verlag}
}

@book{Luen:1984,
  Author =       {David G. Luenberger},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Edition =      {Second},
  Publisher =    AddisonWesley,
  Title =        {Linear and Nonlinear Programming},
  Year =         1984
}

@Article{Luo91,
  author =       "Luo, Z. Q.",
  title =        "On the convergence of the LMS algorithm with
                  adaptive learning rate for linear feedforward
                  networks",
  journal =      "Neural Computation",
  year =         1991,
  volume =       3,
  page =         {226--245}
}

@article{LuoPang:1994,
  Author =       {Z.-Q. Luo and J.-S. Pang},
  Journal =      MathProg,
  Pages =        {1--28},
  Title =        {Error bounds for analytic systems and their
                  applications},
  Volume =       67,
  Year =         1994
}

@proceedings{LuoPang:2000,
  Editor =       {Z.-Q. Luo and J.-S. Pang},
  Journal =      MathProg,
  Key =          {LuP00},
  Pages =        {221--410},
  Title =        {Error bounds in mathematical programming, {\rm
                  Math.\ Program.}},
  Volume =       88,
  Year =         2000
}

@book{LuoPangRalph:1996,
  Author =       {Z.-Q. Luo and J.-S. Pang and D. Ralph},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Publisher =    {Cambridge University Press},
  Title =        {Mathematical Programs with Equilibrium Constraints},
  Year =         1996
}

@techreport{LuoSturZhan:1997,
  Address =      {Erasmus University, Rotterdam, The Netherlands},
  Author =       {Z.-Q. Luo and J. F. Sturm and S. Zhang},
  Institution =  {Econometric Institute},
  Month =        {April},
  Number =       {No. 9719/A},
  Title =        {Duality results for conic convex programming},
  Type =         {Econometric Institute Report},
  Year =         1997
}

@article{blatt2008convergent,
  title =        {{A convergent incremental gradient method with a
                  constant step size}},
  author =       {Blatt, D. and Hero, A.O. and Gauchman, H.},
  journal =      siamopt,
  volume =       18,
  number =       1,
  pages =        {29--51},
  year =         2008,
  publisher =    {Citeseer}
}

@article{luo1993error,
  title =        {{Error bounds and convergence analysis of feasible
                  descent methods: A general approach}},
  author =       {Luo, Z.Q. and Tseng, P.},
  journal =      {Ann. Oper. Res.},
  volume =       46,
  number =       1,
  pages =        {157--178},
  year =         1993
}

@article{LustDonoPaul:2007a,
  Author =       {M. Lustig and D. L. Donoho and J. M. Pauly},
  Title =        {Sparse {MRI}: The application of compressed sensing
                  for rapid {MR} imaging},
  Journal =      {Mag. Resonance Med.},
  Volume =       58,
  Number =       6,
  Pages =        {1182--1195},
  Month =        {December},
  Year =         2007,
  DOI =          {10.1002/mrm.21391}
}

@misc{LustDonoPaul:2007b,
  Author =       {M. Lustig and D. L. Donoho and J. M. Pauly},
  Date-Added =   {2007-09-14 10:54:08 -0700},
  Date-Modified ={2007-09-14 14:52:20 -0700},
  Howpublished =
                  {\url{http://www.stanford.edu/~mlustig/SparseMRI.html}},
  Title =        {Sparse {MRI} {Matlab} code},
  Year =         2007
}

@article{LustDonoSantPaul:2007,
  Author =       {M. Lustig and D. L. Donoho and J. M. Santos and
                  J. M. Pauly},
  Title =        {Compressed Sensing {MRI}},
  Journal =      {IEEE Signal Process. Mag.},
  Volume =       25,
  Number =       2,
  Pages =        {72--82},
  Month =        {March},
  Year =         2007
}

@article{MGB08,
  Author =       {L. Meier and S. van de Geer and P. B{\"{u}}hlmann},
  Title =        {The Group {L}asso for Logistic Regression},
  Journal =      {J. Royal Statist. Soc. B},
  Volume =       70,
  Pages =        {53--71},
  Year =         2008
}

@Techreport{MGC08,
  author =       "S. Ma and D. Goldfarb and L. Chen",
  title =        "Fixed point and {Bregman} iterative methods for
                  matrix rank minimization",
  type =         "Report",
  number =       "08-78",
  institution =  "UCLA Computational and Applied Mathematics",
  year =         2008
}

@article{MGC:2009,
  author =       "S. Ma and D. Goldfarb and L. Chen",
  title =        "Fixed point and {Bregman} iterative methods for
                  matrix rank minimization",
  journal =      MathProg,
  volume =       128,
  number =       {1-2},
  pages =        {321-353},
  year =         2009
}

@misc{MOSEK,
  Date-Added =   {2007-12-13 11:47:47 -0800},
  Date-Modified ={2007-12-13 11:47:47 -0800},
  Howpublished = {Mathematical programming system,
                  \url{http://www.mosek.com}},
  Key =          {MOSEK},
  Year =         2007
}

@article{MR1052832,
  Author =       {Wright, S. J.},
  Coden =        {JOTABN},
  Date-Added =   {2007-10-20 15:30:07 -0700},
  Date-Modified ={2007-10-20 15:30:07 -0700},
  Fjournal =     {Journal of Optimization Theory and Applications},
  Issn =         {0022-3239},
  Journal =      jota,
  Mrclass =      {90C05 (90C06 90C20)},
  Mrnumber =     {MR1052832 (91d:90062)},
  Mrreviewer =   {Christian Michelot},
  Number =       3,
  Pages =        {531--554},
  Title =        {Implementing proximal point methods for linear
                  programming},
  Volume =       65,
  Year =         1990
}

@misc{MaGoldChen:2009,
  Author =       {Shiqian Ma and Donald Goldfarb and Lifeng Chen},
  Title =        {Fixed point and {Bregman} iterative methods for
                  matrix rank minimization},
  URL =          {http://arxiv.org/abs/0905.1643},
  Howpublished = {arXiv 0905.1643},
  Month =        {May},
  Year =         2009
}

@Article{MaM99,
  author =       "Mangasarian, O. L. and Musicant, D. R.",
  title =        "Successive over relaxation for support vector
                  machines",
  journal =      "IEEE Trans. Neural Networks",
  year =         1999,
  volume =       10,
  page =         {1032--1037}
}

@Article{MaZ93,
  author =       "Mallat, S. and Zhang, Z.",
  title =        "Matching pursuits with time-frequency dictionaries",
  journal =      "Signal Processing, IEEE Transactions",
  year =         1993,
  volume =       41,
  page =         {3397--3415}
}

@mastersthesis{Mali:2003,
  Address =      {Cambridge, MA},
  Author =       {Dmitry M. Malioutov},
  Month =        {July},
  School =       {Dept. Electrical Engineering, Massachusetts
                  Institute of Technology},
  Title =        {A Sparse Signal Reconstruction Perspective for
                  Source Localization with Sensor Arrays},
  Year =         2003
}

@article{MaliCetiWill:2005,
  Abstract =     {We present a source localization method based on a
                  sparse representation of sensor measurements with an
                  overcomplete basis composed of samples from the
                  array manifold. We enforce sparsity by imposing
                  penalties based on the $\ell_1$-norm. A number of
                  recent theoretical results on sparsifying properties
                  of $\ell_1$ penalties justify this
                  choice. Explicitly enforcing the sparsity of the
                  representation is motivated by a desire to obtain a
                  sharp estimate of the spatial spectrum that exhibits
                  super-resolution. We propose to use the singular
                  value decomposition (SVD) of the data matrix to
                  summarize multiple time or frequency samples. Our
                  formulation leads to an optimization problem, which
                  we solve efficiently in a second-order cone (SOC)
                  programming framework by an interior point
                  implementation. We propose a grid refinement method
                  to mitigate the effects of limiting estimates to a
                  grid of spatial locations and introduce an automatic
                  selection criterion for the regularization parameter
                  involved in our approach. We demonstrate the
                  effectiveness of the method on simulated data by
                  plots of spatial spectra and by comparing the
                  estimator variance to the Crame\'{e}r-Rao bound
                  (CRB). We observe that our approach has a number of
                  advantages over other source localization
                  techniques, including increased resolution, improved
                  robustness to noise, limitations in data quantity,
                  and correlation of the sources, as well as not
                  requiring an accurate initialization.  },
  Author =       {Dmitry Malioutov and M\"{u}jad \c{C}etin and Alan
                  S. Willsky},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      IEEETransSigProc,
  Keywords =     {Direction-of-arrival estimation, overcomplete
                  representation, sensor array processing, source
                  localization, sparse representation,
                  superresolution},
  Month =        {August},
  Number =       8,
  Pages =        {3010--3022},
  Title =        {A sparse signal reconstruction perspective for
                  source localization with sensor arrays},
  Volume =       53,
  Year =         2005
}

@inproceedings{MaliCetiWill:2005b,
  Author =       {D. M. Malioutov and M. \c{C}etin and A. S. Willsky},
  Booktitle =    {{IEEE} International Conference on Acoustics,
                  Speech, and Signal Processing},
  Location =     {Philadelphia, PA},
  Month =        {March},
  Pages =        {733--736},
  Title =        {Homotopy Continuation for Sparse Signal
                  Representation},
  Volume =       5,
  Year =         2005
}

@InProceedings{MaliSangWill:2008,
  author =       {Dmitry Malioutov and Sujay Sanghavi and Alan
                  Willsky},
  title =        {Compressed sensing with sequential observations},
  year =         2008,
  month =        {April},
  booktitle =    {Proceedings of the International Conference on
                  Acoustics, Speech, and Signal Processing},
  publisher =    {IEEE Signal Processing Society}
}

@Book{Mallat:1999,
  author =       {S. Mallat},
  title =        {A Wavlet Tour of Signal Processing},
  publisher =    {Academic Press},
  year =         1999
}

@Article{Man84,
  author =       "Mangasarian, O. L.",
  title =        "Sparsity-Preserving SOR Algorithms for Separable
                  Quadratic and Linear Programming",
  journal =      "Comnput. Oper. Res.",
  year =         1984,
  volume =       11,
  page =         {105--112}
}

@Article{Man93,
  author =       "Mangasarian, O. L.",
  title =        "Mathematical programming in neural networks",
  journal =      "ORSA J. Comput.",
  year =         1993,
  volume =       5,
  page =         {349--360}
}

@Article{Man95,
  author =       "Mangasarian, O. L.",
  title =        "Parallel gradient distribution in unconstrained
                  optimization",
  journal =      siamcontrol,
  year =         1995,
  volume =       33,
  page =         {1916--1925}
}

@book{Mang:1969,
  Address =      {New York},
  Author =       {O. L. Mangasarian},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Publisher =    McGrawHill,
  Title =        {Nonlinear Programming},
  Year =         1969
}

@article{Mang:1984,
  Author =       {O. L. Mangasarian},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      MathProgStudy,
  Pages =        {206--216},
  Title =        {Normal solutions of linear programs},
  Volume =       22,
  Year =         1984
}

@article{Mang:1985,
  Author =       {O. L. Mangasarian},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      siamcontrol,
  Pages =        {30-37},
  Title =        {Sufficiency of exact penalty minimization},
  Volume =       23,
  Year =         1985
}

@article{Mang:1988,
  Author =       {O. L. Mangasarian},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      {Oper. Res. Lett.},
  Pages =        {21--26},
  Title =        {A simple characterization of solution sets of convex
                  programs},
  Volume =       7,
  Year =         1988
}

@book{Mang:1994,
  Address =      {New York},
  Author =       {O. L. Mangasarian},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Editor =       {Gene Golub},
  Note =         {Originally published: New York, McGraw-Hill, 1969.},
  Publisher =    SIAM,
  Series =       {Classics in Applied Mathematics},
  Title =        {Nonlinear Programming},
  Volume =       10,
  Year =         1994
}

@article{Mang:2004,
  Author =       {O. L. Mangasarian},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      JOTA,
  Pages =        {1-18},
  Title =        {A {N}ewton method for linear programming},
  Volume =       121,
  Year =         2004
}

@article{MangFrom:1967,
  Author =       {O. L. Mangasarian and S. Fromovitz},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      MathAnaAppl,
  Pages =        {37-47},
  Title =        {The {F}ritz-{J}ohn conditions in the presence of
                  equality and inequality constraints},
  Volume =       17,
  Year =         1967
}

@article{MangMeye:1979,
  Author =       {O. L. Mangasarian and R. R. Meyer},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      siamcontrol,
  Month =        {November},
  Number =       6,
  Pages =        {745--752},
  Title =        {Nonlinear Perturbation of Linear Programs},
  Volume =       17,
  Year =         1979
}

@techreport{MannRich:2004,
  Address =      {CA},
  Author =       {Alan S. Manne and Richard G. Richels},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Institution =  {Stanford University},
  Month =        {June},
  Title =        {{MERGE}: An intergrated assessment model for global
                  climate change},
  Year =         2004
}

@phdthesis{Mara:1978,
  Address =      {London, UK},
  Author =       {N. Maratos},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  School =       {Imperial College of Science and Technology},
  Title =        {Exact penalty function algorithms for finite
                  dimensional and optimization problems},
  Year =         1978
}

@article{Mark:1956,
  author =       {H. M. Markowitz},
  title =        {The optimization of a quadratic function subject to
                  constraints},
  journal =      {Nav. Res. Logist. Quart.},
  volume =       3,
  year =         1956,
  pages =        {111--133}
}

@manual{Math:1992,
  Address =      {Natick, MA},
  Author =       {MathWorks},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Organization = {The {MathWorks}, Inc.},
  Title =        {{MATLAB} User's Guide},
  Year =         1992
}

@manual{Math:1995,
  Address =      {Natick, MA},
  Author =       {MathWorks},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Organization = {The {MathWorks}, Inc.},
  Title =        {{MATLAB}: External Interfaces},
  Year =         1995
}

@article{MaynPola:1982,
  Author =       {D. Q. Mayne and E. Polak},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      MathProgStudy,
  Pages =        {45-61},
  Title =        {A superlinearly convergent algorithm for constrained
                  optimization problems},
  Volume =       16,
  Year =         1982
}

@article{McCo:1971,
  Author =       {Garth P. McCormick},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      MathProg,
  Pages =        {217-238},
  Title =        {Penalty Function Versus Non-Penalty Function Methods
                  for Constrained Nonlinear Programming Problems},
  Volume =       1,
  Year =         1971
}

@book{McLaTure:1993,
  Address =      {Mill Valley, CA},
  Author =       {Fred W. McLafferty and Franti{\u{s}}ek
                  Ture{\u{c}}ek},
  Publisher =    {University Science Books},
  Title =        {Interpretation of Mass Spectra},
  Edition =      {Fourth},
  Year =         1993
}

@Article{McLinden:1978,
  author =       "L. McLinden",
  title =        "Symmetric duality for structured convex programs",
  journal =      "Transactions of the American Mathematical Society",
  year =         1978,
  volume =       245,
  pages =         {147--181},
}

@article{MendPajoTomc:2007,
  Author =       {S. Mendelson and A. Pajor and N. Tomczak-Jaegermann},
  Title =        {Uniform uncertainty principle for {B}ernoulli and
                  subgaussian ensembles},
  Journal =      {Constructive Approximation},
  Note =         {To appear},
  DOI =          {10.1007/s00365-007-9005-8},
  Year =         2008
}

@Article{MiF81,
  author =       "Mine, H. and Fukushima, M.",
  title =        "A minimization method for the sum of a convex
                  function and a continuously differentiable function",
  journal =      jota,
  year =         1981,
  volume =       33,
  page =         {9--23}
}

@article{Mill1:1970,
  Author =       {Keith Miller},
  Date-Added =   {2007-12-13 11:48:09 -0800},
  Date-Modified ={2007-12-13 11:48:09 -0800},
  Journal =      SIAMMath,
  Number =       1,
  Pages =        {52--74},
  Title =        {Least squares methods for ill-posed problems with a
                  prescribed bound},
  Volume =       1,
  Year =         1970
}

@conference{ZhenJaco:2008a,
  author =       {Jing Zheng and Eddie Jacobs},
  editor =       {Z. Rahman and Stephen E. Reichenbach and Mark
                  A. Neifeld},
  title =        {Application of compressive sensing theory in
                  infrared imaging systems},
  publisher =    {SPIE},
  year =         {2008},
  booktitle =    {Visual Information Processing XVII},
  volume =       {6978},
  numpages =     {8},
  location =     {Orlando, FL, USA},
  url =          {http://link.aip.org/link/?PSI/6978/69780J/1},
  doi =          {10.1117/12.776967}
}

@conference{ZhenJaco:2008b,
  author =       {Jing Zheng and Eddie Jacobs},
  editor =       {G. C. Holst},
  title =        {The application of Compressive Sensing technique on
                  a stationary surveillance camera system},
  publisher =    {SPIE},
  year =         {2008},
  booktitle =    {Infrared Imaging Systems: Design, Analysis,
                  Modeling, and Testing XIX},
  volume =       {6941},
  numpages =     {8},
  location =     {Orlando, FL, USA},
  url =          {http://link.aip.org/link/?PSI/6941/69410H/1},
  doi =          {10.1117/12.779321}
}

@article{Mill:1970,
  Author =       {Keith Miller},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      SIAMMath,
  Number =       1,
  Pages =        {52--74},
  Title =        {Least squares methods for ill-posed problems with a
                  prescribed bound},
  Volume =       1,
  Year =         1970
}

@misc{MishYoni:2008,
  Author =       {Moshe Mishali and Yonina C. Eldar},
  Title =        {Reduce and Boost: Recovering Arbitrary Sets of
                  Jointly Sparse Vectors},
  URL =          {http://arxiv.org/abs/0802.1311},
  Howpublished = {arXiv 0802.1311},
  Month =        {February},
  Year =         2008
}

@Article{MoW97,
  author =       "More, J. J. and Wu, Z.",
  title =        "Global continuation for distance geometry problems",
  journal =      siamopt,
  year =         1997,
  volume =       7,
  page =         {814--836}
}

@article{MoguPrie:2003,
  Author =       {J.M. Moguerza and F.J. Prieto},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      {Math. Program. A},
  Pages =        {573-616},
  Title =        {An augmented Lagrangian interior-point method using
                  directions of negative curvature},
  Volume =       95,
  Year =         2003
}

@article{MoguPrie:2003b,
  Author =       {J. M. Moguerza and F. J. Prieto},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      {Math. Program. A},
  Pages =        {529-559},
  Title =        {Combining search directions using gradient flows},
  Volume =       96,
  Year =         2003
}

@incollection{More:1983,
  Address =      {Berlin},
  Author =       {J. J. Mor\'{e}},
  Booktitle =    {Mathematical Programming : The State of the Art},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Editor =       {A. Bachem and M. Groetschel and B. Korte},
  Pages =        {258-287},
  Publisher =    SPRINGER,
  Title =        {Recent developments in algorithms and software for
                  trust region methods},
  Year =         1983
}

@article{MoreMuns:2004,
  Author =       {Jorge J. Mor\'{e} and Todd S. Munson},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      MATHprog,
  Pages =        {151--182},
  Title =        {Computing mountain passes and transition states},
  Volume =       100,
  Year =         2004
}

@article{MoreSorensen:1983,
  author =       {Jorge J. More and D. C. Sorensen},
  title =        {Computing a Trust Region Step},
  publisher =    {SIAM},
  year =         1983,
  journal =      {SIAM Journal on Scientific and Statistical
                  Computing},
  volume =       4,
  number =       3,
  pages =        {553-572},
  keywords =     {Newton's method; trust region; ellipsoidal
                  constraint; global convergence},
  url =          {http://link.aip.org/link/?SCE/4/553/1},
  doi =          {10.1137/0904038}
}

@article{MoreTora:1989,
  Abstract =     {Presents an algorithm which combines standard active
                  set strategies with the gradient projection method
                  for the solution of quadratic programming problems
                  subject to bounds. The authors show, in particular,
                  that if the quadratic is bounded below on the
                  feasible set then termination occurs at a stationary
                  point in a finite number of iterations. Moreover, if
                  all stationary points are nondegenerate, termination
                  occurs at a local minimizer. A numerical comparison
                  of the algorithm based on the gradient projection
                  algorithm with a standard active set strategy shows
                  that on mildly degenerate problems the gradient
                  projection algorithm requires considerable less
                  iterations and time than the active set strategy. On
                  nondegenerate problems the number of iterations
                  typically decreases by at least a factor of 10. For
                  strongly degenerate problems, the performance of the
                  gradient projection algorithm deteriorates, but it
                  still performs better than the active set method.},
  Author =       {J. J. Mor\'{e} and G. Toraldo},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      {Numerische Mathematik},
  Number =       4,
  Pages =        {377--400},
  Title =        {Algorithms for bound constrained quadratic
                  programming problems},
  Volume =       55,
  Year =         1989
}

@article{MoreTora:1991,
  Author =       {J. J. Mor\'{e} and G. Toraldo},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      siamopt,
  Number =       1,
  Pages =        {93--113},
  Title =        {On the Solution of Large Quadratic Programming
                  Problems with Bound Constraints},
  Volume =       1,
  Year =         1991
}

@incollection{Murr:1969,
  Address =      {London and New York},
  Author =       {W. Murray},
  Booktitle =    {Optimization},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Editor =       {R. Fletcher},
  Publisher =    Academic,
  Title =        {An algorithm for constrained minimization},
  Year =         1969
}

@article{Murr:1971,
  Author =       {W. Murray},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      JOTA,
  Pages =        {189--196},
  Title =        {Analytical expressions for the eigenvalues and
                  eigenvectors of the Hessian matrices of barrier and
                  penalty functions},
  Volume =       7,
  Year =         1971
}

@article{MurrPrie:1995,
  Author =       {W. Murray and F. J. Prieto},
  Date-Modified ={2007-10-13 17:59:03 -0700},
  Journal =      siamopt,
  Month =        {August},
  Number =       3,
  Pages =        {590--640},
  Title =        {A sequential quadratic programming algorithm using
                  an incomplete solution of the subproblem},
  Volume =       5,
  Year =         1995
}

@article{MurtSaun:1978,
  Author =       {B. A. Murtagh and M. A. Saunders},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      MathProg,
  Pages =        {41-72},
  Title =        {Large-scale Linearly Constrained Optimization},
  Volume =       14,
  Year =         1978
}

@article{MurtSaun:1982,
  Author =       {Bruce A. Murtagh and M. A. Saunders},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      MathProgStudy,
  Pages =        {84-117},
  Title =        {A Projected {L}agrangian Algorithm and its
                  Implementation for Sparse Nonlinear Constraints},
  Volume =       16,
  Year =         1982
}

@techreport{MurtSaun:1983,
  Address =      {Department of Management Science and Engineering,
                  Stanford University, Stanford, CA},
  Author =       {Bruce A. Murtagh and M. A. Saunders},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Institution =  {Systems Optimization Laboratory},
  Month =        {December},
  Number =       {83-20R},
  Title =        {{MINOS 5.5} User's Guide},
  Year =         1983
}

@manual{NAG:1977,
  Address =      {Wilkinson House, Jordan Hill Road, Oxford, England},
  Annote =       {Authors: P. E. Gill, W. Murray and S. M. Picken},
  Date-Modified ={2007-12-14 11:58:59 -0800},
  Edition =      {Mark 6},
  Note =         {{E04UAF}, {E04VAF}, {E04VBF}, {E04WAF}, constrained
                  optimization using sequential augmented {Lagrangian}
                  methods},
  Organization = {Numerical Algorithms Group Limited},
  Title =        {The {NAG} {Fortran Library Manual}},
  Year =         1977
}

@misc{NETLIB:2006,
  Date-Modified ={2007-12-14 11:59:07 -0800},
  Key =          {Netlib},
  Title =        {{NETLIB} Linear Programming Library},
  Url =          {\url{http://www.netlib.org/lp/infeas/}},
  Year =         2006
}

@misc{NIST:ChemWebBook,
  Author =       {{National Institute of Standards and Technology}},
  Title =        {{NIST Chemistry WebBook}},
  Howpublished = {\url{http://webbook.nist.gov/chemistry/}},
  Url =          {http://webbook.nist.gov/chemistry/},
  Year =         2009
}

@book{NashSofe:1996,
  Address =      {New York},
  Author =       {Stephen G. Nash and Ariela Sofer},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Publisher =    McGrawHill,
  Title =        {Linear and Nonlinear Programming},
  Year =         1996
}

@article{Nata:1995,
  Author =       {B. K. Natarajan},
  Title =        {Sparse Approximate Solutions to Linear Systems},
  Journal =      siamcomp,
  Volume =       24,
  Number =       2,
  Year =         1995,
  Month =        {April},
  Pages =        {227--234},
  Keywords =     {Sparse solutions, linear systems},
  Summary =      {The suggested algorithm takes as input $A$, $b$, and
                  $\epsilon$. The algorithm first normalizes each
                  column $a_i$ of $A$. Then, at each iteration of the
                  selection phase, the algorithm greedily picks that
                  column of $A$ that is closest in angle to the vector
                  $b$. Then, $b$ and the column vectors of $A$ are
                  projected onto the subspace orthogonal to the chosen
                  column. This procedure is repeated until $\Vert
                  b\Vert_2 \leq \epsilon$. In the solution phase, the
                  algorithm solves the linear system problem $Bx =
                  b^{(0)} - b^{(r)}$ where $B$ is the matrix
                  consisting of those columns of $A$ that were chosen
                  in the selection phase, $b^{(0)}$ is $b$ at the
                  start of the selection phase, and $b^{(r)}$ is $b$
                  at the end of the selection phase.},
  Abstract =     {The following problem is considered: given a matrix
                  $A$ in $\mathbb{R}^{m\times n}$, ($m$ rows and $n$
                  columns), a vector $b$ in $\mathbb{R}^m$, and
                  $\epsilon > 0$, compute a vector $x$ satisfying
                  $\Vert Ax-b\Vert_2 \leq \epsilon$ if such exists,
                  such that $x$ has the fewest number of non-zero
                  entries over all such vectors. It is shown that the
                  problem is NP-hard, but that the well-known greedy
                  heuristic is good in that it computes a solution
                  with at most $\lceil 18\mathrm{Opt}(\epsilon/2)
                  \Vert\mathbf{A}^+\Vert_2^2 \ln(\Vert
                  b\Vert_2/\epsilon)\rceil$ non zero entries, where
                  $\mathrm{Opt}(\epsilon/2)$ is the optimum number of
                  nonzero entries at error $\epsilon/2$. $\mathbf{A}$
                  is the matrix obtained by normalizing each column of
                  $A$ with respect to the $L_2$ norm, and
                  $\mathbf{A}^+$ is its peudo-inverse}
}

@Article{NeB01,
  author =       "Nedi\'c, A. and Bertsekas, D. P.",
  title =        "Incremental subgradient methods for
                  nondifferentiable optimization",
  journal =      siamopt,
  year =         2001,
  volume =       12,
  page =         {109--138}
}

@book{NeN94,
  Address =      {Philadelphia},
  Author =       {Y. E. Nesterov and A. Nemirovski},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Publisher =    SIAMPub,
  Series =       {Stud. Appl. Math.},
  Title =        {Interior-Point Polynomial Algorithms in Convex
                  Programming},
  Volume =       13,
  Year =         1994
}

@Book{NeY83,
  author =       "Nemirovski, A. and Yudin, D.",
  title =        "Problem Complexity and Method Efficiency in
                  Optimization",
  publisher =    "Wiley",
  year =         1983,
  address =      "New York"
}

@Unpublished{NeedTrop:2008,
  title =        {{CoSaMP}: Iterative signal recovery from incomplete
                  and inaccurate samples},
  author =       {D. Needell and J. A. Tropp},
  month =        {June},
  year =         2008,
  note =         {To appear in {\it Appl. Comp. Harmonic Anal.}}
}

@INPROCEEDINGS{NeedVers:2008,
  author =       {{Needell}, D. and {Vershynin}, R.},
  title =        "{Greedy signal recovery and uncertainty principles}",
  booktitle =    {Society of Photo-Optical Instrumentation Engineers
                  (SPIE) Conference Series},
  year =         2008,
  series =       {Society of Photo-Optical Instrumentation Engineers
                  (SPIE) Conference Series},
  volume =       6814,
  month =        mar,
  doi =          {10.1117/12.776996},
  adsurl =       {http://adsabs.harvard.edu/abs/2008SPIE.6814E..13N},
  adsnote =      {Provided by the SAO/NASA Astrophysics Data System}
}

@Article{Nem05,
  author =       "Nemirovski, A.",
  title =        "Prox-Method with Rate of Convergence $O(1/t)$ for
                  Variational Inequalities with Lipschitz Continuous
                  Monotone Operators and Smooth Convex-Concave Saddle
                  Point Problems",
  journal =      siamopt,
  year =         2005,
  volume =       15,
  page =         {229--251}
}

@Techreport{Nes04a,
  author =       "Nesterov, Y.",
  title =        "Smoothing technique and its applications in
                  semidefinite optimization",
  institution =  "CORE, Catholic University of Louvain,
                  Louvain-la-Neuve",
  address =      "Belgium",
  year =         2004,
  month =        "October"
}

@Book{Nes04b,
  author =       "Nesterov, Y.",
  title =        "Introductory Lectures on Convex Optimization",
  publisher =    "Kluwer Academic",
  year =         2004,
  address =      "Dordrecht, The Netherlands"
}

@Article{Nes05a,
  author =       "Nesterov, Y.",
  title =        "Smooth minimization of nonsmooth functions",
  journal =      "Math. Program.",
  year =         2005,
  volume =       103,
  page =         {127--152}
}

@Article{Nes05b,
  author =       "Nesterov, Y.",
  title =        "Excessive gap technique in nonsmooth convex
                  minimization",
  journal =      siamopt,
  year =         2005,
  volume =       16,
  page =         {235--249}
}

@techreport{Nes07,
  title =        {Gradient methods for minimizing composite objective
                  function},
  author =       {Nesterov, Y.},
  institution =  {Center for Operations Research and Econometrics
                  (CORE), Catholic University of Louvain},
  type =         {Tech. Rep.},
  volume =       76,
  year =         2007
}

@Article{Nes07a,
  author =       "Nesterov, Y.",
  title =        "Dual extrapolation and its applications to solving
                  variational inequalities and related problems",
  journal =      "Math. Program.",
  year =         2007,
  volume =       109,
  page =         {319-344}
}

@Techreport{Nes07b,
  author =       "Nesterov, Y.",
  title =        "Gradient methods for minimizing composite objective
                  function",
  institution =  "CORE, Catholic University of Louvain",
  address =      "Louvain-la-Neuve, Belgium",
  year =         2007,
  month =        "September"
}

@Article{Nes07c,
  author =       "Nesterov, Y.",
  title =        "Primal-dual subgradient methods for convex problems",
  journal =      "Math. Program.",
  year =         2007,
  volume =       120,
  page =         {221--259},
  note =         "DOI 10.1007/s10107-007-0149-x"
}

@Article{Nes:1983,
  author =       "Nesterov, Y.",
  title =        "A method for unconstrained convex minimization
                  problem with the rate of convergence {$O(1/k^2)$}",
  journal =      "Soviet Math. Dokl.",
  year =         1983,
  volume =       269,
  page =         {543--547},
}

@Article{Nes88,
  author =       "Nesterov, Y.",
  title =        "On an approach to the construction of optimal
                  methods of minimization of smooth convex functions",
  journal =      "Ekonom. i. Mat. Metody ",
  year =         1988,
  volume =       24,
  page =         {509--517}
}

@article{NestNemi:1992,
  Author =       {Yu. E. Nesterov and A. S. Nemirovski},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      OptimMeth,
  Pages =        {95--115},
  Title =        {Conic formulation of a convex programming problem
                  and duality},
  Volume =       1,
  Year =         1992
}

@Techreport{Nie06,
  author =       "Nie, J.",
  title =        "Sum of squares method for sensor network
                  localization",
  institution =  "Department of Mathematics, University of California",
  address =      "Berkeley",
  year =         2006,
  month =        "June",
  note =         "to appear in Comput. Optim. Appl."
}

@book{NoW99,
  Address =      {New York},
  Author =       {Jorge Nocedal and Stephen J. Wright},
  Publisher =    {Springer},
  Title =        {Numerical Optimization},
  Year =         1999
}

@book{NoceWrig:2006,
  Address =      {New York},
  Author =       {J. Nocedal and S. J. Wright},
  Edition =      {Second},
  Publisher =    {Springer},
  Title =        {Numerical Optimization},
  Year =         2006
}

@Book{Nocedal1999,
  author =       "Nocedal, J. and Wright S. J.",
  title =        "Numerical Optimization",
  publisher =    "Springer-Verlag",
  year =         1999,
  address =      "New York"
}


@Article{OBGX05,
  author =       "Osher, S. and Burger, M. and Goldfarb, D. and
                  Xu. J.",
  title =        "An iterative regularization method for total
                  variation-based image restoration",
  journal =      siammms,
  year =         2005,
  volume =       4,
  page =         {460--489}
}


@Article{OTJ09,
  author =       "G. Obozinski and B. Taskar and M. I. Jordan",
  title =        "Joint covariate selection and joint subspace
                  selection for multiple classification problems",
  journal =      "Stat. Comput.",
  year =         2009
}

@Article{OlivSore:2005,
  author =       {A.R.L. Oliveira and D.C. Sorensen},
  title =        {A new class of preconditioners for large-scale
                  linear systems from interior point methods for
                  linear programming},
  journal =      linalgapp,
  year =         2005,
  volume =       394,
  pages =        {1--24}
}

@book{OrR70,
  Address =      {London},
  Author =       {J. M. Ortega and W. C. Rheinboldt},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Publisher =    Academic,
  Title =        {Iterative Solutions of Nonlinear Equations in
                  Several Variables},
  Year =         1970
}

@Book{Ortega2000,
  author =       "Ortega, J. M. and Rheinboldt, W. C.",
  title =        "Iterative Solution of Nonlinear Equations in Several
                  Variables",
  publisher =    "SIAM",
  year =         2000,
  address =      "Philadelphia"
}

@article{OsboPresTurl:2000a,
  Author =       {M. R. Osborne and Brett Presnell and B. A. Turlach},
  Date-Modified ={2007-09-14 11:00:08 -0700},
  Journal =      IMANumerAna,
  Keywords =     {L1},
  Local-Url =
                  {file://localhost/Users/mpf/papers/OsboPresTurl00.pdf},
  Number =       3,
  Pages =        {389--403},
  Title =        {A new approach to variable selection in least
                  squares problems},
  Volume =       20,
  Year =         2000
}

@article{OsboPresTurl:2000b,
  Author =       {M. R. Osborne and B. Presnell and B. A. Turlach},
  Date-Modified ={2007-09-14 11:00:11 -0700},
  Journal =      {J. of Comput. Graph. Statist.},
  Keywords =     {L1},
  Local-Url =
                  {file://localhost/Users/mpf/papers/OsboPresnTurl99.pdf},
  Pages =        {319--337},
  Title =        {On the {LASSO} and its dual},
  Volume =       9,
  Year =         2000
}

@misc{Osborne:2003,
  title =        {{When LP is not a good idea--using structure in
                  polyhedral optimization problems}},
  author =       {Osborne, M. R. },
  year =         2003
}

@book{OutrKocvZowe:1998,
  Address =      {Dordrecht, The Netherlands},
  Author =       {J. Outrata and M. Kocvara and J. Zowe},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Publisher =    {Kluwer Academic},
  Title =        {Nonsmooth approach to optimization problems with
                  equilibrium constraints: {T}heory, applications, and
                  numerical results},
  Year =         1998
}

@Article{PRT08,
  author =       "Pfander, G. B. and Rauhut, H. and Tanner, J.",
  title =        "Identification of Matrices Having a Sparse
                  Representation",
  journal =      "IEEE Trans. Signal Proc.",
  year =         2008,
  volume =       56,
  page =         {5376--5388}
}

@Article{PaH07,
  author =       "Park, M.-Y. and Hastie, T.",
  title =        "An {L1} regularization-path algorithm for
                  generalized linear models",
  journal =      "J. Roy. Soc. Stat. B",
  year =         2007,
  volume =       69,
  page =         {659--677}
}

@article{PaatTapp:1994,
  Author =       {P. Paatero and U. Tapper},
  Date-Added =   {2007-10-20 15:30:26 -0700},
  Date-Modified ={2007-10-20 15:30:30 -0700},
  Journal =      {Envirometrics},
  Pages =        {111--126},
  Title =        {Positive matrix factorization: A non-negative factor
                  model with optimal utilization of error},
  Volume =       5,
  Year =         1994
}

@article{PaigSaun:1975,
  Author =       {C. C. Paige and M. A. Saunders},
  Date-Added =   {2007-10-22 22:30:37 -0700},
  Date-Modified ={2007-10-22 22:32:36 -0700},
  Journal =      {siamnumanal},
  Pages =        {617--629},
  Title =        {Solution of sparse indefinite systems of linear
                  equations},
  Volume =       12,
  Year =         1975
}

@article{PaigSaun:1982,
  Author =       {C. C. Paige and M. A. Saunders},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      ACMMathSoft,
  Pages =        {43--71},
  Title =        {{LSQR}: An Algorithm for Sparse Linear Equations and
                  Sparse Least Squares},
  Volume =       8,
  Year =         1982
}

@article{PalaLasdEngq:1982,
  Author =       {F. Palacios-Gomez and L. Lasdon and E. Engquist},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      ManageSci,
  Month =        {October},
  Number =       10,
  Pages =        {1106--1120},
  Title =        {Nonlinear optimization by successive linear
                  programming},
  Volume =       28,
  Year =         1982
}

@Article{Pan87,
  author =       "Pang, J.-S.",
  title =        "A posteriori error bounds for the linearly
                  constrained variational inequality problem",
  journal =      "Math. Oper. Res.",
  year =         1987,
  volume =       12,
  page =         {474--484}
}

@article{Pan:2005,
  Author =       {Ping-Qi Pan},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      siamopt,
  Number =       1,
  Pages =        {49-68},
  Publisher =    {SIAM},
  Title =        {A Revised Dual Projective Pivot Algorithm for Linear
                  Programming},
  Volume =       16,
  Year =         2005
}

@techreport{PataSchm:2002,
  Author =       {G. Pataki and S. Schmieta},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Institution =  {Computational Optimization Research Center, Columbia
                  University, New York},
  Number =       {Preliminary draft},
  Title =        {The {DIMACS} library of
                  semidefinite-quadratic-linear programs},
  Year =         {July 2002}
}

@inproceedings{PatiRezaKris:1993,
  Abstract =     {In this paper we describe a recursive algorithm to
                  compute representations of functions with respect to
                  nonorthogonal and possibly overcomplete dictionaries
                  of elementary building blocks e.g. affine (wavelet)
                  frames. We propose a modification to the Matching
                  Pursuit algorithm of Mallat and Zhang (1992) that
                  maintains full backward orthogonality of the
                  residual (error) at every step and thereby leads to
                  improved convergence. We refer to this modified
                  algorithm as Orthogonal Matching Pursuit (OMP). It
                  is shown that all additional computation required
                  for the OMP algorithm may be performed recursively.},
  Author =       {Y. C. Pati and R. Rezaiifar and P. S. Krishnaprasad},
  Booktitle =    {Proceedings of the 27th Annual Asilomar Conference
                  on Signals, Systems and Computers},
  Month =        {Nov.},
  Pages =        {40--44},
  Title =        {Orthogonal Matching Pursuit: Recursive Function
                  Approximation with Applications to Wavelet
                  Decomposition},
  Volume =       1,
  Year =         1993
}

@article{Pere:1967,
  Author =       {Victor Pereyra},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      SIAMNumAnal,
  Pages =        {508--533},
  Title =        {Accelerating the Convergence of Discretization
                  Algorithms},
  Volume =       4,
  Year =         1967
}

@article{Piet:1969,
  Author =       {T. Pietrzykowski},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      SIAMNumAnal,
  Pages =        {262--304},
  Title =        {An exact potential method for constrained maxima},
  Volume =       6,
  Year =         1969
}

@InCollection{Pla98,
  author =       {J. Platt},
  title =        {Fast training of support vector machines using
                  sequential minimal optimization},
  booktitle =    {Advances in Kernel Methods: Support Vector Learning},
  year =         1998,
  publisher =    {MIT Press},
  address =      {Cambridge, MA, USA}
}

@InCollection{Plumbley:2006,
  author =       {Mark D. Plumbley},
  title =        {Recovery of Sparse Representations by Polytope Faces
                  Pursuit},
  booktitle =    {Independent Component Analysis and Blind Signal
                  Separation},
  pages =        {206-213},
  publisher =    {Springer},
  year =         2006,
  volume =       {3889/2006},
  series =       {Lecture Notes in Computer Science},
  address =      {Berlin},
  doi =          {10.1007/11679363}
}

@Techreport{PoT09,
  author =       "Pong, T. K. and Tseng, P.",
  title =        "(Robust) edge-based semidefinite programming
                  relaxation of sensor network localization",
  institution =  "Department of Mathematics, University of Washington",
  address =      "Seattle",
  year =         2009,
  month =        "January"
}

@Book{Pol87,
  author =       {Polyak, B. T.},
  title =        {Introduction to optimization},
  publisher =    {Optimization Software},
  year =         1987,
  address =      {New York}
}

@article{Pola:1976,
  Author =       {Elijah Polak},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      {Automica},
  Pages =        {337-342},
  Title =        {On the global stabalization of locally convergent
                  algorithms for optimization and root finding},
  Volume =       12,
  Year =         1976
}

@book{Pola:1991,
  Address =      {New York},
  Author =       {Elijah Polak},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Editor =       {J. E. Marsden and L. Sirovich},
  Number =       124,
  Publisher =    SPRINGER,
  Series =       {Applied Mathematical Sciences},
  Title =        {Optimization: {A}lgorithms and Consistent
                  Approximations},
  Year =         1991
}

@incollection{Powe:1969,
  Address =      {London and New York},
  Author =       {M. J. D. Powell},
  Booktitle =    {Optimization},
  Chapter =      19,
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Editor =       {R. Fletcher},
  Publisher =    Academic,
  Title =        {A method for nonlinear constraints in minimization
                  problems},
  Year =         1969
}

@article{Pshe:1970,
  Author =       {Borris N. Pshenichnyj},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      {Mathematical notes of the Academy of Sciences of the
                  USSR},
  Note =         {[English translation]; Original Russian:
                  Matematicheskie Zametki, 8 (1970),
                  pp.~635--640. (Note that the authors name is
                  transliterated as Pshenichnyi)},
  Pages =        {827-830},
  Title =        {{N}ewton's {M}ethod for the solution of systems of
                  equalities and inequalities},
  Volume =       8,
  Year =         1970
}

@book{Pshe:1994,
  Address =      {Berlin},
  Annote =       {Stephen S. Wilson},
  Author =       {Borris N. Pshenichnyj},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Publisher =    SPRINGER,
  Title =        {The Linearization Method for Constrained
                  Optimization},
  Year =         1994
}

@misc{RFP07,
  Author =       {Benjamin Recht and Maryam Fazel and Pablo
                  A. Parrilo},
  Title =        {Guaranteed minimum-rank solutions of linear matrix
                  equations via nuclear norm minimization},
  URL =          {http://arxiv.org/abs/0706.4138},
  Howpublished = {arXiv 0706.4138},
  Month =        {June},
  Year =         2007
}

@article{RFP:2010,
  Author =       {Benjamin Recht and Maryam Fazel and Pablo
                  A. Parrilo},
  Title =        {Guaranteed minimum-rank solutions of linear matrix
                  equations via nuclear norm minimization},
  journal =      siamrev,
  volume =       52,
  number =       3,
  pages =        {471-501},
  Year =         2010
}

@Article{RRT94,
  author =       "Ravi, S. S. and Rosenkrantz, D. J. and Tayi, G. K.",
  title =        "Heuristic and special case algorithms for dispersion
                  problems",
  journal =      "Oper. Res.",
  year =         1994,
  volume =       42,
  page =         {299--310}
}

@Article{RSMB04,
  author =       "Rohl, C. A. and Strauss, C. E. M. and Misura, K. and
                  Baker, D.",
  title =        "Protein structure prediction using Rosetta",
  journal =      "Methods Enzym.",
  year =         2004,
  volume =       383,
  page =         {66--93}
}

@misc{RWT,
  Author =       {R. Baraniuk and H. Choi and F. Fernandes and
                  B. Hendricks and R. Neelamani and V. Ribeiro and
                  J. Romberg and R. Gopinath and H.-T Guo and M. Lang
                  and J. E. Odegard and D. Wei},
  Date-Added =   {2007-09-18 22:09:54 -0700},
  Date-Modified ={2007-09-18 22:09:54 -0700},
  Howpublished = {\url{http://www.dsp.rice.edu/software/rwt.shtml}},
  Title =        {{Rice Wavelet Toolbox}},
  Year =         1993
}

@techreport{RaghBieg:2003,
  Author =       {Arvind U. Raghunathan and Lorenz T. Biegler},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Institution =  {Carnegie Mellon University, Department of Chemical
                  Engineering},
  Title =        {Interior point methods for mathematical programs
                  with complementarity constraints},
  Year =         2003
}

@article{RalpWrig:2000,
  Author =       {Danny Ralph and Stephen J. Wright},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      mathofor,
  Pages =        {179--194},
  Title =        {Superlinear convergence of an interior-point method
                  despite dependent constraints},
  Volume =       25,
  Year =         2000
}

@techreport{RalpWrig:2003,
  Author =       {Danny Ralph and Stephen J. Wright},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Institution =  {Computer Sciences, University of Wisconsin},
  Month =        {December},
  Number =       {03-04},
  Title =        {Some properties of regularization schemes for
                  {MPEC}s},
  Year =         2003
}

@article{RaoEngaCottPalmKreu:2003,
  Abstract =     {We develop robust methods for subset selection based
                  on the minimization of diversity measures. A
                  Bayesian framework is used to account for noise in
                  the data and a maximum a posteriori (MAP) estimation
                  procedure leads to an iterative procedure which is a
                  regularized version of the focal underdetermined
                  system solver (FOCUSS) algorithm. The convergence of
                  the regularized FOCUSS algorithm is established and
                  it is shown that the stable fixed points of the
                  algorithm are sparse. We investigate three different
                  criteria for choosing the regularization parameter:
                  quality of fit; sparsity criterion; L-curve. The
                  L-curve method, as applied to the problem of subset
                  selection, is found not to be robust, and we propose
                  a novel modified L-curve procedure that solves this
                  problem. Each of the regularized FOCUSS algorithms
                  is evaluated through simulation of a detection
                  problem, and the results are compared with those
                  obtained using a sequential forward selection
                  algorithm termed orthogonal matching pursuit
                  (OMP). In each case, the regularized FOCUSS
                  algorithm is shown to be superior to the OMP in
                  noisy environments.  },
  Author =       {Bhaskar D. Rao and Kjersti Engan and Shane F. Cotter
                  and Jason Palmer and Kenneth Kreutz-Delgado},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      IEEETransSigProc,
  Keywords =     {Diversity measures, linear inverse problems,
                  matching pursuit, regularization, sparsity, subset
                  selection, undetermined systems},
  Month =        {March},
  Number =       3,
  Pages =        {760--770},
  Title =        {Subset selection in noise based on diversity measure
                  minimization},
  Volume =       51,
  Year =         2003
}

@inproceedings{RaoKreu:1998,
  Abstract =     {We consider procedures to enhance the reliability of
                  basis selection procedures with particular attention
                  being given to methods based on minimizing diversity
                  measures. To deal with noise in the data, basis
                  selection procedures based on a Bayesian framework
                  are considered. An algorithm based on the MAP
                  estimation procedure is developed which leads to a
                  regularized version of the FOCUSS algorithm. Another
                  approach considered is to select basis vectors over
                  multiple measurement vectors thereby achieving an
                  averaging effect and enhancing the reliability. New
                  diversity measures are presented for this purpose,
                  and algorithms are derived for minimizing them },
  Address =      {Pacific Grove, CA, USA},
  Author =       {Bhaskar D. Rao and Kenneth Kreutz-Delgado},
  Booktitle =    {Conference Record of Thirty-Second Asilomar
                  Conference on Signals, Systems and Computers},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Month =        {November},
  Pages =        {752--756},
  Publisher =    {IEEE},
  Title =        {Basis selection in the presence of noise},
  Volume =       1,
  Year =         1998
}

@inproceedings{RechXuHass:2008,
  Author =       {Benjamin Recht and Weiyu Xu and Babak Hassibi},
  Title =        {Necessary and sufficient conditions for success of
                  the nuclear norm heuristic for rank minimization},
  Booktitle =    {47th IEEE Conference on Decision and Control},
  Pages =        {3065--3070},
  Publisher =    {IEEE},
  Month =        {December},
  Year =         2008
}

@book{Rene:2001,
  Address =      {Philadelphia},
  Author =       {J. Renegar},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Publisher =    SIAMPub,
  Series =       {MPS/SIAM Series on Optimization},
  Title =        {A Mathematical View of Interior-Point Methods in
                  Convex Optimization},
  Year =         2001
}

@Book{RoW98,
  author =       "Rockafellar, R. T. and Wets, Roger J.-B",
  title =        "Variational Analysis",
  publisher =    "Springer-Verlag",
  year =         1998,
  address =      "New York"
}

@article{Robi:1971,
  Author =       {Stephen M. Robinson},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      NumerMath,
  Pages =        {341-347},
  Title =        {Extension of {N}ewton's {M}ethod to nonlinear
                  functions with values in a cone},
  Volume =       19,
  Year =         1971
}

@article{Robi:1972,
  Author =       {Stephen M. Robinson},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      MathProg,
  Pages =        {145-156},
  Title =        {A Quadratically-Convergent Algorithm for General
                  Nonlinear Programming Problems},
  Volume =       3,
  Year =         1972
}

@article{Robi:1974,
  Author =       {Stephen M. Robinson},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      MathProg,
  Pages =        {1-16},
  Title =        {Perturbed {K}uhn-{T}ucker Points and Rates of
                  Convergence for a Class of Nonlinear-Programming
                  Algorithms},
  Volume =       7,
  Year =         1974
}

@article{Robi:1984,
  Author =       {Stephen M. Robinson},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      MathProgStudy,
  Pages =        {217-230},
  Title =        {Local structure of feasible sets in nonlinear
                  programming, Part {II}: Nondegeneracy},
  Volume =       22,
  Year =         1984
}

@phdthesis{Robi:2007,
  Abstract =     {Nonlinearly constrained optimization problems may be
                  solved by minimizing a se- quence of simpler
                  subproblems based on the properties of a so-called
                  \emph{merit function} that balances the (usually)
                  conflicting aims of reducing the ob jective function
                  and satisfying the constraints. Sometimes this merit
                  function is minimized directly as an unconstrained
                  function, in which case convergence is achieved by
                  adjusting the relative weighting of the ob jective
                  and constraints between subproblems. Alter-
                  natively, some model of the merit function is
                  minimized sub ject to simple bounds and/or
                  linearizations of the constraints. In this case, the
                  merit function drives the algorithm by assessing the
                  ``quality'' of points generated by the subproblem.
                  A new primal-dual augmented Lagrangian merit
                  function is proposed that may be minimized with
                  respect to both the primal \emph{and} dual
                  variables. A benefit of this approach is that each
                  subproblem may be regularized by imposing explicit
                  bounds on the dual variables. Two primal-dual
                  variants of classical primal methods are given: a
                  primal-dual bound constrained Lagrangian (pdBCL)
                  method and a primal-dual l1 linearly constrained
                  Lagrangian (pd$\ell1$-LCL) method.  },
  Author =       {D. P. Robinson},
  Date-Added =   {2007-10-13 18:02:27 -0700},
  Date-Modified ={2007-10-13 18:04:05 -0700},
  Local-Url =    {file://localhost/Users/mpf/papers/Robinson07.pdf},
  School =       {University of California, San Diego},
  Title =        {Primal-dual methods for nonlinear optimization},
  Year =         2007
}

@book{Roc70,
  Address =      {Princeton},
  Author =       {R. T. Rockafellar},
  Publisher =    {Princeton University Press},
  Title =        {Convex Analysis},
  Year =         1970
}

@Book{Roc74,
  author =       "Rockafellar. R. T.",
  title =        "Conjugate Duality and Optimization",
  publisher =    "Society for Industrial and Applied Mathematics",
  year =         1974,
  address =      "Philadelphia"
}

@misc{Romb:2005,
  Author =       {J. Romberg},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Howpublished = {{\sc Matlab} solver for {DS} problem,
                  \url{http://www.l1-magic.org/}},
  Title =        {{l1dantzig\_pd.m}},
  Year =         2005
}

@inbook{Rose:1963,
  Author =       {J. B. Rosen},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Editor =       {R. L. Graves and P. Wolfe},
  Publisher =    McGrawHill,
  Title =        {Recent Advances in Mathematical Programming},
  Year =         1963
}

@incollection{Rose:1963b,
  Address =      {New York},
  Author =       {J. B. Rosen},
  Booktitle =    {Recent Advances in Mathematical Programming},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Editor =       {R. L. Graves and P. Wolfe},
  Pages =        {159-176},
  Publisher =    McGrawHill,
  Title =        {Convex Partition Programming},
  Year =         1963
}

@techreport{Rose:1977,
  Address =      {Minneapolis, MN},
  Author =       {J. B. Rosen},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Institution =  {Computer Science Department, University of
                  Minnesota},
  Month =        {August},
  Number =       {77-8},
  Title =        {Two-phase algorithm for nonlinear constraint
                  problems},
  Year =         1977
}

@inproceedings{Rose:1978,
  Address =      {New York},
  Author =       {J. B. Rosen},
  Booktitle =    {Nonlinear Programming 3},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Editor =       {O. Mangasarian and R. Meyer and S. Robinson},
  Pages =        {97--124},
  Publisher =    Academic,
  Title =        {{Two-phase} algorithm for nonlinear constraint
                  problems},
  Year =         1978
}

@incollection{RoseKreu:1972,
  Address =      {London},
  Author =       {J. B. Rosen and J. Kreuser},
  Booktitle =    {Numerical Methods for Nonlinear Optimization},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Editor =       {F. A. Lootsma},
  Pages =        {297--300},
  Publisher =    Academic,
  Title =        {A Gradient Projection Algorithm for Non-Linear
                  Constraints},
  Year =         1972
}

@article{RudiOsheFate:1992,
  Author =       {L. Rudin and S. Osher and E. Fatemi},
  Journal =      {Physica D},
  Pages =        {259--268},
  Title =        {Nonlinear total variation based noise removal
                  algorithms},
  Volume =       60,
  Year =         1992
}

@book{RTRW,
  Author =       {R. T. Rockafellar and R. J. B. Wets},
  Publisher =    {Springer},
  Title =        {Variational Analysis},
  Volume =       317,
  Year =         1998
}

@BOOK{Vapnik95,
  author =       {Vapnik,~V.},
  title =        {The Nature of Statistical Learning Theory},
  publisher =    {Springer},
  year =         1995,
  address =      {New York, NY, USA},
}

@ARTICLE{Rockafellar:1990,
  author =       {R. T. Rockafellar},
  title =        {Computational schemes for large-scale problems in
                  extended linear-quadratic programming},
  journal =      mathprog,
  year =         1990,
  pages =        {447--474}
}
@book{vogel:1987,
  title =        {Computational methods for inverse problems},
  author =       {Vogel, C.R.},
  volume =       23,
  year =         1987,
  publisher =    {Society for Industrial Mathematics}
}

@article{osborne1992fisher,
  title =        {Fisher's method of scoring},
  author =       {Osborne, M.R.},
  journal =      {Intern.\@ Stat.\@ Rev.},
  pages =        {99--117},
  year =         1992,
}

@article{RyanOsbo:1986,
  title =        {On the solution of highly degenerate linear
                  programmes},
  author =       {Ryan, D. M. and Osborne, M.R.},
  journal =      MathProg,
  volume =       41,
  number =       1,
  pages =        {385--392},
  year =         1986
}

@Article{SAT04,
  author =       "Sardy, S. and Antoniadis, A. and Tseng, P.",
  title =        "Automatic smoothing with wavelets for a wide class
                  of distributions",
  journal =      "J. Comput. Graph. Stat.",
  year =         2004,
  volume =       13,
  page =         {399--421}
}

@Article{SBT00,
  author =       "Sardy, S. and Bruce, A. and Tseng, P.",
  title =        "Block coordinate relaxation methods for
                  nonparametric wavelet denoising",
  journal =      "J. Comput. Graph. Stat.",
  year =         2000,
  volume =       9,
  page =         {361--379}
}

@Article{SBT01,
  author =       "Sardy, S. and Bruce, A. and Tseng, P.",
  title =        "Robust wavelet denoising",
  journal =      "IEEE Trans. Signal Proc.",
  year =         2001,
  volume =       49,
  page =         {1146--1152}
}

@article{SDPT3:2003,
  Author =       {Reha H T\"ut\"unc\"u and Kim Chuan Toh and Michael
                  J. Todd},
  Title =        {Solving semidefinite-quadratic-linear programs using
                  {SDPT3}},
  Journal =      mathprog,
  Volume =       95,
  Year =         2003,
  Pages =        {189--217}
}

@Techreport{SYOS08,
  author =       "J. Shi and W. Yin and S. Osher and P. Sajda",
  title =        "A fast algorithm for large scale {L1}-regularized
                  logistic regression",
  institution =  "Department of Computational and Applied Mathematics,
                  Rice University",
  address =      "Houston",
  year =         2008
}

@Article{SaS02,
  author =       "Sagastizabal, C. A. and Solodov, M. V.",
  title =        "Parallel variable distribution for constrained
                  optimization",
  journal =      "Computational Optimization and Applications",
  year =         2002,
  volume =       22,
  page =         {111--131}
}

@article{SaT04a,
  Author =       {S. Sardy and P. Tseng},
  Journal =      {J. Amer. Statist. Assoc.},
  Pages =        {191-204},
  Title =        {On the statistical analysis of smoothing by
                  maximizing dirty Markov random field posterior
                  distributions},
  Volume =       99,
  Year =         2004
}

@Article{SaT04b,
  author =       "Sardy, S. and Tseng, P.",
  title =        "{AMlet}, {RAMlet}, and {GAMlet}: automatic nonlinear
                  fitting of additive models, robust and generalized,
                  with wavelets",
  journal =      "J. Comput. Graph. Stat.",
  year =         2004,
  volume =       13,
  page =         {283--309}
}

@InProceedings{SangBuc:2000,
  Author =       {E. Sang and S. Buchholz},
  Title =        {Introduction to the {CoNLL-2000 Shared Task:
                  Chunking}},
  booktitle =    {Proceedings of Conference on Natural Language
                  Learning},
  pages =        {127--132},
  year =         2000
}

@Article{Sardy2004c,
  author =       "Sardy, S. and Tseng, P.",
  title =        "On the statistical analysis of smoothing by
                  maximizing dirty Markov random field posterior
                  distributions",
  journal =      "J. Amer. Statist. Assoc.",
  year =         2004,
  volume =       99,
  page =         {191--204}
}

@incollection{Saun:1996,
  Address =      {Philadelphia},
  Author =       {M. A. Saunders},
  Booktitle =    {Linear and Nonlinear Conjugate Gradient-Related
                  Methods},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Editor =       {L. Adams and J. L. Nazareth},
  Pages =        {92--100},
  Publisher =    SIAMPub,
  Title =        {Cholesky-based methods for sparse least squares:
                  {T}he benefits of regularization},
  Year =         1996
}

@misc{Saun:2010,
  Author =       {Michael A. Saunders},
  Howpublished =
                  {\url{http://www.stanford.edu/group/SOL/software/pdco.html}},
  Title =        {{PDCO: Primal-Dual interior method for Convex
                  Objectives}},
  Month =        {April},
  Year =         2010
}

@techreport{SaunToml:1996,
  Address =      {Department of {EES} \& {OR}, Stanford, CA 94305},
  Author =       {M. A. Saunders and J. A. Tomlin},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Institution =  {Stanford University},
  Month =        {December},
  Note =         {Also IBM Research Report RJ 10064},
  Number =       {SOL Report 96-4},
  Title =        {Solving regularized linear programs using barrier
                  methods and {KKT} systems},
  Year =         1996
}

@article{ScheScho:2000,
  Author =       {Holger Scheel and Stefan Scholtes},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      mathofor,
  Month =        {February},
  Number =       1,
  Title =        {Mathematical programs with complementarity
                  constraints: Stationarity, optimality, and
                  sensitivity},
  Volume =       25,
  Year =         2000
}

@techreport{Schi:2003,
  Author =       {K. Schittkowski},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Institution =  {Department of Mathematics, University of Bayreuth},
  Title =        {{QL}: {A} {F}ortran code for convex quadratic
                  programming - {U}ser's guide},
  Year =         2003
}

@article{Scho:2001,
  Author =       {S. Scholtes},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      siamopt,
  Number =       4,
  Pages =        {918-936},
  Title =        {Convergence properties of a regularization scheme
                  for mathematical programs with complementarity
                  constraints},
  Volume =       11,
  Year =         2001
}

@article{SchoStoh:1999,
  Author =       {S. Scholtes and M. St\"ohr},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      siamcontrol,
  Pages =        {617-652},
  Title =        {Exact penalization of mathematical programs with
                  equilibrium constraints},
  Volume =       37,
  Year =         1999
}

@article{SchoStoh:2001,
  Author =       {S. Scholtes and M. St\"ohr},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      mathofor,
  Pages =        {851-863},
  Title =        {How stringent is the linear independence condition
                  for mathematical programs with equilibrium
                  constraints?},
  Volume =       26,
  Year =         2001
}

@article{Seti:1992,
  Author =       {R. Setiono},
  Date-Modified ={2007-10-20 15:06:49 -0700},
  Journal =      JOTA,
  Number =       3,
  Pages =        {425--444},
  Title =        {Interior proximal point algorithm for linear
                  programs},
  Volume =       74,
  Year =         1992
}

@article{schopfer:2012,
  author =       {Sch\"opfer, F.},
  title =        {Exact Regularization of Polyhedral Norms},
  journal =      {SIAM Journal on Optimization},
  volume =       22,
  number =       4,
  pages =        {1206-1223},
  year =         2012,
  doi =          {10.1137/11085236X},
  URL =          {http://epubs.siam.org/doi/abs/10.1137/11085236X},
}

@article{AravkinLeeuwen:2012,
  author =       {Aleksandr Y Aravkin and Tristan van Leeuwen},
  title =        {Estimating nuisance parameters in inverse problems},
  journal =      {Inverse Problems},
  volume =       28,
  number =       11,
  pages =        115016,
  url =          {http://stacks.iop.org/0266-5611/28/i=11/a=115016},
  year =         2012,
  abstract =     {Many inverse problems include nuisance parameters
                  which, while not of direct interest, are required to
                  recover primary parameters. The structure of these
                  problems allows efficient optimization strategies?îa
                  well-known example is variable projection , where
                  nonlinear least-squares problems which are linear in
                  some parameters can be very efficiently
                  optimized. In this paper, we extend the idea of
                  projecting out a subset over the variables to a
                  broad class of maximum likelihood and maximum a
                  posteriori likelihood problems with nuisance
                  parameters, such as variance or degrees of freedom
                  (d.o.f.). As a result, we are able to incorporate
                  nuisance parameter estimation into large-scale
                  constrained and unconstrained inverse problem
                  formulations. We apply the approach to a variety of
                  problems, including estimation of unknown variance
                  parameters in the Gaussian model, d.o.f. parameter
                  estimation in the context of robust inverse
                  problems, and automatic calibration. Using numerical
                  examples, we demonstrate improvement in recovery of
                  primary parameters for several large-scale inverse
                  problems. The proposed approach is compatible with a
                  wide variety of algorithms and formulations, and its
                  implementation requires only minor modifications to
                  existing algorithms.}
}
	

@inproceedings{pacheco2012minimization,
  title =        {Minimization of Continuous Bethe Approximations: A
                  Positive Variation},
  author =       {Pacheco, Jason and Sudderth, Erik B},
  booktitle =    {Advances in Neural Information Processing Systems},
  pages =        {2573--2581},
  year =         2012
}

@mastersthesis{Shan:2008,
  Address =      {Vancouver},
  Author =       {Shidong Shan},
  Month =        {August},
  School =       {Dept. Computer Science, University of British
                  Columbia},
  Title =        {A {Levenberg-Marquardt} method for large-scale
                  bound-constrained nonlinear least-squares},
  Year =         2008
}

@article{ShanVand:1999,
  Author =       {D. Shanno and R. Vanderbei},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      compapplopt,
  Pages =        {231--252},
  Title =        {An interior-point algorithm for nonconvex nonlinear
                  programming},
  Volume =       13,
  Year =         1999
}

@article {ShannoPhua:1978,
  author =       {Shanno, D. F. and Phua, K.-H.},
  affiliation =  {The University of Arizona Tucson AZ USA},
  title =        {Matrix conditioning and nonlinear optimization},
  journal =      {Mathematical Programming},
  publisher =    {Springer Berlin / Heidelberg},
  issn =         {0025-5610},
  keyword =      {Mathematics and Statistics},
  pages =        {149-160},
  volume =       14,
  issue =        1,
  url =          {http://dx.doi.org/10.1007/BF01588962},
  note =         {10.1007/BF01588962},
  abstract =     {In a series of recent papers, Oren, Oren and
                  Luenberger, Oren and Spedicato, and Spedicato have
                  developed the self-scaling variable metric
                  algorithms. These algorithms alter Broyden's single
                  parameter family of approximations to the inverse
                  Hessian to a double parameter family. Conditions are
                  given on the new parameter to minimize a bound on
                  the condition number of the approximated inverse
                  Hessian while insuring improved step-wise
                  convergence.},
  year =         1978
}

@inproceedings{ShasHaza:2005,
  Author =       {A. Shashua and T. Hazan},
  Booktitle =    {{IEEE} Proceedings of Intl. Conf. Comp. Vision},
  Date-Added =   {2007-10-20 16:04:31 -0700},
  Date-Modified ={2007-10-20 16:05:22 -0700},
  Title =        {Non-negative tensor factorization with applications
                  to statistics and computer vision},
  Year =         2005
}

@unpublished{Shew:1994,
  Author =       {J. R. Shewchuk},
  Month =        {August},
  Note =         {See the author's website:
                  http://www-2.cs.cmu.edu/\tild jrs/},
  Title =        {An Introduction to the Conjugate Gradient Method
                  Without the Agonizing Pain},
  Year =         1994
}

@misc{SilvLim:2007,
  Author =       {V. de Silva and L. Lim},
  Howpublished = {To appear in {\it SIAM J. Matrix Anal. Appl.}},
  Title =        {Tensor rank and the ill-posedness of the best
                  low-rank approximation problem},
  Year =         2007
}

@book{Smit:2004,
  Address =      {Hoboken, NJ},
  Author =       {R. Martin Smith},
  Publisher =    johnwileysons,
  Title =        {Understanding mass spectra: A basic approach},
  Edition =      {Second},
  Year =         2004
}

@Article{SoY07,
  author =       "So, A. M.-C. and Yinyu Ye",
  title =        "Theory of semidefinite programming for sensor
                  network localization",
  journal =      "Math. Program.",
  year =         2007,
  volume =       109,
  page =         {367--384}
}

@Article{Sol98,
  author =       "Solodov, M. V.",
  title =        "Incremental gradient algorithms with step sizes
                  bounded away from zero",
  journal =      "Comput. Optim. Appl.",
  year =         1998,
  volume =       11,
  page =         {23--35}
}

@misc{Spec:2009,
  Author =       {Eckard Specht},
  Title =        {Packing of circles in the unit circle},
  Url =
                  {http://hydra.nat.uni-magdeburg.de/packing/cci/cci.html},
  Year =         2009
}

@Article{StH03,
  author =       "Strohmer, T. and Heath, R. Jr.",
  title =        "Grassmannian frames with applications to coding and
                  communications.",
  journal =      "Appl. Comp. Harm. Anal.",
  year =         2003,
  volume =       14,
  page =         {257--275}
}

@Unpublished{StojParvHass:2008,
  author =       {M. Stojnic and F. Parvaresh and B.  Hassibi},
  title =        {On the reconstruction of block-sparse signals with
                  an optimal number of measurements},
  month =        {March},
  year =         2008,
  note =         {Available at arXiv 0804.0041},
}

@techreport{Stur:2001,
  Author =       {J. F. Sturm},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Institution =  {Department of Econometrics, Tilburg University,
                  Tilburg, The Netherlands},
  Title =        {Using {SeDuMi} 1.02, A {Matlab} toolbox for
                  optimization over symmetric cones (updated for
                  {V}ersion 1.05)},
  Year =         {August 1998 -- October 2001}
}

@article{SturLies:2005,
  Author =       {Eric de Sturler and J\"{o}rg Liesen},
  Doi =          {10.1137/S1064827502411006},
  Journal =      siamcomp,
  Keywords =     {saddle point systems; indefinite systems; eigenvalue
                  bounds; Krylov subspace methods; preconditioning;
                  constrained optimization; mesh-flattening},
  Number =       5,
  Pages =        {1598-1619},
  Publisher =    {SIAM},
  Title =        {Block-Diagonal and Constraint Preconditioners for
                  Nonsymmetric Indefinite Linear Systems. Part I:
                  Theory},
  Url =          {http://link.aip.org/link/?SCE/26/1598/1},
  Volume =       26,
  Year =         2005
}

@misc{SurfaceletToolbox,
  Author =       {Y. Lu},
  Howpublished =
                  {\url{http://www.mathworks.com/matlabcentral/fileexchange/14485}},
  Title =        {{Surfacelet toolbox}},
  Year =         2008
}

@article{TGS06,
  Author =       {Joel A. Tropp and Anna C. Gilbert and Martin
                  J. Strauss},
  Title =        {Algorithms for Simultaneous Sparse Approximation:
                  Part I: Greedy Pursuit},
  Journal =      {Signal Processing},
  Volume =       86,
  Issue =        3,
  Year =         2006,
  Pages =        {572--588}
}

@inproceedings{TakhLaskWakiEtAl:2006,
  Author =       {D. Takhar and J. N. Laska and M. Wakin and M. Duarte
                  and D. Baron and S. Sarvotham and K. K. Kelly and
                  R. G. Baraniuk},
  Booktitle =    {Proceedings of the IS\&T/SPIE Symposium on
                  Electronic Imaging: Computational Imaging},
  Month =        {January},
  Title =        {A new camera architecture based on optical-domain
                  compression},
  Volume =       6065,
  Year =         2006
}

@article{Tapi:1977,
  Author =       {R. A. Tapia},
  Journal =      JOTA,
  Pages =        {135--194},
  Title =        {Diagonalized multiplier methods and quasi-{N}ewton
                  methods for constrained optimization},
  Volume =       22,
  Year =         1977
}

@Article{Teb97,
  author =       "Teboulle, M.",
  title =        "Convergence of proximal-like algorithms",
  journal =      siamopt,
  year =         1997,
  volume =       7,
  page =         {1069--1083}
}

@article{Tib96,
  Author =       {R. Tibshirani},
  Journal =      {J. R. Statist. Soc. B.},
  Number =       1,
  Pages =        {267-288},
  Title =        {Regression shrinkage and selection via the {L}asso},
  Volume =       58,
  Year =         1996
}

@article{TibsSaunRossZhuKnig:2005,
  author =       {Tibshirani, R., Saunders, M., Rosset, S., Zhu,
                  J. and Knight, K.},
  year =         2005,
  title =        {Sparsity and smoothness via the fused lasso},
  journal =      {J. Royal Statistical Society: Series B (Statistical
                  Methodology)},
  number =       67,
  pagges =       {91??08},
  doi =          {10.1111/j.1467-9868.2005.00490.x}
}


@article{Tik63a,
  Author =       {Andrey N. Tikhonov},
  Date-Modified ={2007-12-13 11:49:11 -0800},
  Journal =      {Soviet Math. Dokl.},
  Note =         {English translation of Dokl. Akad. Nauk. SSSR, 153:1
                  (1963), pp 49--52},
  Number =       6,
  Pages =        {1624--1647},
  Title =        {Regularization of incorrectly posed problems},
  Volume =       4,
  Year =         1963
}

@article{Tikh:1963b,
  Author =       {Andrey N. Tikhonov},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      {Soviet Math. Dokl.},
  Note =         {English translation of Dokl. Akad. Nauk. SSSR, 151:3
                  (1963) pp. 501--504},
  Number =       4,
  Pages =        {1035--1038},
  Title =        {Solution of incorrectly formulated problems and the
                  regularization method},
  Volume =       4,
  Year =         1963
}

@book{TikhArse:1977,
  Address =      {Washington, D.C.},
  Author =       {A. N. Tikhonov and V. Y. Arsenin},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Note =         {Translated from Russian},
  Publisher =    {V. H. Winston and Sons},
  Title =        {Solutions of Ill-Posed Problems},
  Year =         1977
}

@Techreport{ToY09,
  author =       "Toh, K.-C. and Yun, S.",
  title =        "An accelerated proximal gradient algorithm for
                  nuclear regularized least squares problems",
  institution =  "Department of Mathematics, National University of
                  Singapore",
  address =      "Singapore",
  year =         2009
}

@article{Todd:2001,
  Author =       {M. J. Todd},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      actanumerica,
  Pages =        {515--560},
  Title =        {Semidefinite optimization},
  Volume =       10,
  Year =         2001
}

@phdthesis{Toft:1996,
  Author =       {P. Toft},
  School =       {Department of Mathematical Modelling, Technical
                  University of Denmark},
  Title =        {The Radon transform: Theory and implementation},
  Year =         1996
}

@techreport{Toml:1975,
  Author =       {John A. Tomlin},
  Institution =  {Department of Operations Research, Stanford
                  University},
  Number =       {SOL 75-12},
  Title =        {A parametric bounding method for finding a minimum
                  {$\ell_\infty$}-norm solution to a system of
                  equations},
  Type =         {Tech. Rep.},
  Year =         1975
}

@article{TrG07,
  title =        {Signal Recovery From Random Measurements Via
                  Orthogonal Matching Pursuit},
  author =       {Tropp, J. A and Gilbert, A. C},
  journal =      ieeetransinfo,
  volume =       53,
  number =       12,
  pages =        {4655--4666},
  year =         2007,
  abstract =     {This article demonstrates theoretically and
                  empirically that a greedy algorithm called
                  Orthogonal Matching Pursuit (OMP) can reliably
                  recover a signal with m nonzero entries in dimension
                  $d$ given $O(m ln d)$ random linear measurements of
                  that signal. This is a massive improvementover
                  previous results for OMP, which require $O(m^2)$
                  measurements. The new results for OMP are comparable
                  with recent results for another algorithm called
                  Basis Pursuit (BP). The OMP algorithm is much faster
                  and much easier to implement, which makes it an
                  attractive alternative to BPfor signal recovery
                  problems}
}

@article{Tro04,
  Author =       {Joel A. Tropp},
  Date-Modified ={2007-09-15 09:32:05 -0700},
  Journal =      {{IEEE} Trans. Inform. Theory},
  Month =        {October},
  Number =       10,
  Pages =        {2231-2242},
  Title =        {Greed is Good: Algorithmic Results for Sparse
                  Approximation},
  Volume =       50,
  Year =         2004
}

@article{BeckBobCandGrant:2011,
  author =       {Becker, Stephen and Cand√®s, Emmanuel and Grant,
                  Michael},
  affiliation =  {Applied and Computational Mathematics, California
                  Institute of Technology, Pasadena, CA 91125, USA},
  title =        {Templates for convex cone problems with applications
                  to sparse signal recovery},
  journal =      mathprogc,
  issn =         {1867-2949},
  keyword =      {Mathematics and Statistics},
  pages =        {165-218},
  volume =       3,
  issue =        3,
  doi =         {10.1007/s12532-011-0029-5},
  abstract =     {This paper develops a general framework for solving
                  a variety of convex cone problems that frequently
                  arise in signal processing, machine learning,
                  statistics, and other fields. The approach works as
                  follows: first, determine a conic formulation of the
                  problem; second, determine its dual; third, apply
                  smoothing; and fourth, solve using an optimal
                  first-order method. A merit of this approach is its
                  flexibility: for example, all compressed sensing
                  problems can be solved via this approach. These
                  include models with objective functionals such as
                  the total-variation norm, || Wx || 1 where W is
                  arbitrary, or a combination thereof. In addition,
                  the paper introduces a number of technical
                  contributions such as a novel continuation scheme
                  and a novel approach for controlling the step size,
                  and applies results showing that the smooth and
                  unsmoothed problems are sometimes formally
                  equivalent. Combined with our framework, these lead
                  to novel, stable and computationally efficient
                  algorithms. For instance, our general implementation
                  is competitive with state-of-the-art methods for
                  solving intensively studied problems such as the
                  LASSO. Further, numerical experiments show that one
                  can solve the Dantzig selector problem, for which no
                  efficient large-scale solvers exist, in a few
                  hundred iterations. Finally, the paper is
                  accompanied with a software release. This software
                  is not a single, monolithic solver; rather, it is a
                  suite of programs and routines designed to serve as
                  building blocks for constructing complete
                  algorithms.},
  year =         2011
}

@article{Tro06a,
  Abstract =     {This paper studies a difficult and fundamental
                  problem that arises throughout electrical
                  engineering, applied mathematics, and statistics.
                  Suppose that one forms a short linear combination of
                  elementary signals drawn from a large, fixed
                  collection. Given an observation of the linear
                  combination that has been contaminated with additive
                  noise, the goal is to identify which elementary
                  signals participated and to approximate their
                  coefficients. Although many algorithms have been
                  proposed, there is little theory which guarantees
                  that these algorithms can accurately and efficiently
                  solve the problem. This paper studies a method
                  called convex relaxation, which attempts to recover
                  the ideal sparse signal by solving a convex program.
                  This approach is powerful because the optimization
                  can be completed in polynomial time with standard
                  scientific software. The paper provides general
                  conditions which ensure that convex relaxation
                  succeeds. As evidence of the broad impact of these
                  results, the paper describes how convex relaxation
                  can be used for several concrete signal recovery
                  problems. It also describes applications to channel
                  coding, linear regression, and numerical analysis.
                  },
  Author =       {Joel A. Tropp},
  Journal =      IEEETransInfo,
  Keywords =     {Algorithms, approximation methods, basis pursuit,
                  convex program, linear regression, optimization
                  methods, orthogonal matching pursuit, sparse
                  representations},
  Month =        {March},
  Number =       3,
  Pages =        {1030--1051},
  Title =        {Just relax: Convex programming methods for
                  identifying sparse signals in noise},
  Volume =       52,
  Year =         2006
}

@article{Tro06b,
  Author =       {Joel A. Tropp},
  Title =        {Algorithms for Simultaneous Sparse Approximation:
                  Part II: Convex Relaxation},
  Journal =      {Signal Processing},
  Volume =       86,
  Issue =        3,
  Year =         2006,
  Pages =        {589--602}
}

@Article{Tropp2004,
  author =       "Tropp, J. A.",
  title =        "Greed is good: algorithmic results for sparse
                  approximation",
  journal =      "IEEE Trans. Inf. Theory",
  year =         2004,
  volume =       50,
  page =         {2231--2242}
}

@Article{TsY08,
  author =       "Paul Tseng and S. Yun",
  title =        "A coordinate gradient descent method for linearly
                  constrained smooth optimization and support vector
                  machines training",
  journal =      "Comput. Optim. Appl.",
  year =         2008
}

@Article{TsY09a,
  author =       "Paul Tseng and S. Yun",
  title =        "A coordinate gradient descent method for nonsmooth
                  separable minimization",
  journal =      "Math. Program.",
  year =         2009,
  volume =       117,
  page =         {387--423}
}

@Article{TsY09b,
  author =       "Paul Tseng and S. Yun",
  title =        "A block-coordinate gradient descent method for
                  linearly constrained nonsmooth separable
                  optimization",
  journal =      jota,
  year =         2009,
  volume =       140,
  page =         {513--535}
}

@Inbook{Tse00,
  author =       "Paul Tseng",
  chapter =      "Error bounds and superlinear convergence analysis of
                  sonic Newton-type methods in optimization",
  title =        "Nonlinear Optimization and Related Topics",
  publisher =    "Kiuwer",
  address =      "Dordrecht",
  year =         2000,
  page =         {445--462}
}

@Article{Tse00b,
  author =       "Paul Tseng",
  title =        "Convergence of block coordinate descent method for
                  nondifferentiable minimization",
  journal =      jota,
  year =         2001,
  volume =       109,
  page =         {473--492}
}

@Article{Tse07,
  author =       "Paul Tseng",
  title =        "Second-order cone programming relaxation of sensor
                  network localization",
  journal =      siamopt,
  year =         2007,
  volume =       18,
  page =         {156--185}
}

@article {Tseng:2010,
   author = {Tseng, Paul},
   title = {Approximation accuracy, gradient methods, and error bound for structured convex optimization},
   journal = mathprog,
   publisher = {Springer Berlin / Heidelberg},
   issn = {0025-5610},
   keyword = {Mathematics and Statistics},
   pages = {263-295},
   volume = {125},
   issue = {2},
   doi = {10.1007/s10107-010-0394-2},
   year = {2010}
}

@Techreport{Tse08,
  author =       "Paul Tseng",
  title =        "On accelerated proximal gradient methods for
                  convex-concave optimization",
  institution =  "Department of Mathematics, University of Washington",
  address =      "Seattle",
  year =         2008,
  month =        "May",
  note =         "submitted to SIAM J. Optim."
}

@Article{Tse09,
  author =       "Paul Tseng",
  title =        "Further results on a stable recovery of sparse
                  overcomplete representations in the presence of
                  noise",
  journal =      IEEETransInfo,
  year =         2009,
  volume =       55,
  page =         {888--899}
}

@Article{Tse91,
  author =       "Paul Tseng",
  title =        "On the rate of convergence of a partially
                  asynchronous gradient projection algorithm",
  journal =      siamopt,
  year =         1991,
  volume =       1,
  page =         {603--619}
}

@Article{Tse93,
  author =       "Paul Tseng",
  title =        "Dual coordinate descent methods for non-strictly
                  convex minimization",
  journal =      "Math. Prog.",
  year =         1993,
  volume =       59,
  page =         {231--247}
}

@Article{Tse98,
  author =       "Paul Tseng",
  title =        "An incremental gradient(-projection) method with
                  momentum term and adaptive stepsize rule",
  journal =      siamopt,
  year =         1998,
  volume =       8,
  page =         {506--531}
}

@article{Tse99,
  Author =       {P. Tseng},
  Journal =      {Comput. Optim. Appl.},
  Pages =        {221--230},
  Title =        {Convergence and error bound for perturbation of
                  linear programs},
  Volume =       13,
  Year =         1999
}

@article{TurlVenaWrig:2005,
  title =        {Simultaneous variable selection},
  author =       {Turlach, B.A. and Venables, W.N. and Wright, S.J.},
  journal =      {Technometrics},
  volume =       47,
  number =       3,
  pages =        {349--363},
  year =         2005,
  publisher =    {American Statistical Association}
}

@article{Ulbr:2004,
  Author =       {S. Ulbrich},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      MathProg,
  Pages =        {217--245},
  Title =        {On the superlinear local convergence of a
                  filter-{SQP} method},
  Volume =       100,
  Year =         2004
}

@article{UlbrUlbr:2003,
  Author =       {M. Ulbrich and S. Ulbrich},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      MathProg,
  Pages =        {103--135},
  Title =        {Non-monotone trust region methods for nonlinear
                  equality constrained optimization without a penalty
                  function},
  Volume =       95,
  Year =         2003
}

@article{Van-:1982,
  Author =       {G. {Van Der Hoek}},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      MathProgStudy,
  Pages =        {162--189},
  Title =        {Asymptotic Properties of Reduction Methods Applying
                  Linearly Equality Constrained Reduced Problems},
  Volume =       16,
  Year =         1982
}

@article{Vand:1995,
  Author =       {R. J. Vanderbei},
  Date-Added =   {2007-10-19 18:34:07 -0700},
  Date-Modified ={2007-10-19 18:34:20 -0700},
  Journal =      siamopt,
  Number =       1,
  Pages =        {100-113},
  Title =        {Symmetric Quasi-Definite Matrices},
  Volume =       5,
  Year =         1995
}

@misc{Vand:2002,
  Author =       {Robert Vanderbei},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Month =        {December},
  Title =        {Benchmarks for nonlinear optimization. {\rm
                  http://www.princeton.edu/\tild rvdb/ bench.html}},
  Year =         2002
}

@article{VandBoyd:1996,
  Author =       {Lieven Vandenberghe and Stephen Boyd},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      SIAMReview,
  Month =        {March},
  Number =       1,
  Pages =        {49--95},
  Title =        {Semidefinite programming},
  Volume =       38,
  Year =         1996
}

@PhdThesis{Vasi:2009,
  author =       {Vasiloglou, Nikolaos},
  title =        {Isometry and convexity in dimensionality reduction},
  school =       {Georgia Institute of Technology},
  year =         2009
}

@article{ViceWrig:2002,
  Author =       {L. N. Vicente and S. Wright},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      compapplopt,
  Pages =        {311--328},
  Title =        {Local convergence of a primal-dual method for
                  degenerate nonlinear programming},
  Volume =       22,
  Year =         2002
}

@Techreport{WNF07,
  author =       "Wright, S. J. and Nowak, R. D. and Figueiredo,
                  M. A. T.",
  title =        "Sparse reconstruction by separable approximation",
  institution =  "Computer Sciences Department, University of
                  Wisconsin",
  address =      "Madison",
  year =         2007,
  month =        "October"
}

@Techreport{WYYZ07,
  author =       "Y. Wang and J. Yang and W. Yin and Y. Zhang",
  title =        "A new alternating minimization algorithm for total
                  variation image reconstruction",
  institution =  "Department of Computational and Applied Mathematics,
                  Rice University",
  address =      "Houston",
  year =         2007,
  note =         "to appear in SIAM Imaging Sci."
}

@Article{WZYB08,
  author =       "Wang, Z. and Zheng, S. and Ye, Y. and Boyd, S.",
  title =        "Further relaxations of the semidefinite programming
                  approach to sensor network localization",
  journal =      siamopt,
  year =         2008,
  volume =       19,
  page =         {655--673}
}

@article{Schittkowski:1981,
  author =       {K. Schittkowski},
  title =        {The nonlinear programming method of {Wilson, Han,
                  and Powell} with an augmented {Lagrangian} type line
                  search function. {I.} Convergence analysis},
  journal =      numermath,
  volume =       38,
  number =       1,
  pages =        {83??14},
  year =         {1981/82}
}

@article{WachBieg:2005,
  Author =       {Andreas W\"achter and Lorenz T. Biegler},
  Journal =      siamopt,
  volume =       16,
  number =       1,
  Pages =        {1--31},
  Title =        {Line Search Filter Methods for Nonlinear
                  Programming: Motivation and Global Convergence},
  Year =         2005
}

@article{WachBieg:2005b,
  Author =       {Andreas W\"achter and Lorenz T. Biegler},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      SIAMOpt,
  Number =       1,
  Pages =        {32--48},
  Title =        {Line Search Filter Methods for Nonlinear
                  Programming: Local Convergence},
  Volume =       16,
  Year =         2005
}

@article{WellWebe:2001,
  Author =       {M. Welling and M. Weber},
  Date-Added =   {2007-09-13 22:01:05 -0700},
  Date-Modified ={2007-09-13 22:01:14 -0700},
  Journal =      {Pattern Recog. Letters},
  Pages =        {1255--1261},
  Title =        {Positive tensor factorization},
  Volume =       22,
  Year =         2001
}

@Article{Whi96,
  author =       "White, D. J.",
  title =        "A heuristic approach to a weighted maxmin dispersion
                  problem",
  journal =      "IMA Journal of Management Mathematics",
  year =         1996,
  volume =       9,
  page =         {219--231}
}

@article{Wils:1992,
  Author =       {D. G. Wilson},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      {SIAG/OPT Views and News},
  Pages =        {9--10},
  Title =        {A brief introduction to the IBM Optimization
                  Subroutine Library},
  Volume =       1,
  Year =         1992
}

@Book{Wri97,
  author =       "Wright, S. J.",
  title =        "Primal-Dual Interior-Point Methods",
  publisher =    "SIAM",
  year =         1997,
  address =      "Philadelphia"
}

@article{Wrig:1990,
  Author =       {Wright, S. J.},
  Coden =        {JOTABN},
  Fjournal =     {Journal of Optimization Theory and Applications},
  Issn =         {0022-3239},
  Journal =      jota,
  Mrclass =      {90C05 (90C06 90C20)},
  Mrnumber =     {MR1052832 (91d:90062)},
  Mrreviewer =   {Christian Michelot},
  Number =       3,
  Pages =        {531--554},
  Title =        {Implementing proximal point methods for linear
                  programming},
  Volume =       65,
  Year =         1990
}

@article{Wrig:1998,
  Author =       {M. H. Wright},
  Date-Modified ={2007-07-18 14:59:32 -0700},
  Journal =      siamopt,
  Pages =        {84-111},
  Title =        {Ill-conditioning and computational error in
                  primal-dual methods for nonlinear programming},
  Volume =       9,
  Year =         1998
}

@article{WrigRalp:1996,
  Author =       {Stephen J. Wright and Danny Ralph},
  Date-Modified ={2007-07-18 14:59:31 -0700},
  Journal =      mathofor,
  Pages =        {815--838},
  Title =        {A superliner infeasible-interior-point algorithm for
                  monotone complementarity problems},
  Volume =       21,
  Year =         1996
}

@article{Wright:1998,
  title =        {Superlinear Convergence of a Stabilized SQP Method
                  to a Degenerate Solution},
  author =       {Wright, S.J.},
  Journal =      compapplopt,
  volume =       11,
  number =       3,
  pages =        {253--275},
  year =         1998,
  publisher =    {Springer}
}

@article{WuYe:2002,
  Author =       {Z. Wu and J. J. Ye},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      MathProg,
  Number =       1,
  Pages =        {301--314},
  Title =        {On error bounds for lower semicontinuous functions},
  Volume =       92,
  Year =         2002
}

@article{XueYe:2000,
  Author =       {G. Xue and Y. Ye},
  Title =        {An efficient algorithm for minimizing a sum of
                  p-norms},
  Journal =      siamopt,
  Volume =       10,
  Number =       2,
  Pages =        {551--579},
  Year =         2000
}

@Article{YELM07,
  author =       "M. Yuan and A. Ekici and Z. Lu and R. Monteiro",
  title =        "Dimension reduction and coefficient estimation in
                  multivariate linear regression",
  journal =      "J. Royal Stat. Soc. B.",
  year =         2007,
  volume =       69,
  page =         {329--346}
}

@Article{YJC08,
  author =       "Ye, J. and Ji, S. and Chen, J.",
  title =        "Multi-class discriminant kernel learning via convex
                  programming",
  journal =      "J. Machine Learning Res.",
  year =         2008,
  volume =       9,
  page =         {719--758}
}

@article{Haber:2012,
  Author =       {E. Haber and M. Chung and F. J. Herrmann},
  journal =      siamopt,
  Number =       3,
  volume =       22,
  pages =        {739--757},
  Title =        {An effective method for parameter estimation with
                  {PDE} constraints with multiple right-hand sides},
  Year =         2012
}


@Article{YOGD08,
  author =       "W. Yin and S. Osher and D. Goldfarb and J. Darbon",
  title =        "{Bregman} iterative algorithms for L1 minimization
                  with applications to compressed sensing",
  journal =      "SIAM J. Imaging Sci.",
  year =         2008,
  volume =       1,
  page =         {143--168}
}

@Techreport{YZY08,
  author =       "J. Yang and Y. Zhang and W. Yin",
  title =        "An efficient {TVL1} algorithm for deblurring
                  multichannel images corrupted by impulsive noise",
  institution =  "Department of Computational and Applied Mathematics,
                  Rice University",
  address =      "Houston",
  year =         2008
}

@article{YamaYabe:1996,
  Author =       {H. Yamashita and H. Yabe},
  Date-Modified ={2007-07-18 14:59:34 -0700},
  Journal =      MathProg,
  Pages =        {377--397},
  Title =        {Superlinear and quadratic convergence of some
                  primal-dual interior point methods for constrained
                  optimization},
  Volume =       75,
  Year =         1996
}

@Book{Ye97,
  author =       "Ye, Y.",
  title =        "Interior point Algorithms: Theory and Analysis",
  publisher =    "John Wiley \& Sons",
  year =         1997,
  address =      "New York"
}

@book{Ye:1997,
  Address =      {Chichester, UK},
  Author =       {Y. Ye},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Publisher =    {Wiley},
  Title =        {Interior-Point Algorithms: Theory and Analysis},
  Year =         1997
}

@Article{YuL06,
  author =       "M. Yuan and Y. Lin",
  title =        "Model selection and estimation in regression with
                  grouped variables",
  journal =      "J. Royal Stat. Soc. B.",
  year =         2006,
  volume =       68,
  page =         {49--67}
}

@Article{YuL07,
  author =       "M. Yuan and Y. Lin",
  title =        "Model selection and estimation in the Gaussian
                  graphical model",
  journal =      "Biometrika",
  year =         2007,
  volume =       94,
  page =         {19--35}
}

@Techreport{YuT08,
  author =       "S. Yunand K.-C. Toh",
  title =        "A coordinate gradient descent method for
                  L1-regularized convex minimization",
  institution =  "Department of Mathematics, National University of
                  Singapore",
  address =      "Singapore",
  year =         2008,
  note =         "submitted to Comput. Optim. Appl."
}

@article{YuZhaoWang:2005,
  Author =       {H.-Y. Yu and S.-Y. Zhao and Ge Wang},
  Journal =      {Phys. Med. Biol.},
  Pages =        {5583--5595},
  Title =        {A differentiable Shepp-Logan phantom and its
                  application in exact cone-beam {CT}},
  Volume =       50,
  Year =         2005
}

@Techreport{ZWC08,
  author =       "M. Zhu and S. J. Wright and T. F. Chan",
  title =        "Duality-based algorithms for total-variation
                  regularized image restoration",
  institution =  "Department of Mathematics, UCLA",
  address =      "Los Angeles",
  year =         2008
}

@Techreport{ZhC08,
  author =       "M. Zhu and T. F. Chan",
  title =        "An efficient primal-dual hybrid gradient algorithm
                  for total variation image restoration",
  institution =  "Department of Mathematics, UCLA",
  address =      "Los Angeles",
  year =         2008
}

@article{ZhaoLi:2002,
  Author =       {Y.-B. Zhao and D. Li},
  Date-Modified ={2007-07-18 14:59:33 -0700},
  Journal =      siamopt,
  Number =       4,
  Pages =        {893-912},
  Title =        {Locating the Least 2-Norm Solution of Linear
                  Programs via a Path-Following Method},
  Volume =       12,
  Year =         2002
}

@article{ZibuPear:2001,
  Author =       {M. Zibulevsky and B. A. Pearlmutter},
  Issue =        4,
  Journal =      {Neural Computation},
  Pages =        {863--882},
  Title =        {Blind source separation by sparse decomposition in a
                  signal dictionary},
  Volume =       13,
  Year =         2001
}

@Article{bellavia-2009,
  author =       {S. Bellavia and J. Gondzio and B. Morini},
  title =        {Regularization and Preconditioning of {KKT} Systems
                  Arising in Nonnegative Least-Squares Problems},
  journal =      {Numerical Linear Algebra and Applications},
  year =         2009,
  doi =          {10.1002/nla.610},
  volume =       16,
  number =       1,
  pages =        {39--61},
}

@book{bertsekas1996neuro,
  title =        {{Neuro-dynamic programming}},
  author =       {Bertsekas, D.P. and Tsitsiklis, J.N.},
  publisher =    {Athena Scientific},
  year =         1996
}

@article{Byrd:2012,
  author =       {Byrd, Richard H. and Chin, Gillian and Nocedal, Jorge
                  and Wu, Yuchen},
  affiliation =  {Department of Computer Science, University of
                  Colorado, Boulder, CO, USA},
  title =        {Sample size selection in optimization methods for
                  machine learning},
  journal =      mathprog,
  publisher =    {Springer Berlin / Heidelberg},
  issn =         {0025-5610},
  keyword =      {Mathematics and Statistics},
  pages =        {127-155},
  volume =       134,
  issue =        1,
  doi =          {10.1007/s10107-012-0572-5},
  abstract =     {This paper presents a methodology for using varying
                  sample sizes in batch-type optimization methods for
                  large-scale machine learning problems. The first
                  part of the paper deals with the delicate issue of
                  dynamic sample selection in the evaluation of the
                  function and gradient. We propose a criterion for
                  increasing the sample size based on variance
                  estimates obtained during the computation of a batch
                  gradient. We establish an $${O(1/\epsilon)}$$
                  complexity bound on the total cost of a gradient
                  method. The second part of the paper describes a
                  practical Newton method that uses a smaller sample
                  to compute Hessian vector-products than to evaluate
                  the function and the gradient, and that also employs
                  a dynamic sampling technique. The focus of the paper
                  shifts in the third part of the paper to L 1
                  -regularized problems designed to produce sparse
                  solutions. We propose a Newton-like method that
                  consists of two phases: a (minimalistic) gradient
                  projection phase that identifies zero variables, and
                  subspace phase that applies a subsampled Hessian
                  Newton iteration in the free variables. Numerical
                  tests on speech recognition problems illustrate the
                  performance of the algorithms.},
  year =         2012
}

@inproceedings{schraudolph:2007,
  author =       {Nicol N. Schraudolph and Jin Yu and Simon G\"unter},
  title =
                  {\href{http://nic.schraudolph.org/pubs/SchYuGue07.pdf}{
                  A Stochastic Quasi-{N}ewton Method for Online Convex
                  Optimization}},
  pages =        {436--443},
  editor =       {Marina Meila and Xiaotong Shen},
  booktitle =    {Proc.\ 11$^{th}$ Intl.\ Conf.\ Artificial
                  Intelligence and Statistics (AIStats)},
  address =      {San Juan, Puerto Rico},
  volume =       2,
  series =       {Workshop Conf.\@ Proc.},
  publisher =    {J.\@ Machine Learning Res.},
  year =         2007,
  b2h_type =     {Top Conferences},
  b2h_topic =    {>Quasi-Newton Methods},
  abstract =     { We develop stochastic variants of the well-known
                  BFGS quasi-Newton optimization method, in both full
                  and memory-limited (LBFGS) forms, for online
                  optimization of convex functions. The resulting
                  algorithm performs comparably to a well-tuned
                  natural gradient descent but is scalable to very
                  high-dimensional problems. On standard benchmarks in
                  natural language processing, it asymptotically
                  outperforms previous stochastic gradient methods for
                  parameter estimation in conditional random
                  fields. We are working on analyzing the convergence
                  of online (L)BFGS, and extending it to non-convex
                  optimization problems.  }
}

@inproceedings{bottou-2010,
  author =       {Bottou, L\'{e}on},
  title =        {Large-Scale Machine Learning with Stochastic
                  Gradient Descent},
  year =         2010,
  booktitle =    {Proceedings of the 19th International Conference on
                  Computational Statistics (COMPSTAT'2010)},
  editor =       {Lechevallier, Yves and Saporta, Gilbert},
  address =      {Paris, France},
  month =        {August},
  publisher =    {Springer},
  pages =        {177--187},
  url =          {http://leon.bottou.org/papers/bottou-2010},
}



@article{Byrd:2011,
  author =       {Richard H. Byrd and Gillian M. Chin and Will Neveitt
                  and Jorge Nocedal},
  title =        {On the Use of Stochastic Hessian Information in
                  Optimization Methods for Machine Learning},
  publisher =    {SIAM},
  year =         2011,
  journal =      siamopt,
  volume =       21,
  number =       3,
  pages =        {977-995},
  keywords =     {unconstrained optimization; stochastic optimization;
                  machine learning},
  url =          {http://link.aip.org/link/?SJE/21/977/1},
  doi =          {10.1137/10079923X}
}

@misc{cplex:2007,
  Howpublished = {Mathematical programming system,
                  \url{http://www.cplex.com}},
  Key =          {CPLEX},
  Title =        {{ILOG CPLEX}},
  Year =         2007
}

@book{lohr1999sampling,
  title =        {{Sampling: design and analysis}},
  author =       {Lohr, Sharon L.},
  year =         1999,
  publisher =    {Duxbury Press},
  address =      {Pacific Grove}
}

@Misc{mnist,
  author =       {Yann LeCun and Corinna Cortes},
  title =        {The {MNIST} database},
  howpublished = {\url{http://yann.lecun.com/exdb/mnist/}},
  year =         2011
}

@article{nemirovski1994efficient,
  title =        {{Efficient methods in convex programming}},
  author =       {Nemirovski, A.},
  journal =      {Lecture notes},
  year =         1994
}

@article{nemirovski2009robust,
  title =        {Robust stochastic approximation approach to
                  stochastic programming},
  author =       {Nemirovski, A. and Juditsky, A. and Lan, G. and
                  Shapiro, A.},
  journal =      siamopt,
  volume =       19,
  number =       4,
  pages =        {1574--1609},
  year =         2009,
  publisher =    {Society for Industrial and Applied Mathematics}
}

@Misc{slimpy:2007,
  key =          {\url{http://slim.eos.ubc.ca/SLIMpy}},
  author =       {F. Herrmann and S. Ross-Ross},
  title =        {{SlimPy}: {A Python} interface to {Unix}-like pipe
                  based linear operators},
  howpublished = {\url{http://slim.eos.ubc.ca/SLIMpy}},
  year =         2007
}

@article{solodov1998incremental,
  title =        {{Incremental gradient algorithms with stepsizes
                  bounded away from zero}},
  author =       {Solodov, M.V.},
  journal =      {Computational Optimization and Applications},
  volume =       11,
  number =       1,
  pages =        {23--35},
  year =         1998,
  publisher =    {Springer}
}

@misc{sparselab,
  Author =       {David L. Donoho and Iddo Driori and Victoria
                  C. Stodden and Yaakov Tsaig},
  Date-Added =   {2007-12-13 11:47:57 -0800},
  Date-Modified ={2007-12-13 11:47:57 -0800},
  Howpublished = {\url{http://sparselab.stanford.edu/}},
  Title =        {Sparselab},
  Year =         2007
}

@article {springerlink:10.1007/s10107-009-0306-5,
  author =       {Ma, Shiqian and Goldfarb, Donald and Chen, Lifeng},
  affiliation =  {Department of Industrial Engineering and Operations
                  Research, Columbia University, New York, NY 10027,
                  USA},
  title =        {Fixed point and Bregman iterative methods for matrix
                  rank minimization},
  journal =      {Mathematical Programming},
  publisher =    {Springer Berlin / Heidelberg},
  issn =         {0025-5610},
  keyword =      {Mathematics and Statistics},
  pages =        {321-353},
  volume =       128,
  issue =        1,
  url =          {http://dx.doi.org/10.1007/s10107-009-0306-5},
  note =         {10.1007/s10107-009-0306-5},
  abstract =     {The linearly constrained matrix rank minimization
                  problem is widely applicable in many fields such as
                  control, signal processing and system
                  identification. The tightest convex relaxation of
                  this problem is the linearly constrained nuclear
                  norm minimization. Although the latter can be cast
                  as a semidefinite programming problem, such an
                  approach is computationally expensive to solve when
                  the matrices are large. In this paper, we propose
                  fixed point and Bregman iterative algorithms for
                  solving the nuclear norm minimization problem and
                  prove convergence of the first of these
                  algorithms. By using a homotopy approach together
                  with an approximate singular value decomposition
                  procedure, we get a very fast, robust and powerful
                  algorithm, which we call FPCA (Fixed Point
                  Continuation with Approximate SVD), that can solve
                  very large matrix rank minimization problems (the
                  code can be downloaded from
                  http://www.columbia.edu/~sm2756/FPCA.htm for
                  non-commercial use). Our numerical results on
                  randomly generated and real matrix completion
                  problems demonstrate that this algorithm is much
                  faster and provides much better recoverability than
                  semidefinite programming solvers such as SDPT3. For
                  example, our algorithm can recover 1000 ? 1000
                  matrices of rank 50 with a relative error of 10 ??
                  in about 3 min by sampling only 20\% of the
                  elements. We know of no other method that achieves
                  as good recoverability. Numerical experiments on
                  online recommendation, DNA microarray data set and
                  image inpainting problems demonstrate the
                  effectiveness of our algorithms.},
  year =         2011
}

@article {springerlink:10.1007/s10107-010-0437-8,
  author =       {Liu, Yong-Jin and Sun, Defeng and Toh, Kim-Chuan},
  affiliation =  {Faculty of Science, Shenyang Aerospace University,
                  110136 Shenyang, People?ôs Republic of China},
  title =        {An implementable proximal point algorithmic
                  framework for nuclear norm minimization},
  journal =      {Mathematical Programming},
  publisher =    {Springer Berlin / Heidelberg},
  issn =         {0025-5610},
  keyword =      {Mathematics and Statistics},
  pages =        {1-38},
  url =          {http://dx.doi.org/10.1007/s10107-010-0437-8},
  note =         {10.1007/s10107-010-0437-8},
  abstract =     {The nuclear norm minimization problem is to find a
                  matrix with the minimum nuclear norm subject to
                  linear and second order cone constraints. Such a
                  problem often arises from the convex relaxation of a
                  rank minimization problem with noisy data, and
                  arises in many fields of engineering and science. In
                  this paper, we study inexact proximal point
                  algorithms in the primal, dual and primal-dual forms
                  for solving the nuclear norm minimization with
                  linear equality and second order cone
                  constraints. We design efficient implementations of
                  these algorithms and present comprehensive
                  convergence results. In particular, we investigate
                  the performance of our proposed algorithms in which
                  the inner sub-problems are approximately solved by
                  the gradient projection method or the accelerated
                  proximal gradient method. Our numerical results for
                  solving randomly generated matrix completion
                  problems and real matrix completion problems show
                  that our algorithms perform favorably in comparison
                  to several recently proposed state-of-the-art
                  algorithms. Interestingly, our proposed algorithms
                  are connected with other algorithms that have been
                  studied in the literature.},
}

@TechReport{tao-user-ref:2007,
  author =       "S. J. Benson and L. Curfman McInnes and J.  Mor\'{e}
                  and J. Sarich",
  title =        "{TAO} User Manual (Revision 1.8)",
  year =         2007,
  institution =  "Mathematics and Computer Science Division, Argonne
                  National Laboratory",
  address =      {Argonne, IL},
  number =       "ANL/MCS-TM-242",
  note =         "\url{http://www.mcs.anl.gov/tao}",
  type =         {Tech. rep.}
}

@PhdThesis{Robinson:2007,
  author =       {Daniel Robinson},
  title =        {Primal Dual Methods for Nonlinear Optimization},
  school =       {University of California, San Diego},
  year =         2007,
  month =        {September}
}

@article{IzmailovSolodov:2011,
  year =         2011,
  issn =         {0025-5610},
  journal =      mathprog,
  volume =       126,
  number =       2,
  doi =          {10.1007/s10107-009-0279-4},
  title =        {On attraction of linearly constrained Lagrangian
                  methods and of stabilized and quasi-Newton SQP
                  methods to critical multipliers},
  url =          {http://dx.doi.org/10.1007/s10107-009-0279-4},
  publisher =    {Springer-Verlag},
  keywords =     {Constrained optimization; Degenerate constraints;
                  Second-order sufficiency; Newton method; SQP; MINOS;
                  SNOPT; 90C30; 90C33; 90C55; 65K05},
  author =       {Izmailov, A.F. and Solodov, M.V.},
  pages =        {231-257},
  language =     {English}
}

@article{WinTitAbs:2013,
  year =         2013,
  issn =         {0022-3239},
  journal =      jota,
  doi =          {10.1007/s10957-013-0323-7},
  title =        {Addressing Rank Degeneracy in Constraint-Reduced
                  Interior-Point Methods for Linear Optimization},
  url =          {http://dx.doi.org/10.1007/s10957-013-0323-7},
  publisher =    {Springer US},
  keywords =     {Linear programming; Linear optimization; Constraint
                  reduction; Primal?ìdual interior point;
                  Regularization},
  author =       {Winternitz, LukeB. and Tits, Andr√©L. and Absil,
                  P.-A.},
  pages =        {1-31},
  language =     {English}
}

@article {freund:1987,
  AUTHOR =       {Freund, Robert M.},
  TITLE =        {Dual gauge programs, with applications to quadratic
                  programming and the minimum-norm problem},
  JOURNAL =      {Math. Programming},
  FJOURNAL =     {Mathematical Programming},
  VOLUME =       38,
  YEAR =         1987,
  NUMBER =       1,
  PAGES =        {47--67},
  ISSN =         {0025-5610},
  CODEN =        {MHPGA4},
  MRCLASS =      {90C20 (65K05)},
  MRNUMBER =     {899008 (88k:90146)},
  MRREVIEWER =   {Kunio Oshima},
  DOI =          {10.1007/BF02591851},
  URL =          {http://dx.doi.org/10.1007/BF02591851},
}


@article{ArmandBenois:2013,
  year =         2013,
  issn =         {0025-5610},
  journal =      mathprog,
  volume =       137,
  number =       {1-2},
  doi =          {10.1007/s10107-011-0498-3},
  title =        {Uniform boundedness of the inverse of a Jacobian
                  matrix arising in regularized interior-point
                  methods},
  url =          {http://dx.doi.org/10.1007/s10107-011-0498-3},
  publisher =    {Springer-Verlag},
  keywords =     {Constrained optimization; Primal-dual interior-point
                  method; 49M37; 65F05; 65F22; 65K05; 90C05; 90C30;
                  90C51},
  author =       {Armand, Paul and Benoist, Jo√´l},
  pages =        {587-592},
  language =     {English}
}


@article{tseng:1998,
  author =       {Paul Tseng},
  title =        {An Incremental Gradient(-Projection) Method with
                  Momentum Term and Adaptive Stepsize Rule},
  publisher =    {SIAM},
  year =         1998,
  journal =      siamopt,
  volume =       8,
  number =       2,
  pages =        {506-531},
  keywords =     {incremental gradient method; gradient projection;
                  convergence analysis; backpropagation; nonlinear
                  neural network training},
  url =          {http://link.aip.org/link/?SJE/8/506/1},
  doi =          {10.1137/S1052623495294797}
}

@InCollection{vonNeumann:1937,
  author =       {J. von Neumann},
  title =        {Some matrix inequalities and metrization of
                  matric-space},
  booktitle =    {Univ. Tomsk. Rev.},
  series =       {Collected Works},
  publisher =    {Pergamon},
  address =      {Oxford},
  year =         1962,
  volume =       {IV},
  pages =        {205-218}
}
